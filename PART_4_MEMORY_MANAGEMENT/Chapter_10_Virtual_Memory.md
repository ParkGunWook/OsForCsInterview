## What we gonna study

9장에서, 우리는 컴퓨터 시스템을 이용한 다양한 메모리 관리 전략을 토론했다. 모든 전략들은 같은 목적을 가지고 있다. 많은 프로세스를 멀티프로그래밍을 허용하기 위해서 메모리에 유지하는 것이다. 그러나, 그들은 실행하기 위해서 전체 프로세스를 필요로하는 경향이 있다.

가상 메모리는 메모리 전체가 프로세스에 없어도 실행하게 해주는 기술이다. 이 구조의 한가지 주요한 장점은 프로그램이 물리 프로그램보다 커도 가능할 수 있다는 것이다. 더 나아가, 가상 메모리는 메인메모리를 아주 크고, 일정한 공간의 행렬이고, 논리 메모리를 프로그래머의 입장에서 분리한다. 이 기술은 프로그래머를 메모리 공간 한계로부터 자유롭게 해주었다. 가상 메모리는 또한 프로세스끼리 파일과 라이브러리를 공유하게 해주고, 공유메모리를 구현한다. 추가적으로, 그것은 프로세스 생성에 효율적인 메커니즘을 제공한다. 가상 메모리는 쉽게 구현할 수 없다. 그러나, 그것이 부주의하게 만들어지면, 잠재적으로 성능을 하락시킨다. 이 장에서는, 우리는 가상메모리의 개요를 기술하고, 어떻게 구현되었는지, 그것의 복잡도와 장점을 살펴보겠다.

## Objectives

- [ ] 가상 메모리를 정의하고 그것의 장점을 설명한다.
- [ ] 어떻게 페이지가 디맨드 페이징을 이용해서 로드되는지 설명한다.
- [ ] FIFO, optimal, LRU 페이지 교체 알고리즘을 적용한다.
- [ ] 프로세스의 집합을 설명하고, 어떻게 프로그램 지역성을 관련하는지 설명한다.
- [ ] 리눅스, 윈도우, 솔라리스에서의 가상메모리 관리를 설명한다.
- [ ] C언어를 이용해서 가상 메모리 매니저 시뮬레이션을 디자인한다.


## 10.1 백그라운드

9장에서 설명한 메모리 관리 알고리즘은 한가지 기초 필수 사항 때문에 필요하다. 바로, 실행되는 명령어는 반드시 물리메모리에 있어야한다는 점이다. 이 필요를 충족하는 첫번째 접근은 전체 논리 주소 공간을 물리메모리에 넣는 것이다. 동적 링킹은 이 제한을 완화할 수 있는데, 그것은 특별한 주의와 추가 작업이 프로그래머에게 필요하다.

명령어가 반드시 물리 메모리에 있어야한다는 필요점은 필수적이고 근거있어보인다. 불행한 점인 이유는 프로그램의 사이즈가 물리메모리의 사이즈에 의해서 제한된다. 실제 프로그램를 평가하면, 많은 경우에서, 전체 프로그램이 필요하지는 않다. 예를 들어서, 다음을 고려해보자.

- 프로그램들은 보통 비정상적인 에러 상황을 코딩해야한다. 이런 에러는 가끔 일어나고, 코드는 거의 실행되지 않는다.
- 행렬, 리스트, 테이블들은 보통 필요한 것보다 더 많이 할당된다. 행렬은 10개가 필요한데도 100개가 선언되기도 한다.
- 프로그램의 일부 옵션과 기능은 거의 사용되지 않는다. 예를 들어서, US 정부 컴퓨터의 예산을 조정하는 루틴은 몇년간 사용되지 않았다.

전체 프로그램이 필요한 경우에도, 그것은 같은 시간동안 필요하지는 않다.

메모리에 일부만 있는 프로그램을 실행하는 능력은 많은 장점을 수여한다.

- 프로그램은 물리 메모리의 크기에 더이상 제한되지 않는다. 유저들은 프로그램을 아주 큰 가상 메모리 공간으로 쓸 수 있게된다. 
- 각 프로그램이 적은 물리 메모리를 차지해서, 더 많은 프로그램들이 동시에 작동할 수 있어서, CPU 효율성, 산출량을 증가 시킬 수있다.(반응시간 또는 턴어라운드 시간은 변화가 없다.)
- I/O가 프로그램의 일부분을 메모리로 로드하거나 스왑할 필요가 적어진다. 그래서 각 프로그램은 더 빠르게 실행할 수 있다.

그러므로, 메모리에 전체 프로그램을 담지 않는 것은 유저와 시스템에게 이득이 된다.

**Virtual memory**는 물리메모리로부터 개발자에게 감지되는 논리 메모리의 분리를 포함한다. 이 분리는 오직 작은 물리 메모리가 존재할 때 프로그래머에게 제공된 매우 큰 물리 메모리를 허용한다. 가상 메모리는 프로그래밍의 업무를 훨씬 쉽게 만드는데, 왜냐하면 프로그래머는 더이상 물리 메모리의 양에 신경쓰지 않아도 되기 때문이다. 그녀는 문제를 해결하는데에만 신경써도 된다.

프로세스의 **Virtual address space**는 어떻게 논리적인 관점에서 프로세스가 메모리에 저장하는지를 언급한다. 일반적으로, 이 과점은 프로세스가 특정 논리 주소에서 시작한다는 것이다. 즉, 주소 0이다. 그리고 연속적인 메모리로 존재한다. 9장을 생각하면, 물리 메모리의 페이지 프레임에서 프레임에 할당된 프로세스는 연속적이지 않다. 그것은 논리 페이지를 물리 페이지 프레임에 매핑하는 MMU에 달려있다.

우리는 프로세스에서 동적 메모리 할당으로 사용되는 힙 메모리가 있다. 유사하게, 우리는 함수콜마다 사용되는 스택메모리가 있다. 힙영역과 스택 영역 사이의 거대한 빈 공간은 가상 주소공간의 일부이지만, 힙과 스택이 커질수록 실제 물리 페이지를 필요로 할 것이다. 가상 메모리 공간에서 구멍을 포함한 공간을 **sparse address space**라고 한다. sparse 주소 공간을 사용하는 것은 스택과 힙이 자랄때마다 채워지기 때문에 이득이다. 또는 우리가 dll을 프로그램 실행중에 사용하고 싶을때도 마찬가지이다.

물리 메모리로부터 논리 메모리를 분리하는 것은, 가상 메모리가 2프로세스간에 페이지 공유를 통해서 메모리와 파일을 공유하게한다. 다음과 같은 이득을 만든다.
- C 라이브러리같은 시스템 라이브러리는 공유 오브젝트의 매핑을 통해서 몇몇 프로세스를 공유할 수 있다. 비록 각 프로세스가 그것의 가상 주소공간의 일부를 라이브러리에 사용해도, 물리 페이지에 있는 라이브러리는 같은 곳에서 공유된 것이다. 일반적으로, 라이브러리는 각 프로세스의 공간에서 읽기전용으로 매핑된다.
- 비슷하게, 프로세스들은 메모리를 공유할 수 있다. 3장에서 말했던 두 프로세스간의 통신을 생각해보자. 가상 메모리는 한 프로세스가 다른 프로세스와 공유할 수 있는 메모리의 리전을 만들게 해준다. 이 리전을 공유하는 프로세스들은 그것을 그들의 가상 메모리 주소라고 고려하고, 실제로는 공유되고 있는 것이다.
- 페이지들은 프로세스 생성중에 fork() 시스템 콜로 공유될수 있고, 그러므로 프로세스 생성을 빠르게한다.

우리는 뒤에서 더 많은 장점을 보겠다. 먼저, 디맨드 페이징을 이용해서 가상메모리를 구현해보겠다.

## 10.2 디맨드 페이징

어떻게 실행가능한 프로그램이 2차 저장소에서 메모리로 로드될까? 한가지 옵션은 전체 프로그램을 물리 메모리에 로드하는 것이다. 그러나, 이 접근은 전체 프로그램이 메모리에 있을 필요가 없기에 필요하지 않다. 프로그램은 유저가 선택한 필요한 옵션만 시작한다. 전체 프로그램을 메모리에 로딩하는 것은 모든 옵션을 로딩하는 것이고, 유저에 의해서 선택되었는지는 전혀 고려하지 않는다. 

다른 전략은 페이지를 필요한 것만 로드하는 것이다. 이 기술이 **demand paging**이고 가상 메모리 시스템에서 보통 사용된다. 디맨드 페이지된 가상 메모리와 함께, 페이지들은 오직 그들이 프로그램 실행에 필요할떄만 로드된다. 디맨드 페이징 시스템은 스와핑과 비슷하다. 디맨드 페이징은 가상 메모리의 주요한 장점을 설명하는데, 오직 프로그램의 일부만을 로딩하고, 메모리는 더욱 효율적이게된다.

### 10.2.1 기본 개념

디맨드 페이징의 일반적인 컨셉은, 페이지를 오직 필요할 때만 로드하는 것이다. 결과적으로, 프로세스가 실행중일때, 몇몇 페이지들은 메모리에 있어야하고, 몇몇은 2차 저장소에 있다. 그러므로, 우리는 이 두가지를 구분할 하드웨어적인 지원이 필요하다. valid-invalid 비트가 이 목적을 위해서 사용된다. 이번에는, 비트가 valid이면 사용가능이고 메모리에 있다는 것이다. 만약에 비트가 invalid이면, 유효하지 않거나, 2차메모리에 있다는 것이다. 페이지를 위한 페이지 테이블 엔트리는 평소대로 세팅되지만, 메모리에 없는 페이지 테이블의 엔트리는 invalid가 된다. 

그러나 메모리에 없는 페이지를 프로세스가 접근하려면 무슨 일이 일어날까? 페이지로의 접근은 **page fault**를 만든다. 페이지 테이블로 번역하는 과정에서, 페이징 하드웨어는 invalid 비트가 세팅되었고, 운영체제로 하여금 트랩하게한다. 이 트랩은 메모리에서 원하는 페이지를 가져오지 못한 운영체제의 실패이다. 페이지 폴트를 해결하는 과정은 직관적이다.

1. 이 프로세스에서의 참조가 valid인지 아닌지 결정하는 내부 테이블을 체크한다.(PCB에 저장되어있음)
2. 만약 invalid라면, 우리는 프로세스를 종료한다. 만약 valid인데 페이지로 가져오지 않았다면, 페이지를 가져온다.
3. 여유있는 프레임을 찾는다.
4. 우리는 2차 저장소 명령어를 원하는 페이지를 새롭게 할당된 프레임에 넣기 위해서 읽는다.
5. 저장소 읽기가 완료되면, 우리는 프로세스가 가진 내부 테이블을 수정하고 페이지 테이블이 메모리에 페이지가 있다고 알린다.
6. 우리는 트랩에 의해서 인터럽트된 명령어를 다시 시작한다. 프로세스는 그것이 원래 메모리에 있던 것처럼 페이지에 접근한다.

극단적인 케이스에서, 우리는 메모리에 페이지 없이 프로세스를 실행할 수 있다. 운영체제가 명령어 포인터를 프로세스의 메모리에 상주하지 않는 페이지의 첫 명령어를 지정하면, 프로세스는 즉각적으로 페이지를 폴트한다. 페이지가 메모리로 가져와진후에, 프로세스는 실행을 모든 페이지가 메모리에 필요할때까지 지속한다. 이 점에서, 그것은 아무런 폴트 없이 실행가능하다. 이 구조는 **pure demand paging**이라고한다. 페이지가 필요할때까지 절대로 메모리에 가져오지 않는다.

이론적으로, 몇몇 프로그램들은 각 명령어 실행마다 메모리의 새로운 페이지에 접근할 수 있는데, 명령어 별로 다중 페이지 폴트를 유발한다. 이 상황을 시스템 성능에서 용납할수없는 성능을 만들어낸다. 다행히도, 실행중인 프로세스의 분석은 이 행동이 매우 예상 밖이라는 것을 보여준다. 프로그램은 **locality of reference**를 하는 경향이 있고, 디맨드 페이징의 의미있는 성능을 결과로 낸다. 

디맨드 페이징을 지원하는 하드웨어는 페이징, 스와핑의 것과 같다. 
- 페이지 테이블 : 이 테이블은 valid-invalid 비트또는 특별한 보호비트의 값을 통해서 엔트리가 invalid인지 마크할 능력이 있다.
- 2차 메모리 : 이 메모리는 메인 메모리에 없는 페이지를 잡고있다. 2차 메모리는 보통 빠른 디스크 또는 NVM 디바이스이다. 이것은 swap device로 알려져 있고, 저장소의 공간은 **swap space**라는 목적으로 사용된다. Swap-space 할당은 11장에서 언급된다.

디맨드 페이징의 필요는 페이지 폴트 이후에 어떤 명령어든 다시 실행할 능력이다. 우리는 페이지 폴트가 일어났을때 인터럽트된 프로세스의 상태(레지스터, 컨디션 코드, 명령어 카운터)를 저장하고, 우리는 반드시 프로세스를 같은 장소와 상태로 재시작해야한다. 페이지 폴트는 메모리 레퍼런스에서 언제든 일어날 수 있다. 만약 페이지 폴트가 명령어 패치에서 일어나면, 우리는 명령어를 다시 패치하면된다. 만약 페이지 폴트가 피연산 함수 패칭 중에 일어나면, 우리는 명령어를 다시 패치하고 디코드하고 피연산 함수를 패치해야한다.

최악의 예제로, 3가지 명령어, ADD A to B한 결과를 C에 배치한다고 고려하겠다. 이 명령어에는 다음과 같은 과정이 필요하다.
1. ADD 명령어를 실행하고 해석한다.
2. A를 가져온다.
3. B를 가져온다.
4. A와 B를 더한다.
5. 합을 C에 저장한다.

만약 페이지 폴트가 C를 저장하는 중에 생기면(왜냐하면 C는 현재 메모리에 없다.), 우리는 원하는 페이지를 가져와야하고, 페이지 테이블을 조정하고, 명령어를 재시작해야한다. 재시작은 명령어 패칭, 디코딩, 연산자 패칭, 더하기를 다시하게 할 수 있다. 그러나, 반복된 일은 많지 않고, 반복은 오직 페이지 폴트가 생겼을떄만 필요하다.

이 문제는 두가지 방법으로 해결이 가능하다. 한가지는 마이크로 코드 컴퓨터와 두 블럭 사이의 두 끝을 연결하려는 시도이다. 만약 페이지 폴트가 일어나려고하면, 그것은 무언가 수정되기전에 이 단계를 거치다.이동이 공간을 차지할 수도 있다. 우리는 모든 관련 페이지가 메모리에 있다면 아무런 페이지 폴트가 일어나지 않은 것을 알고 있다. 다른 방법은 덮어쓰기 당할 공간의 값을 임시 레지스터에서 잡고있는 것이다. 만약 페이지 폴트가 일어나면, 모든 구식 값들은 트랩이 생기기전에 메모리에 덮인다. 이 행동은 명령어가 실행하기 전의 상태로 메모리를 복구한다. 그래서 명령어는 다시 실행한다.

이것은 디맨드 페이징을 허용하기 위해서 존재하는 아키텍처에 페이징을 더한것인데, 많은 어려움이 포함되어있다. 페이징은 컴퓨터 시스템의 CPU와 메모리 사이에 있다. 그것은 프로세스에 완벽히 명백해야한다. 비록 디맨드 페이징이 없는 환경에서의 가정은 사실이지만, 페이지 폴트는 페이탈 에러를 의미한다. 페이지 폴트가 오직 추가적인 페이지를 메모리에 가져오고 프로세스를 재시작하는 것은 사실이 아니다.

### 10.2.2 프리프레임 리스트

페이지 폴트가 일어나면, 운영체제는 반드시 원하는 페이지를 2차 저장소에서 메모리로 가지고 와야한다. 페이지 폴트를 해제하기 위해서, 대부분의 운영체제는 이런 요청을 만족시키는 프리 프레임의 풀인 **free-frame list**를 사용한다.(프리 프레임은 반드시 스택 또는 힙 세그먼트가 확장할때 할당되어야한다.) 운영체제는 일반적으로 **zero-fill-on-demand**라는 기술로 여유프레임을 할당한다. Zero fill on demand frames들은 할당되기전에 "zeroed out" 된다. 그러므로, 그들의 이전 정보를 삭제한다.(이 컨텐츠들을 재할당하기전에 지우지 않으면 생길 보안적인 측면을 고려하자.)

시스템이 시작되면, 모든 가용 메모리는 프리 프레임 리스트에 오른다. 프리 프레임이 요청되면, 그 크기만큼의 리스트는 줄어든다. 몇몇 관점에서, 리스트는 0으로 떨어지거나 특정 스레시홀드로 떨어진다. 우리는 이 전략을 10.4에서 더 자세히 보겠다.

### 10.2.3 디맨드페이징의 성능

디맨드 페이징은 컴퓨터 시스템의 성능에 큰 영향을 끼쳤다. 왜인지 보기위해서 디맨드 페이지 메모리에서의 **effective access time**을 측정해보자. 메모리 액세스 시간(ma)가 10나노초이다. 페이지 폴트가 없다면, 유효 접근 시간은 메모리 접근시간과 같을 것이다. 만약, 페이지 폴트가 일어나면, 우리는 반드시 2차 저장소로부터 페이지를 읽고 원하는 word에 접근해야한다.

페이지 폴트 확률을 p라고 하겠다. 우리는 p가 0에 가깝다고 예상하면 유효 시간은 `effective access time = (1-p)\*ma + p \*page fault time`이 될 것이다. 유효 접근 시간을 측정하기 위해서, 우리는 페이지 폴트에 얼마나 시간이 걸리는지 봐야한다. 페이지 폴트는 다음 순서로 일어난다.
1. 운영체제를 트랩한다.
2. 레지스터와 프로세스 상태를 저장한다.
3. 인터럽트가 페이지 폴트인것을 결정한다.
4. 페이지 레퍼런스가 적합한지 확인하고 2차 저장소에 있는 페이지의 위치를 결정한다.
5. 여유 프레임인 저장소를 읽는다.
   1. 리드 리퀘스트가 서비스 될떄까지 큐에서 기다린다.
   2. 디바이스 찾기와 레이턴시 시간을 기다린다.
   3. 페이지를 프리 프레임에 전송하기 시작한다.
6. 기다리면서, CPU 코어는 다른 프로세스를 할당한다.
7. 저장소 I/O 서브시스템으로부터 완료 인터럽트를 받는다.
8. 다른 프로세스의 레지스터와 프로세스 상태를 저장한다.
9. 인터럽트가 2차 저장소로 온것을 결정한다.
10. 페이지 테이블을 수정하고 원하는 페이지가 메모리에 있다는 것을 보인다.
11. CPU 코어가 이 프로세스를 할당하기를 기다린다.
12. 레지스터, 프로세스 상태, 새로운 페이지 테이블을 복구하고, 인터럽트된 명령어부터 재시작한다.

모든 스텝이 항상 필요하지는 않다. 예를 들어서, 우리는 6번 과정에서, CPU가 I/O 실행시 다른 프로세스를 할당했다고 했다. 이 나열은 CPU 효율을 높이지만 페이지 폴트 서비스 루틴의 시간을 늘린다. 어떤 경우이든, 3가지 페이지 폴트는 반드시 일어난다.
1. 페이지 폴트 인터럽트 서비스
2. 페이지 읽기
3. 프로세스 재시작

첫번째와 세번쨰 태스크는 감소될수 있다. 이런 태스크들은 1~100 마이크로초가 걸린다. HDD가 페이징 디바이스로 쓰인다고 가정하자. 페이지 스위치 시간은 8미리초일 것이다.(하드 디스크는 보통 3미리초의 지연시간, 5미리초의 탐색, 0.05미리초의 전송시간을 가진다.) 우리는 디바이스 서비스 시간만 살펴보았다. 만약 프로세스의 큐가 디바이스를 기다리면, 우리는 우리의 서비스 시간에 페이징 디바이스가 여유로울 떄까지의 큐잉 시간을 더해야하고, 페이지 인에 시간을 더욱 투자한다.
페이지 폴트 시간이 8미리초이고 메모리 엑세스 시간이 200나노초라면, 나노초 기준에서의 유효 접근시간은 다음과 같다.
`effective access time = (1-p) \* 200 + p (8milliseconds) = 200 + 7999800 \* p`
우리는 이로서 유효 접근 시간이 **page fault rage**에 비례함을 알 수 있다. 만약 1000번중에서 1번 페이지 폴트가 일어나면, 8.2 마이크로 초 일 것이다. 기존의 시간보다 무려 40배나 긴것이다. 만약 성능 하락을 10퍼센트 이내로 바꾸려면 우리는 p가 0.0000025의 비율이어야할 것이다. 즉 페이징으로 인한 성능 하락을 없애려면 우리는 사십만번중에 한번의 페이지 폴트를 만들라는 것이다. 디맨드 페이징 시스템에서 페이지 폴트를 낮게하는 것은 중요하다. 그렇지 않으면, 유효 접근 시간은 증가하고, 프로세스 실행은 엄청나게 느려진다.

디맨드 페이징의 추가적인 면은 스왑 공간의 핸들링과 전체 사용이다. I/O에서 스왑 공간은 일반적인 파일 시스템보다 빠르다. 스왑공간이 더욱 큰 블럭에 할당되었고 파일 룩업과 간접 할당 메서드가 사용되지 않아서 더욱 빠르다.(11장) 더좋은 페이징 산출량을 얻기위한 옵션은 프로세스가 시작할때 전체 파일 이미지를 복사하고 스왑공간으로부터 디맨드 페이징을 실행하는 것이다. 이 방법의 단점은 프로그램이 시작할때 파일이미지를 복사하는 것이다. 두번째 옵션이자 윈도우/리눅스에서 사용되는 방법은 디맨드 페이지를 파일 시스템 그대로 사용하다가 그들이 교체되면 스왑 공간으로 쓰는 것이다. 이 접근은 오직 필요한 페이지들을 파일 시스템으로부터 읽게하고 다음 페이징들은 스왑공간에서 하게한다.

몇몇 시스템들은 바이너리 실행 파일의 디맨드 페이징을 통해서 스왑 공간의 양을 제한했다. 이런 파일의 디맨드 페이지는 파일 시스템으로부터 직접 가져왔다. 그러나, 페이지 교체가 불리면, 이런 프레임들은 덮여쓰이고 페이지들은 필요할때 다시 파일시스템에서 읽어온다. 이 접근을 사용하면, 파일 시스템 자체는 배킹 스토어처럼 사용된다. 그러나, 스왑 공간은 반드시 파일(**anonymous memory**로 알려짐)과 관련되지 않은 페이지를 사용해야한다.(이런 페이지들은 프로세스의 힙과 스택을 포함한다.) 이 메서드는 좋은 타협점이고 리눅스와 BSD UNIX에서도 사용된다.

9.5.3에서 설명했듯이, 모바일 시스템은 스와핑을 지원하지 않는다. 대신에, 이러한 시스템들은 메모리가 제한되면 파일 시스템으로 부터 페이지를 요청하고 읽기 전용 페이지를 재정의한다. 이런 데이터는 파일 시스템으로부터 디맨드 페이지드 될수 있다. iOS에서는, 익명 메모리 페이지는 앱이 종료되거나 메모리에서 해제되기 전까지는 결코 재정의되지 않는다. 10.7절에서는, 우리는 모바일 시스템에서 스와핑의 대용으로 쓰이는 압축 메모리를 보겠다.

