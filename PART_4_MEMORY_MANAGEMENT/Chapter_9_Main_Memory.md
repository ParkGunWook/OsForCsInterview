## what we gonna study

5장에서, 우리는 CPU가 어떻게 프로세스의 집합들에서 공유되는지 보였다. CPU 스케쥴링의 결과로, 우리는 CPU의 효율성과 유저로부터의 컴퓨터 반응 속도를 모두 향상시켰다. 이 성능의 증가를 느끼기위해서, 우리는 메모리에 많은 프로세스를 보관해야한다, 즉 우리는 반드시 메모리를 공유해야한다.

이 장에서, 우리는 메모리를 관리하는 다양한 방법을 논의하겠다. 메모리 관리 알고리즘은 기계적 접근부터 페이징과 같은 전략 사용이 있다. 각각의 접근은 장점과 단점을 가지고 있다. 특정 시스템을 위한 메모리 관리 메서드의 선택은 시스템의 하드웨어 디자인과 특히 관련이 있다. 우리는 대부분의 알고리즘이 하드웨어 지원이 필요하고, 많은 시스템들이 하드웨어와 운영체제 메모리 관리의 통합하는 것을 볼 것이다.

## Objectives

- 물리적, 논리적 주소 사이의 차이와 Memory management unit(MMU)의 주소 번역 역할을 설명한다.
- 연속적 메모리 할당의 first-, best-, worst-fit 전략을 적용한다.
- 내부와 외부 단편화의 차이를 설명한다.
- Translation look-aside buffer(TLB)를 포함한 페이징 시스템속의 논리->물리적 주소 번역을 살펴본다.
- 계층적 페이징, 해쉬 페이징, inverted page tables를 본다.
- IA-32, x86-64, ARMv4 구조의 번역을 설명한다.

## 9.1 Background

1장에서 보았듯이, 메모리는 운영체제 시스템의 명령어에 집중한다. 메모리는 거대한 바이트의 행렬을 포함하고, 각각의 주소를 가진다. CPU는 명령어를 매모리로부터 프로그램 카운터의 값에 따라서 가지고 온다. 이런 명령어들은 특정한 메모리 주소로부터 로딩하고, 주소에 저장한다. 

전형적인 명령어 실행 주기는, 먼저 메모리로부터 명령어를 가지고 온다. 명령어는 해독되고 메모리로 부터 피연산함수를 가지고 오게한다. 명령어가 피연산함수에서 실행된 후에, 결과는 다시 메모리에 저장된다. 메모리 유닛은 오직 메모리 주소의 스트림만 본다. 그것은 그들이 어떻게(명령어 카운터, 인덱싱, 비간접, 리터럴 주소 등) 생성되었는지를 모르고, 그들이 무엇(명령어, 데이터)을 위해서 생성되었는지 모른다.  이에 따라서, 우리는 프로그램이 어떻게 메모리 주소를 생성했는지 무시해도 된다. 우리는 오직 프로그램을 실행하면서 생긴 메모리 주소의 시퀀스만 보면된다. 

우리는 우리의 논의를 메모리 관리에 적절한 이슈를 살펴보겠다. 기초 하드웨어, 심벌릭(가상) 메모리 주소에서 실제 물리주소, 논리와 물리 주소의 차이가 있을 것이다. 우리는 이 절의 마무리를 동적 링킹과 공유 라이브러리로 결론 짓겠다.

### 9.1.1 기초 하드웨어

각 프로세싱 코어 속에 내장된 메인 메모리와 레지스터는 CPU만 직접 접근 가능한 저장소이다. 메모리 주소를 인자로 받는 기계 명령어는 있지만, 디스크 주소를 받는 것은 없다. 그러므로, 실행중인 명령어, 명령에 사용되는 데이터는 반드시 이 직접 접근 저장 장치에 있어야한다. 만약 데이터가 메모리에 없으면, 그들은 CPU가 실행하기전에 반드시 이동되어야한다.

각 CPU에 내장된 레지스터는 CPU 클락의 한번의 사이클로 보통 접근이 가능하다. 몇몇 CPU 코어들은 래지스터 내용물의 명령어 해독과 간단한 명령어는 클락 틱의 한번에 보통 해결가능하다. 메모리에서는 같지 않을 것인데, 접근이 메모리 버스의 트랜잭션으로 이루어지기 때문이다. 메모리 엑세스 완료는 CPU 클락의 몇 사이클이 걸릴 수도 있다. 이런 경우에는, 프로세서는 보통 **stall**이 필요한데, 그것은 실행중인 명령어를 완료하는데 데이터를 필요로하지 않기 때문이다. 이 상황은 편협적인데, 메모리 접근의 주기 때문이다. 그 치료는 CPU와 메인 메모리 사이의 빠른 메모리를 추가한다. 이런 캐시는 1.5.5에서 설명했다. CPU의 내장 캐시를 관리하려면, 하드웨어는 자동적으로 운영체제의 관리 없이 메모리 접근의 속도를 올려야한다.(5.5.2에서 메모리 스톨을 설명했고, 멀티 스레드 코어가 스톨된 하드웨어 스레드에서 다른 하드웨어 스레드로 교체하는 것이다.) 

물리 메모리의 상대적인 속도에 대한 고려뿐만 아니라, 우리는 적절한 명령을 해야한다. 적절한 시스템 명령을 위해서, 우리는 반드시 운영체제로부터 유저 프로세스로의 접근을 막아야한다. 물론 유저 프로세서끼리의 접근도 마찬가지이다. 이 보호는 반드시 하드웨어에 의해서 제공되어야하는데, 운영체제는 CPU와 그것의 메모리 접근사이에 개입하지 않기 때문이다. 하드웨어는 이 생산을 몇가지 다른 방식으로 구현하고, 이 챕터에서 보일 것이다. 여기서, 우리는 한가지 가능한 구현을 보이겠다.

우리는 먼저 각 프로세스가 개별의 메모리 공간을 가지게 한다. 프로세스 메모리 공간별 구분은 프로세스끼리를 보호하고 동시 실행을 위한 다양한 프로세스 메모리 적재를 위해서 기초적이다. 메모리 공간을 분리하기 위해서, 우리는 프로세스가 오직 그 프로세스만이 접근가능한 법적 허용 주소를 가지고 있어야한다. 우리는 이 보호를 두개의 레지스터를 사용해서 제공하고, 보통은 베이스와 리미트가 있다. **base register**는 합법 물리 메모리 주소의 가장 작은 값을 가지고, **limit memory**는 범위의 크기를 정의한다. 예를 들어서, 만약 기본 레지스터가 300040이고 리미트 레지스터가 120900이면, 프로그램은 30040부터 420939까지 접근이 가능하다.

메모리 공간의 보호는 유저모드에서 생성된 모든 주소를 비교해서 CPU 하드웨어를 가지는 것으로 완료된다. 유저모드에서 실행하는 프로그램의 운영체제 메모리 또는 다른 유저의 메모리 접근은 어떤 시도든 운영체제에 의해서 트랩되고, 치명적인 오류로 다루어진다. 이런 구조는 유저 프로그램이 운영체제나 다른 유저의 코드나 데이터 구조를 변조하는 것을 방지한다.

베이스와 리미트 레지스터는 오직 운영체제에 의해서만 로드되는데, 특별한 우선순위 명령어를 사용한다. 우선 순위 명령어는 커널 모드에서만 실행 가능하고, 운영체제만이 베이스와 리미트 레지스터를 로딩한다. 이 구조는 운영체제가 레지스터의 값을 바꾸는 것을 허용하면서 유저 프로그램이 레지스터의 컨텐츠를 바꾸는 것을 방지한다.

운영체제에서, 커널모드로 실행하는 것은, 운영체제 메모리와 유저 메모리의 통제되지 않은 접근을 준다. 이 공급은 운영체제가 유저의 프로그램을 유저의 메모리에 담게 해주고, 에러인 프로그램을 덤프아웃시키고, 시스템콜의 파라미터를 접근하고 수정하고, 유저 메모리로부터 I/O를 실행하고, 다양한 서비스를 제공한다. 예를 들어서, 멀티 프로세싱 시스템 시스템은 반드시 컨텍스트 스위치를 실행한다. 다음 프로세스의 컨텍스트가 메인메모리에서 레지스터로 로딩되기 전에 한가지 프로세스의 상태를 레지스터에서 메인메모리에 저장한다.

## 9.1.2 Address Binding

일반적으로, 디스크에 바이너리 실행파일로 프로그램은 자리잡고 있다. 실행하기 위해서, 프로그램은 반드시 메모리로 가지고 와야하고 가용한 CPU의 실행을 할 수 있는 프로세스의 컨텍스트에 위치해야한다. 프로세스가 실행되면, 그것은 메모리로부터 명령어와 데이터에 접근한다. 마침내, 프로세스가 종료되면, 그것의 메모리는 다른 프로세스의 사용을 위해 재정의된다.

대부분의 시스템은 유저 프로세스가 물리 메모리에 거주하게 허용한다. 그러므로, 비록 컴퓨터의 주소 공간이 00000에서 시작해도, 유저 프로세스의 시작 주소는 00000일 필요가 없다. 너는 어떻게 운영체제가 실제로 물리 메모리에 프로세스를 배치하는지 볼 것이다.

대부분의 사례에서, 유저 프로그램은 몇가지 단계를 거쳐가고, 몇몇은 실행전에 선택지가 있다. 주소는 이런 스템 동안 다른 방법으로 대표된다. 컴파일러는 대개 이런 심볼릭 주소를 relocatable 주소(모듈의 시작으로부터 14바이트)로 **binds**한다. 링커 또는 로더(2.5절)는 relocatable 주소를 절대 주소로 **binds**한다. 각 바인딩은 한가지 주소공간을 다른 것으로 매핑한다.

전통적으로, 명령어와 데이터의 바인딩부터 메모리 주소는 다음 방법으로 실행된다.

- Compile time. 만약 너가 프로세스가 거주할 메모리인 컴파일 시간을 알면, **absolute code**는 생성될 수 있다. 예를 들어서, 만약 너가 유저 프로세스가 위치 R로부터 시작하는 것을 알면, 생성된 컴파일러 코드는 그 주소에서 시작하고 그 주소에서 확장될 것이다. 만약, 어느정도 후에, 시작 점이 바뀌면, 그것은 이 코드를 반드시 리컴파일 해야한다.
- Load time. 만약 compile time을 모르면, 컴파일러는 **relocatable code**를 생성해야한다. 이런 경우에, 마지막 바인딩은 로드 타임까지 지연된다. 만약 시작 주소가 바뀌면, 너는 이 변화에 맞지 않게 바뀐 유저코드를 다시 로드해야한다.
- Excution time. 만약 프로세스가 그것의 실행중에 다른 메모리 세그먼트로 이동하면, 바인딩은 반드시 런타임까지 지연되어야한다. 특별한 하드웨어가 이 구조에 적합하고 9.1.3에서 다루겠다. 대부분의 운영체제가 이 방법을 사용한다.

이 장의 가장 큰 부분은 어떻게 다양한 바인딩이 컴퓨터 시스템에서 구현되는 것을 보여주고 적절한 하드웨어 지원을 토론한다.

### 9.1.3 논리적-물리적 주소 공간

CPU에 의해서 만들어진 주소는 **logical address**라 불리고, 메모리 유닛에 의해서 관측되는, 메모리의 **memory-adress register**에 저장되는 것은 **physical address**라고 불린다. 

컴파일러 또는 로드 타임에 생성된 바인딩 주소는 동일한 논리와 물리 주소를 생성한다. 그러나, excution time 주소 바인딩 구조는 다른 논리와 물리 주소를 가진다. 이런 경우에, 우리는 논리적 주소를 **virtual address**라고 부른다. 우리는 논리 주소와 가상 주소를 교차해서 부를 것이다. 프로그램에 의해 생성된 논리적 주소의 집합은 **logical address space**라고 불린다. 그러므로, 실행 시간 주소 바인딩 구조는 논리와 물리 주소 공간이 달라진다. 

가상에서 물리 주소로의 런타임 매핑은 **memory management unit(MMU)**라고 불리는 하드웨어 기기에 의해서 진행된다. 우리는 9.2절에서 9.3절까지 언급할 다양한 메서드를 이런 매핑을 위해서 선택해야한다. 우리는 MMU 구조로하는 매핑을 9.1.1에서 언급한 베이스 레지스터 구조의 일반화라고 한다. relocation 레지스터의 값은 유저 프로세스에 의해서 생성되는 모든 주소가 메모리로 보내지면 추가된다. 예를 들어서, 베이스가 14000이면, 0이라는 주소는 동적으로 14000에 배치되고, 346 주소로의 접근은 14346이 된다.

유저 프로그램은 절대로 실제 물리 주소에 접근하지 않는다. 프로그램은 346이라는 장소로 포인터를 생성하지만, 메모리에 저장하고, 조정하고, 그것을 다른 주소와 비교한다. 오직 그것이 메모리 주소(간접적인 로드 또는 저장)으로 사용될 때만, 그것은 베이스 레지스터에 맞게 재배치된다. 유저 프로그램은 오직 논리적 주소와 비교한다. 메모리 매핑 하드웨어는 논리적 주소를 물리적 주소로 바꾼다. 실행시간 바인딩의 형태는 9.1.2에서 언급되었다. 언급된 메모리 주소의 마지막 장소는 레퍼런스가 만들어지기 전까지 결정되지 않는다.

우리는 이제 두가지 다른 주소의타입을 가졌다. 논리적 주소(0부터 최대치)와 물리적 주소(R+0부터 R+최대치). 유저 프로그램은 오직 논리적 주소를 생성하고 프로세스가 메모리 위치에서 실행한다고 생각한다 그러나 이러한 논리적 주소는 반드시 사용되기전에 물리적 주소에 매핑되어야한다. 논리 주소의 개념은 분리된 물리적 주소 공간에 적절한 메모리 관리를 위해서 집중한다.

### 9.1.4 동적 로딩

우리의 논의에서, 모든 프로그램과 모든 프로세스의 데이터가 프로세스를 실행하기 위해서 필수적이라고 했다. 프로세스의 크기는 그러므로 물리적 메모리의 크기에 제한적이다. 더 나은 메모리 공간 활용을 위해서 우리는 **dynamic loading**을 사용한다. 동적 로딩과 함께, 루틴은 그것이 불리기 전까지 로드되지 않는다. 모든 루틴은 디스크에 재할당가능한 로드 형식으로 보존된다. 메인 프로그램은 메모리에 로드되고 실행된다. 루틴이 다른 루틴을 부를때, 루틴을 부르는 것은 우선 다른 루틴이 로드되었는지 먼저 확인한다. 만약 그렇지 않으면, 재할당 가능한 링킹 로더가 원하는 루틴을 메모리에 부르기 위해서 로드하고 프로그램의 주소를 변경사항 반영을 위해서 업데이트한다. 그때부터 새롭게 로드된 루틴으로 제어가 넘어간다.

다이나믹 로딩의 장점은 루틴이 오직 필요할 때만 로드되는 것이다. 이 메서드는 큰 코드가 가끔 일어나는 에러 루틴 같은 것을 처리하는데 특히 유용하다. 이런 상황에서, 비록 전체 프로그램의 크기는 크지만, 사용되는 부분은 훨씬 작을 수 있다.

동적 로딩은 운영체제로부터 특별한 지원을 요구하지 않는다. 그것은 유저가 이 방법의 이점을 위해서 프로그램을 디자인하는 것에 달려있다. 운영체제는 프로그래머를 도울수도 있지만, 동적 로딩을 돕기위해서 라이브러리 루틴을 제공할 뿐이다.

### 9.1.5 Dynamic linking과 공유 라이브러리

**Dynamically linked libraries(DLLs)**는 유저 프로그램이 실행될때 유저 프로그램에 연결되는 시스템 라이브러리이다. 몇몇 운영체제는 오직 시스템 라이브러리가 다른 객체 모듈을 연결하는 것처럼 취급되고 로더에 의해서 바이너리 프로그램 이미지로 합치는 **static linking**을 지원한다. 동적 링킹은 반대로, 동적 로딩과 비슷하다. 여기서, 비록 링킹은 로딩보다 실행시간까지 지연된다. 이 기능은 보통 C 스탠다드 라이브러리 같은 시스템 라이브러리로 사용된다. 이런 기능 없이, 시스템의 각 프로그램은 반드시 그것의 언어 라이브러리 카피를 실행 이미지에 포함해야한다.(또는 적어도 프로그램에 의해서 루틴이 참조되어야한다.) 이 필요는 실행 이미지의 크기를 키울뿐 아니라 메인메모리를 낭비한다. DLLs의 두번째 장점은 라이브러리가 다양한 프로세스에 의해서 공유될 수 있고, 그래서 메인 메모리의 DLL의 인스턴스가 하나만 있다. 이런 이유로, DLLs는 **shared libraries**라고 불리고, 윈도우와 리눅스 시스템에서 널리 사용된다.

프로그램이 동적 라이브러리의 루틴을 참조하면, 로더는 DLL을 메모리에 배치한다. 그것은 DLL의 주소가 저장된 메모리의 주소로 동적 라이브러리의 함수를 참조하는 주소를 조정한다. 

동적 링크드 라이브러리는 라이브러리 업데이트에도 확장가능하다. 추가적으로, 라이브러리는 새로운 버전에 의해서 대체될 수 있고, 라이브러리를 참조하는 모든 프로그램은 자동적으로 새로운 버전에 사용될 수 있다. 동적 링킹없이, 모든 프로그램은 새로운 라이브러리에 접근하기 위해서 다시 링크될 필요가 있다. 그래서 프로그램은 새롭고 적합하지 않은 라이브러리의 버전을 실행하지 않고, 버전 정보는 프로그램과 라이브러리에 모두 포함될 것이다. 한가지 이상의 버전을 가진 라이브러리가 메모리에 로드될 수 있고, 각 프로그램은 어떤 라이브러리의 카피를 쓸지 선택해야할 것이다. 새로운 라이브러리가 설치되기전에 링크된 프로그램은 구식의 라이브러리를 계속 지원할 것이다.

동적 로딩과 다르게, 동적 링킹과 공유 라이브러리는 보통 운영체제의 도움이 필요하다. 만약 메모리의 프로세스가 다른 것으로 보호되면, 운영체제는 필요한 루틴이 다른 프로세스의 메모리 공간에 있는지 다양한 프로세스가 같은 메모리에 접근하는 것을 확인해주는 유일한 엔티티이다. 우리는 이 개념을 9.3.4절의 페이징 설명하면서 DLL이 어떻게 프로세스들끼리 공유되는지 정밀하게 말해주겠다.

## 9.2 연속적 메모리 할당

메인 메모리는 반드시 운영체제와 다양한 유저 프로세스를 수용해야한다. 우리는 그러므로 가장 효율적인 방법으로 메인메모리에 할당할 필요가 있다. 이 절에서는 연속 메모리 할당이라는 초기의 메서드를 설명하겠다. 멤리는 보통 두가지 파티션으로 나뉘어져 있다. 하나는 운영체제 그리고 하나는 유저 프로세스이다. 우리는 운영체제를 낮은 메모리 주소 또는 높은 메모리 주소에 배치할 수 있다. 이 결졍은 인터럽트 벡터의 위치같은 다양한 요소에 달려있다. 그러나 리눅스와 윈도우는 운영체제를 높은 메모리 주소에 배치한다.

우리는 보통 몇가지 유저 프로세스를 동시에 메모리에 배치하기를 원한다. 우리는 그러므로 메모리에 가기를 기다리는 프로세스가 메모리에 어떻게 할당되는지 고려한다. **Contiguous memory allocation**에서 각 프로세스는 다음 프로세스에 연속적인 메모리의 단일 구역에 포함된다. 메모리 할당 구조에 대해서 논의하기전에, 우리는 반드시 메모리 보호의 이슈에 대해서 말해야한다.

### 9.2.1 메모리 보호

우리는 이전에 말한 두가지 아이디어를 홉합해서 프로세스가 가지지 않은 메모리 접근을 방지한다. 만약 우리가 재위치 레지스터, 리미트 레지스터를 가진 시스템이면, 우리는 우리의 목적을 달성했다. 재위치 레지스터는 가장 작은 물리적 주소를 가지고 리미트 레지스터는 논리 주소의 범위를 가진다. 각각의 논리 주소는 반드시 지정한 리미트 레지스터의 범위에 있어야한다. MMU는 논리적 주소를 재위치 레지스터에 더함으로서 동적으로 매핑한다. 이 매핑된 주소는 메모리로 보내진다.

CPU 스케쥴러가 실행할 프로세스를 선택하면, 디스패처는 재위치와 리미티 레지스터를 컨텍스트 스위치의 정확한 값에 로드한다. CPU에 의해서 생성된 모든 주소가 이런 레지스터에 의해서 체크되기 때문에, 우리는 운영체제와 다른 유저의 프로그램이 서로의 자료를 보호한다.

재위치 레지스터 구조는 운영체제의 크기를 동적으로 변하게하는 효과적인 방법을 제공한다. 이 유연성은 많은 상황에서 이상적이다. 예를 들어서, 운영체제는 디바이스 드라이버에 대한 코드와 버퍼 공간이 존재한다. 만약 디바이스 드라이버가 사용중이 아니면, 굳이 메모리에 둘 필요가 없다. 대신에, 그것은 오직 필요할때만 메모리에 두면 된다. 이와 같이 디바이스 드라이버가 필요하지 않으면, 그것은 제거되고 그것의 메모리는 다른 필요한 것으로 대체된다.

### 9.2.2 메모리 할당

이제 우리는 메모리 할당을 보겠다. 메모리 할당의 가장 단순한 방법은 메모리에 맞게 파티션된 프로세스를 할당하는 것이고, 각 파티션은 정확히 하나의 프로세스를 가지다. **Variable partition** 구조에서 운영체제는 현재 메모리에 가용하고 할당된 부분을 가르키는 테이블을 유지한다. 처음에는, 모든 메모리는 유저 프로세스에 존재하고 가용한 메모리의 큰 블럭을 고려된다(**hole**). 마침내, 메모리는 다양한 크기의 홀의 집합이 된다.

프로세스가 시스템에 진입하면, 운영체제는 각 프로세스의 메모리 필요량과 프로세스가 할당될 가용 메모리 공간을 계산한다. 프로세스가 공간에 할당되면, 그것은 메모리에 로드되고, CPU 시간을 경쟁한다. 프로세스가 종료되면, 그것은 운영체제가 다른 프로세스를 제공할 메모리를 해제한다.

만약 도착 프로세스에 대한 수요를 만족할 충분한 공간이 없으면 어떤 일이 생기는가? 한가지 옵션은 단순히 프로세스를 거절하고 에러메시지를 제공하는 것이다. 대안으로는, 우리는 대기 큐에 넣을 수도 있다. 메모리가 해제되면 운영체제는 대기 큐를 확인한다.

일반적으로, 말했듯이, 가용 메모리 블럭은 메모리에 있는 다양한 홀의 집합으로 구성된다. 프로세스가 도착하고 메모리를 필요로 하면, 시스템은 프로세스에게 충분히 맞는 홀을 집합에서 탐색한다. 만약 홀이 너무크면, 그것은 두 파트로 쪼갠다. 한 파트는 도착한 프로세스로 할당하고 나머지는 홀의 집합에 리턴한다. 프로세스가 종료하면, 그거은 메모리의 블럭을 해제하고, 홀의 집합에 돌려준다. 만약 새로운 홀이 다른 홀에 인접하면, 이 인접홀은 하나의 큰 홀로 합쳐지나.

이런 진행은 일반적인 **dynamic storage allocation problem**의 인스턴스이고, 여유 홀의 리스트에서 요청의 사이즈 n을 만족시키는 것을 고려한다. 이 문제에는 여러가지 솔루션이 있다. **best-fit**, **first-fit**, **worst-fit**이 일반적인 전략이다.

- First fit. 할당가능한 첫번째 홀에 할당한다. 서칭은 홀의 시작으로 시작하거나 이전 first-fist 서치가 끝난 지점이 가능하다. 우리는 여유있는 홀을 발견하면 탐색을 중지한다.
- Best fit 할당가능한 가장 작은 홀에 할당한다. 우리는 전체 리스트를 탐색해야한다. 이 전략은 가장 적은 여분 홀을 만든다.
- Worst fit 할당가능한 가장 큰 홀에 할당한다. 다시, 우리는 전체 리스트를 탐색해야한다. 이 전략은 가장 큰 여분 홀을 만들고, 여분은 best-fit 전략의 작은 여분홀 보다 효과적일 수 있다.

시뮬레이션은 first와 best가 worst보다 시간 절약과 공간 활용도에서 낫다고 한다. first와 best는 정확히 어떤게 공간활용도가 좋다는 밝혀지지 않았지만, first가 확실히 시간은 빠르다.

### 9.2.3 단편화

퍼스트와 베스트 핏 전략은 **external fragmentation**에 고통받는다. 프로세스가 메모리에 로드되고 제거되면서, 메모리 공간의 여유분들은 작은 조각으로 분할된다. 외부 단편화는 전체 메모리 공간은 충분한데 가용공간이 연속적이지 않은 것이다. 공간은 작은 공간의 큰 수들로 단편화되있다. 이 단편화 문제는 심각하다. 최악의 경우에는, 우리는 두 프로세스 간에 낭비되는 메모리를 가진다. 만약 모든 메모리의 작은 조각들이 하나의 큰 블럭이면, 우리는 몇가지 프로세스를 더 실행할 수 있다.

우리가 퍼스트 핏과 베스트 핏 전략을 사용하는 것에 따라서 단편화의 양에 영향을 미칠 수 있다.(시스템에 따라서 뭐가 좋은지는 다르다.) 다른 요인은 여유 블럭의 어떤 끝에 할당하는 가이다. 어떤 알고리즘이 사용되든지, 외부 단편화는 문제가 된다.

전체 메모리 공간과 평균 프로세스 크기, 외부단편화에 따라서 단편화는 크거나 작은 문제가 될 수 있다. 퍼스트 핏의 통계적 분석은, 아무리 최적화를 해도 N개의 할당된 블럭은 0.5N의 블럭을 단편화로 일는다. 즉 1/3의 메모리가 쓸수 없어진다. 이런 특성은 **50-percent rule**이라고 한다.

메모리 단편화는 내부화가 될 수도 있다. 다양한 파티션 할당 구조가 18464의 바이트의 홀을 가진다고 가정하겠다. 여기서 다음 프로세스는 18462를 필요로한다. 만약 우리가 정확히 요청한 블럭을 할당하면, 우리는 2바이트의 홀이 생긴다. 이 홀을 유지하면서 추적하는 간접비는 홀 그자체보다 비쌀 것이다. 이런 문제를 회피하는 일반적인 접근은 물리적 메모리를 고정된 사이즈의 블럭으로 나누고 메모리를 블록 사이즈에 맞게 할당하는 것이다. 이런 접근과 함께, 메모리는 요청 메모리보다 약간더 크게 할당한다. 이 두 숫자 간의 차이를 **internal fragmentation**이라고한다. 그리고 파티션의 내부에 존재한다.

외부단편화의 한가지 솔루션은 **compaction**이다. 목적은 메모리 컨텐츠를 이리저리 움직여서 여유 메모리를 하나의 공간에 두는 것이다. 컴팩션은 항상 가능하지는 않다. 만약 재위치가 정적이고 어셈블리 또는 로드 시간에 진행되면, 컴팩션은 실행될 수 없다. 그것은 오직 재위치가 동적이고 실행시간동안에 진행될때 가능하다. 만약 주소가 동적으로 할당되면 재위치는 오직 프로그램과 제이터를 이동하고 베이스 레지스터를 새로운 베이스 레지스터에 반영하면된다. 컴팩션이 가능하면, 우리는 반드시 그것의 비용을 고려해야한다. 가장 단순한 컴팩션 알고리즘은 모든 프로세스를 메모리의 끝으로 향하게하는 것이다. 모든 홀은 다른 방향으로 이동하고, 한개의 큰 가용 메모리 홀을 만든다. 이 구조는 값비싸다.

다른 외부 단편화를 해결하는 솔루션은 프로세스의 논리 주소공간을 비 연속적으로 만드는 것이다. 그러므로, 프로세스를 물리 메모리가 존재할때 항상 배치하는 것이다. 이 전략은 *paging*이라고 불리고, 현대 컴퓨터 시스템의 가장 일반적인 메모리 관리 테크닉이다. 우리는 페이징을 다음 절에서 다루겠다.

단편화는 데이터의 블럭을 다룰때 항상 생긴다. 우리는 이것은 11장부터 15장까지 얘기 하게 될 것이다.

## 9.3 페이징

앞서 말한 메모리 관리는 물리적 주소 공간이 연속적이었다. 우리는 이제 **paging**을 소개할 것인데, 프로세스의 주소 공간이 비 연속적인 것을 허용하는 메모리 관리 구조이다. 페이징은 연속 메모리 할당을 오염시킨 외부 단편화와 컴팩션에 관한 필요를 없앴다. 그것이 많은 장점을 주었기에, 다양항 형태의 페이징은 현재 운영체제의 근간이 되었고, 큰 서버부터 모바일 기기까지 모두 사용된다. 페이징은 운영체제와 컴퓨터 하드웨어 사이의 협력으로 만들어진다.

### 9.3.1 기본 방법

페이징을 구현하는 기본적인 방법은 물리적 메모리를 고정된 사이즈의 **frame**으로 만드는 것과 논리적 메모리를 같은 크기의 **page**로 만드는 것을 포함한다. 프로세스가 실행되었을 때, 그것의 페이지는 그들의 소스로부터 가용한 메모리 프레임으로 로드가 된다. 저장은 메모리 프레임또는 프레임들의 클러스터와 같은 사이즈의 고정된 사이즈의 블록으로 분할된다. 이 간단한 아이디어는 큰 기능성과 넓은 파문을 일으켰다. 예를 들어서, 논리 주소 공간이 이제 완벽히 물리주소 공간과 분리되어있다. 그래서 프로세스는 64비트의 주소 공간을 시스템이 2^64바이트의 물리 메모리공간을 가지지 않아도 가질수 있다.

CPU에 의해서 생긴 주소는 두가지 파트로 나뉠수 있다. **page number(p)**와 **page offset**이다. 페이지 넘버는 프로세스마다 가진 **page table**의 고유의 인덱스로 사용된다. 페이지 테이블은 물리 메모리 프레임의 베이스 주소를 포함하고, 오프셋은 언급된 프레임으로 부터의 거리이다. 그러므로, 프레임의 기본 주소는 물리적 메모리 주소에 정의된 페이지 오프셋과 합쳐진다.

다음의 개요는 MMU가 논리 주소를 물리주소로 해석하는 과정이다.

1. 페이지 넘버를 추출하고 그것을 페이지 테이블의 인덱스로 사용한다.
2. 페이지 테이블로부터 알맞은 프레임 넘버를 추출한다.
3. 페이지 넘버를 프레임넘버로 교체한다.

오프셋은 변하지 않으므로, 교체당하지 않고, 프레임 넘버와 오프셋은 물리적 주소로 구성된다.

페이지 사이즈(프레임 사이즈와 마찬가지로)는 하드웨어에 의해서 정의된다. 페이지의 크기는 2의 제곱승이고, 페이지당 4KB~1GB이고, 컴퓨터 구조에 따라 달라진다. 페이지 크기의 선택은 논리적 주소의 연산을 쉽게 만들 수 있다. 만약에 논리적 주소공간의 크기가 2^m이고 페이지 크기가 2^n이면, m-n의 논리주소가 페이지 넘버를 뜻한다. 그리고 나머지는 페이지 오프셋이 될것이다. 

예시로서, 논리적 주소의 n은 2이고 m은 4라고 하겠다. 페이지 크기가 4바이트이고 물리적 메모리는 32바이트(8페이지)를 쓰면서, 우리는 어떻게 프로그래머 관점의 메모리가 물리 메모리에 매핑되는지 보겠다. 논리 주소 0은 페이지 0에 오프셋 0이다. 페이지 테이블로 인덱싱하면, 우리는 페이지 0이 프레임 5라고 하겠다. 따라서 논리 주소 0은 물리주소 5*4+0으로 가게 될 것이다. 그리고 논리주소 3은 5\*4+3이 될 것이다. 논리주소 4는 페이지 1이 6이라면, 6\*4+0의 물리주소를 갖는 것이다. 

너는 이제 페이징이 동적 재위치와 비슷하다고 느낄 것이다. 모든 논리 주소는 하드웨어 페이징부터 몇몇 물리주소에 갇혀있다. 페이징을 사용하는 것은 베이스(relocation) 레지스터를 사용하는 것과 비슷하다.

우리가 페이징 구조를 사용하면, 우리는 외부 단편화는 일어나지 않는다. 여유있는 프레임은 프로세스가 필요할때마다 사용이 가능하기 때문이다. 그러나, 우리는 내부 단편화가 일어날 수 있다. 프레임은 기본 단위로 할당되는 것때문이다. 만약 프로세스의 메모리 필요가 페이지 바운드와 함께 생기지 않으면, 마지막 할당된 프레임은 가득차지 않을 것이다. 예를 들어서, 만약 페이지 크기가 2048이고 프로세스가 72776바이트이면, 35페이지+1086바이트가 필요할 것이다. 따라서 우리는 36프레임을 할당할 것이고, 962바이트의 내부 단편화를 불러온다. 최악의 경우에는 1바이트가 남아서 한개의 프레임을 사용하게 할 수도있다.

만약 프로세스 크기가 페이지 크기에 독립적이면, 우리는 내부단편화의 평균을 프로세스당 1/2페이지일 것이다. 이 점이 작은 페이지가 이상적이게 한다. 그러나, 각 페이지 테이블 엔트리에서 간접비가 발생하고, 이 간접비는 페이지의 크기가 증가할수록 감소한다. 또한 디스크 I/O는 데이터의 크기가 전송될때 클수록 효율적이다. 일반적으로, 페이지 사이즈는 프로세스, 데이터 집합, 메인 메모리가 커지면서 점점 커지고 있다. 오늘날 페이지는 보통 4KB 또는 8Kb이고, 몇몇 시스템은 더 큰 페이지 사이즈를 지원한다. 몇몇 CPU와 운영체제는 다양한 페이지 크기도 지원한다. 예를 들어서 윈도우 10은 4kB와 2MB를 지원한다. 

32 비트 CPU에서, 각 페이지 엔트리는 4바이트이고, 크기는 다양할 수 있다. 32비트의 엔트리는 2^32개의 페이지 프레임을 가르킬수 있다. 만약 프레임 크기가 4KB이면, 4바이트 엔트리의 시스템은 2^44바이트(16테라바이트)의 물리 공간을 가르킬 수 있다. 우리는 페이지 메모리 시스템의 물리 메모리의 크기는 프로세스의 최대 논리 크기와 다르다는 것을 알아야한다. 페이징을 알아볼 수록, 우리는 페이지 테이블 엔트리에서 반드시 유지되어야할 새로운 정보를 소개할 것이다. 이 정보들은 페이지 프레임을 알려줄 가용한 비트의 숫자를 줄일 것이다. 그러므로, 32비트 페이지 엔트리 시스템은 가능한 최대치보다 적은 물리 메모리를 알릴 수 있다.

프로세스가 시스템에 실행하게 도착하면, 그것의 크기는 페이지에서 표현되고 측정된다. 각 프로세스의 페이지는 하나의 프레임을 필요한다. 그러므로, 만약 프로세스가 n의 페이지를 원하면, 최소 n의 프레임이 메모리에 남아야한다. 만약 n의 프레임이 가용하면, 그들은 프로세스에 할당할 것이다. 프로세스의 첫번째 페이지는 할당된 프레임에 로드되고, 프레임 숫자는 이 프로세스의 페이지 테이블에 넣는다. 다음 페이지는 다른 프레임에 들어가고, 그것의 프레임ㅁ 숫자는 페이지 테이블에 놓인다.

페이징의 중요한 요소는 메모리의 프로그래머의 시점과 실제 물리 메모리 사이의 확실한 분리이다. 프로그래머는 메모리를 하나의 공간으로 보고, 하나의 프로그램만 포함한다. 실제로, 유저 프로그램은 물리 메모리에 흩날려 있으며, 다른 프로그램도 잡고있다. 메모리의 프로그래머의 시점과 실제 물리 메모리의 차이점이 주소 해석 하드웨어에 의해서 조화된 것이다. 논리 주소는 물리 주소로 해석된다. 이 매핑은 프로그래머로부터 숨겨져 있고 운영체제에 의해서 제어된다. 정의에 따르면 유저 프로세스가 소유하지 않은 메모리에 접근하는 것은 불가능하다. 그것은 페이지 테이블의 바깥을 가르키는 방법은 존재하지 않는다. 테이블은 프로세스가 가진 페이지만을 가르키기 때문이다.

운영체제가 물리 메모리를 관리하면서, 물리 메모리의 상세 할당을 신경쓴다. 어떤 프레임에 할당할지, 어떤 프레임이 가용한지, 얼마나 많은 프레임이 있는지 등이다. 이 정보는 보통 한가지 **frame table**이라는 큰 데이터 구조에서 저장이 된다. 프레임 테이블은 각 물리 페이지 프레임을 포함한 한가지 엔트리를 가지고, 페이지 프레임이 비었는지 할당되었는지 확인하고, 만약 할당되었으면, 어떤 프로세스의 어떤페이지인지 알고 있다.

추가적으로, 운영체제는 유저 프로세스가 유저 공간에 있도록 신경쓰고, 모든 논리 주소가 물리 주소를 만들도록 매핑되어야한다. 만약 유저가 시스템 콜을 만들고 파라미터로 가르키면, 주소는 반드시 정확한 물리주소를 생성되게 매핑해야한다. 운영체제는 각 프로세스의 페이지 테이블 사본을 유지하는데, 명령어 카운터와 레지스터 컨텐츠의 사본을 유지하는 것과 같다. 이 사본은 논리 주소를 물리주소로 해석하게 사용되는데, 운영체제는 반드시 논리 주소를 수동으로 물리주소로 맵해야한다. 이것은 CPU 디스패처에서도 사용되는데, 프로세스가 CPU에 할당되었을때 하드웨어 페이지 테이블을 정의하기 위해서이다. 페이징은 따라서 컨텍스트 스위치 시간을 늘린다.

### 9.3.2 하드웨어 지원

페이지 테이블들은 프로세스마다 있는 데이터 구조이고, 페이지 테이블로의 포인터는 각 프로세스의 PCB의 다른 레지스터 값에 저장되어 있다. CPU 스케쥴러가 실행될 프로세스를 선택하면, 그것은 반드시 유저 레지스터와 저장된 유저 페이지 테이블로부터 적절한 하드웨어 페이지 테이블을 재 로딩해야한다. 

페이지 테이블의 하드웨어 구현은 여러가지로 이루어진다. 가장 단순한 케이스로는, 페이지 테이블은 정교한 빠른 속도 하드웨어 레지스터의 집합으로 구현되고, 페이지 주소 해석을 효율적으로 한다. 그러나, 이방법은 컨텍스트 스위치 시간을 증가시키고, 각각의 레지스터가 컨텍스트 스위치간에 교체되어야한다.

 만약 페이지 테이블이 충분히 작다면, 페이지 테이블을 위한 레지스터의 사용은 만족스럽다. 대부분의 현대 CPU는 그러나 훨씬 큰 페이지 테이블을 지원한다.(2^20) 이런 머신에서, 페이지 테이블을 레지스터에 구현하는 것은 적절하지 않다. 오히려, 페이지 테이블은 메인 메모리에 저장되고, **page-table base register(PTBR)**이 페이지 테이블을 가르킨다. 페이지 테이블을 바꾸는 것은 오직 이 레지스터만 교체하면 되고, 컨텍스트 스위치 시간을 줄인다.

 #### 9.3.2.1 Translatoin look aside buffer

 비록 페이지 테이블을 메인메모리에 저장하는 것은 빠른 컨텍스트 스위치를 보장하지만, 그것은 또한 느린 메모리 엑세스 시간을 야기한다. 우리가 i라는 위치에 접근한다고 가정하겠다. 우리는 반드시 페이지 테이블에서 PTRB 오프셋의 값을 사용해서 위치를 찾는다. 이 태스크는 한가지 메모리 액세스를 필요로한다. 그것은 프레임 숫자를 제공하고, 실제 주소를 찾게 해준다. 우리는 메모리의 원하는 장소에 접근할 수 있게된다. 이런 구조에서, 두가지 메모리 엑세스들은 데이터에 접근하기 위해서 필요하다.(하나는 페이지 테이블 엔트리, 하나는 실제 데이터) 그러므로, 메모리 접근은 2가지 요소에 의해서 느려지고, 대부분의 상황에서 참을수 없는 지연이 발생하게 된다.

 이 문제의 일반적인 해결책은 특별하고, 작고, 빠른 하드웨어 캐시인 **Translation look-aside buffer(TLB)**를 사용하는 것이다. TLB는 빠르고 관계적인 메모리이다. TLB안의 각 엔트리는 두가지 부분으로 구성되어있다. 키와 값이다. 관계성 메모리(딕셔너리)가 아이템안에 보여지면, 아이템은 모든 키에 동시에 비교된다. 만약 아이템을 찾으면, 관련있는 값 필드가 반환된다. 탐색은 빠르다. 현대 하드웨어의 TLB 룩업은 명령어 파이프 라인의 일부분이고, 어떤 성능 패널티도 존재하지 않는다. 파이프라인 과정에서 검색을 실행할수 있으려면, TLB는 반드시 작아야한다. 보통 32~1024의 사이즈를 가진다. 몇몇 CPU는 명령어와 TLB 데이터 주소를 분리해서 구현한다. 그것은 TLB의 수를 두배로 늘릴수 있고, 왜냐하면 룩업이 다른 파이프라인 과정에서 구현되기 때문이다. 우리는 이 개발 예제에서 CPU 기술의 진화를 볼 수 있다. 시스템들은 TLB가 없는 단계에서 여러가지 레벨의 TLB를 가지는 단계로 진화하고 있다.

 TLB는 다음과 같은 방식으로 페이지 테이블에 사용될수 있다. TLB는 오직 작은 수의 페이지 테이블을 가지고 있다. 논리적 주소가 CPU에 의해서 생성되면, MMU는 먼저 TLB에 그것의 페이지 번호가 있는지 확인한다. 만약 페이지 넘버가 확인되면, 그것의 프레임 번호를 즉시 알아내고 메모리에 접근하는데 사용된다. 말했듯이, 이런 단계는 CPU안에서 명령어 파이프 라인에서 진행되고, 페이징이 없는 시스템과 거의 차이가 없다.

 만약 페이지 넘버가 TLB에 없으면, 주소 번역은 기존의 방법으로 진행된다. 페이지 테이블에서 메모리 참조를 얻는 것이다. 프레임 숫자가 얻어지면, 우리는 메모리에 접근이 가능해진다. 그리고 이 페이지 넘버와 프레임 숫자를 TLB에 추가해서, 다음 참조에서는 빠르게 찾아질 것이다.

 만약 TLB가 이미 엔트리에 가득찼으면, 존재하는 엔트리는 반드시 교체되어야한다. 교체 정책은 LRU부터 RR, 랜덤 등이 있다. 몇몇 CPU는 운영체제가 LRU를 사용하게 끔하면서, 다른 것들은 그들이 직접 관리하게한다. 더나아가서, 몇몇 TLB들은 일부 엔트리를 **wired down**하게 하는데, 그들이 TLB에서 벗어나지 않게하는 것이다. 일반적으로, TLB의 중요한 커널 코드들이 wired down 된다.

몇몇 TLB들은 **address-space identifiers(ASIDs)**를 각 TLB 엔트리에 저장한다. ASID는 각 프로세스를 유일하게 구별하고 프로세스의 주소 공간 보호를 제공하는데 사용된다. TLB가 가상 페이지 넘버를 해석하려고 시도할때, 그것은 가상 페이지에 관련된 ASID가 현재 실행중인 ASID와 같은지 확인한다. 만약 ASID가 매칭되지 않으면 TLB 미스를 실행한다. 추가적으로 주소 공간 보호를 제공하는 것은, ASID가 TLB로 하여금 몇몇 다른 프로세스를 동시에 가지고 있도록 허용한다. 만약 TLB가 ASID를 지원하지 않으면, 모든 페이지 테이블들이 선택될때마다(각 컨텍스트 스위치), TLB는 반드시 **FLUSHED** 되어서 프로세스가 잘못된 번역 정보를 사용하지 않게 한다. 그렇지 않으면, TLB는 구식의 엔트리로 인해서 잘못된 물리 주소를 전달하게 된다.

TLB에서 페이지 넘버를 찾은 확률의 수를 **hit ratio**라고 한다. 80퍼센트의 hit ratio는 우리가 원하는 페이지 숫자의 80%를 TLB에서 찾았다는 것이다. 만약 10 나노초의 메모리 접근시간이 필요하면, TLB에 있는 값은 총 10나노초가 걸리지만, 만약에 TLB에 없다면, 그것은 페이지 테이블에 접근하는데 10나노초가 걸리고 원하는 메모리로 찾아가는데에 다시 10나노초가 걸려서 20나노초가 걸리게된다.(우리는 페이지 룩업 테이블 확인 과정이 한번의 메모리 엑세스에 된다고 했지만, 그것은 더 걸릴수도 있다.) 유효 메모리 접근 시간을 찾기 위해서, 우리는 각 케이스를 그것의 확률에 비례해서 계산한다. 
`effective access time = 0.8 * 10 + 0.2 * 20 = 12nanoseconds`
이 예시에서 평균 메모리 접근 시간은 20퍼센트 가량 증가했다. 이걸로 우리는 hit ratio가 접근 시간에 얼마나 영향을 미치는지 알 수 있다.

앞서 말했듯이, 오늘 날의 CPU들은 다양한 레벨의 TLB를 제공한다. 현대 CPU에서 메모리 접근 시간 계산은 그러므로 위의 예시보다 더욱 복잡하다. 예를 들어서, 인텔 코어 i7은 128 엔트리 L1 명령어 TLB와 64 엔트리 L1 데이터 TLB가 존재한다. L1에서의 미스가 일어나면, CPU 6사이클이 L2 512 엔트리 TLB에서 필요하다. 만약 L2에서도 실패하면 메모리의 페이지 테이블 엔트리 과정은 수백 사이클이 걸린다.

이런 시스템에서의 완벽한 페이징의 성능 분석 간접비는 각 TLB 티어에 따른 miss rate정보가 필요할 것이다. 우리는 일반적인 정보를 위에서 얻을수 있지만, 하드웨어 기능은 메모리 성능과 운영체제 향상에 엄청난 영향을 미칠 것이다. 그리고 결과적으로 하드웨어 변경에 영향을 줄 것이다. 우리는 TLB의 히트율의 영향을 10장에서 더 알아보겠다.

TLB들은 하드웨어 기능이고 그러므로 운영체제와 그들의 디자이너가 조금만 신경써도 될것 같아 보일 수도있다. 그러나 디자이너들은 하드웨어마다 다른 TLB의 기능과 구조를 이해할 필요가 있다. 선택적 명령어로, 운영체 시스템은 플랫폼의 TLB 디자인에 맞게 페이징을 구현할 수 있다. 이와 같이, TLB 디자인의 변경(인텔 CPU의 세대 변환)은 운영체제의 페이징 구현의 변화를 필요하게 한다.

### 9.3.3 보호

페이징 환경에서의 메모리 보호는 각 프레임과 연관있는 보호비트에 의해서 수행된다. 일반적으로, 이런 비트들은 페이지 테이블에 보관된다.

한 비트는 페이지가 read-write인지 read-only인지 정의한다. 모든 메모리의 참고는 페이지 테이블을 살펴보고 정확한 프레임 숫자를 찾는다. 물리 주소가 계산되는 같은 시간에, 보호 비트는 읽기 전용 페이지에 아무런 쓰기가 실행되었는지 확인한다. 읽기 전용 페이지에 쓰는 시도는 운영체제로 하여금 하드웨어 트랩을 실행하게 한다.

우리는 이런  방법으로 보호를 제공할 수 있다. 우리는 하드웨어를 읽기전용, 일기-쓰기, 실행전용 보호를 제공한다. 또는 분리된 보호 비트를 제공함으로서, 우리는 이러한 접근의 조합을 허용할 수 있다. 부정한 시도는 운영체제에 의해서 트랩된다. 

한가지 추가적인 비트는 페이지의 각 엔트리에 붙여진다. **valid-invalid**비트이다. 비트가 *valid*로 주어지면, 프로세스의 논리 주소 공간에 있는 관계 페이지는 legal(or valid) 페이지가 된다. 만약 bit가 invalid이면, 페이지는 프로세스의 논리 주소공간에 없는 것이다. 잘못된 주소는 valid-invalid 비트로 구분할 수 있다. 운영체제는 이 비트를 각 페이지로의 접근을 허용/비허용하는데 사용한다.

14비트 주소공간의 시스템이 있다고 가정하고(0~16383), 우리가 0~10468을 필요로하는 프로그램이 있다고 가정하자. 2KB의 페이지 사이즈에서, 우리는 총 6개의 페이지가 필요할 것이다. 그러므로 페이지, 6과 7에 대한 접근이 부정하므로, valid-invalid bit가 invalid가 될것이고, 컴퓨터는 운영체제를 트랩할 것이다.

이런 구조는 문제를 만든다. 왜냐하면 프로그램이 10468보다 확장하려고하면, 그 이후의 주소는 불법이다. 그러나 페이지 5번은 valid로 분류되었고, 그래서 12287 까지의 접근은 valid이다. 그 이후만이 invalid이다. 이 문제는 2KB 페이지 사이즈의 결과이고 내부 단편화의 문제를 보여준다.

가끔씩, 그것의 주소 범위를 프로세스가 다사용한다. 실제로, 많은 프로세스는 오직 가용한 일부의 주소공간만을 사용한다. 그럴때에, 모든 주소 범위의 페이지를 만드는 것은 매우 낭비이다. 대부분의 테이블은 사용되지 않고 귀중한 메모리 공간만 축낸다. 몇몇 시스템은 **page table length register(PTLR)**을 제공하고, 페이지 테이블의 크기를 가르킨다. 이 값은 모든 논리 주소에서 프로세스에게 가용한 범위를 확인하기 위해서 사용한다. 이 테스트의 실패는 운영체제가 트랩되게한다.

### 9.3.4 공유 페이지

페이징의 장점은 공유되는 비슷한 코드의 가능성인데, 다중 프로세스가 있는 환경에서 특히 중요하다. 많은 버전의 유닉스와 리눅스 시스템 콜을 제공하는 표준 C 라이브러리를 고려하겠다. 리눅스 시스템에서, 대부분의 유저 프로세스는 표준 C 라이브러리 `libc`를 필요로한다. 한가지 옵션은 각 프로세스가 그것의 libc 카피를 주소공간에 저장하는 것이다. 40개의 유저 프로세스가 있고 libc가 2MB이면, 이것은 80MB의 메모리를 필요로 한다.

만약 코드가 **reentrant code**이면, 그것은 공유될수 있다. 여기서, 우리는 `libc`를 공유하는 3개의 프로세스가 있다고 하겠다. reentrant code는 수정하는 코드가 아니다. 그것은 실행중에 결코 변하지 않는다. 그러므로 2개이상의 프로세스는 같은 코드를 실행할 수 있다. 각 프로세스는 그것의 고유 레지스터 카피와 데이터 공간을 프로세스의 실행동안에 가진다. 다른 두개의 프로세스 데이터는 다를 것이다. 오직 한개의 C 라이브러리 카피만이 물리 메모리에 저장되고 페이지 테이블은 같은 물리 카피를 매핑한다. 그러므로, 40개의 프로세스를 지원하기 위해서, 우리는 한개의 카피만 필요하다.

`libc`같은 런타임 라이브러리에 더해서, 자주 사용되는 컴파일러, 윈도우 시스템, 데이터 베이스 시스템은 공유될 수 있다. 9.1.5에서 설명했던 공유 라이브러리는 공유 페이지로 구현된다. 공유 되기 위해서는 코드가 반드시 reentrant해야한다. 공유 코드의 읽기 전용 환경은 코드의 정확성으로 남겨지지 않는다. 운영 체제는 반드시 이 특성을 강요해야한다.

시스템에서 프로세스간의 메모리의 공유는 4장에서 말한 스레드에 의한 태스크의 주소공간 공유와 비슷하다. 더 나아가 3장에서, 우리는 IPC와 같은 공유 메모리를 설명했다. 몇몇 운영체제는 공유 메모리를 공유 페이지를 이용해서 구현한다.

페이지에 따라서 메모리를 구성하는 것은 많은 프로세스가 같은 물리 페이지를 공유하는 것으로서 더욱 큰 이점을 제공한다. 이 장점은 10장에서 더 다루겠다.