## what we gonna study

5장에서, 우리는 CPU가 어떻게 프로세스의 집합들에서 공유되는지 보였다. CPU 스케쥴링의 결과로, 우리는 CPU의 효율성과 유저로부터의 컴퓨터 반응 속도를 모두 향상시켰다. 이 성능의 증가를 느끼기위해서, 우리는 메모리에 많은 프로세스를 보관해야한다, 즉 우리는 반드시 메모리를 공유해야한다.

이 장에서, 우리는 메모리를 관리하는 다양한 방법을 논의하겠다. 메모리 관리 알고리즘은 기계적 접근부터 페이징과 같은 전략 사용이 있다. 각각의 접근은 장점과 단점을 가지고 있다. 특정 시스템을 위한 메모리 관리 메서드의 선택은 시스템의 하드웨어 디자인과 특히 관련이 있다. 우리는 대부분의 알고리즘이 하드웨어 지원이 필요하고, 많은 시스템들이 하드웨어와 운영체제 메모리 관리의 통합하는 것을 볼 것이다.

## Objectives

- 물리적, 논리적 주소 사이의 차이와 Memory management unit(MMU)의 주소 번역 역할을 설명한다.
- 연속적 메모리 할당의 first-, best-, worst-fit 전략을 적용한다.
- 내부와 외부 단편화의 차이를 설명한다.
- Translation look-aside buffer(TLB)를 포함한 페이징 시스템속의 논리->물리적 주소 번역을 살펴본다.
- 계층적 페이징, 해쉬 페이징, inverted page tables를 본다.
- IA-32, x86-64, ARMv4 구조의 번역을 설명한다.

## 9.1 Background

1장에서 보았듯이, 메모리는 운영체제 시스템의 명령어에 집중한다. 메모리는 거대한 바이트의 행렬을 포함하고, 각각의 주소를 가진다. CPU는 명령어를 매모리로부터 프로그램 카운터의 값에 따라서 가지고 온다. 이런 명령어들은 특정한 메모리 주소로부터 로딩하고, 주소에 저장한다. 

전형적인 명령어 실행 주기는, 먼저 메모리로부터 명령어를 가지고 온다. 명령어는 해독되고 메모리로 부터 피연산함수를 가지고 오게한다. 명령어가 피연산함수에서 실행된 후에, 결과는 다시 메모리에 저장된다. 메모리 유닛은 오직 메모리 주소의 스트림만 본다. 그것은 그들이 어떻게(명령어 카운터, 인덱싱, 비간접, 리터럴 주소 등) 생성되었는지를 모르고, 그들이 무엇(명령어, 데이터)을 위해서 생성되었는지 모른다.  이에 따라서, 우리는 프로그램이 어떻게 메모리 주소를 생성했는지 무시해도 된다. 우리는 오직 프로그램을 실행하면서 생긴 메모리 주소의 시퀀스만 보면된다. 

우리는 우리의 논의를 메모리 관리에 적절한 이슈를 살펴보겠다. 기초 하드웨어, 심벌릭(가상) 메모리 주소에서 실제 물리주소, 논리와 물리 주소의 차이가 있을 것이다. 우리는 이 절의 마무리를 동적 링킹과 공유 라이브러리로 결론 짓겠다.

### 9.1.1 기초 하드웨어

각 프로세싱 코어 속에 내장된 메인 메모리와 레지스터는 CPU만 직접 접근 가능한 저장소이다. 메모리 주소를 인자로 받는 기계 명령어는 있지만, 디스크 주소를 받는 것은 없다. 그러므로, 실행중인 명령어, 명령에 사용되는 데이터는 반드시 이 직접 접근 저장 장치에 있어야한다. 만약 데이터가 메모리에 없으면, 그들은 CPU가 실행하기전에 반드시 이동되어야한다.

각 CPU에 내장된 레지스터는 CPU 클락의 한번의 사이클로 보통 접근이 가능하다. 몇몇 CPU 코어들은 래지스터 내용물의 명령어 해독과 간단한 명령어는 클락 틱의 한번에 보통 해결가능하다. 메모리에서는 같지 않을 것인데, 접근이 메모리 버스의 트랜잭션으로 이루어지기 때문이다. 메모리 엑세스 완료는 CPU 클락의 몇 사이클이 걸릴 수도 있다. 이런 경우에는, 프로세서는 보통 **stall**이 필요한데, 그것은 실행중인 명령어를 완료하는데 데이터를 필요로하지 않기 때문이다. 이 상황은 편협적인데, 메모리 접근의 주기 때문이다. 그 치료는 CPU와 메인 메모리 사이의 빠른 메모리를 추가한다. 이런 캐시는 1.5.5에서 설명했다. CPU의 내장 캐시를 관리하려면, 하드웨어는 자동적으로 운영체제의 관리 없이 메모리 접근의 속도를 올려야한다.(5.5.2에서 메모리 스톨을 설명했고, 멀티 스레드 코어가 스톨된 하드웨어 스레드에서 다른 하드웨어 스레드로 교체하는 것이다.) 

물리 메모리의 상대적인 속도에 대한 고려뿐만 아니라, 우리는 적절한 명령을 해야한다. 적절한 시스템 명령을 위해서, 우리는 반드시 운영체제로부터 유저 프로세스로의 접근을 막아야한다. 물론 유저 프로세서끼리의 접근도 마찬가지이다. 이 보호는 반드시 하드웨어에 의해서 제공되어야하는데, 운영체제는 CPU와 그것의 메모리 접근사이에 개입하지 않기 때문이다. 하드웨어는 이 생산을 몇가지 다른 방식으로 구현하고, 이 챕터에서 보일 것이다. 여기서, 우리는 한가지 가능한 구현을 보이겠다.

우리는 먼저 각 프로세스가 개별의 메모리 공간을 가지게 한다. 프로세스 메모리 공간별 구분은 프로세스끼리를 보호하고 동시 실행을 위한 다양한 프로세스 메모리 적재를 위해서 기초적이다. 메모리 공간을 분리하기 위해서, 우리는 프로세스가 오직 그 프로세스만이 접근가능한 법적 허용 주소를 가지고 있어야한다. 우리는 이 보호를 두개의 레지스터를 사용해서 제공하고, 보통은 베이스와 리미트가 있다. **base register**는 합법 물리 메모리 주소의 가장 작은 값을 가지고, **limit memory**는 범위의 크기를 정의한다. 예를 들어서, 만약 기본 레지스터가 300040이고 리미트 레지스터가 120900이면, 프로그램은 30040부터 420939까지 접근이 가능하다.

메모리 공간의 보호는 유저모드에서 생성된 모든 주소를 비교해서 CPU 하드웨어를 가지는 것으로 완료된다. 유저모드에서 실행하는 프로그램의 운영체제 메모리 또는 다른 유저의 메모리 접근은 어떤 시도든 운영체제에 의해서 트랩되고, 치명적인 오류로 다루어진다. 이런 구조는 유저 프로그램이 운영체제나 다른 유저의 코드나 데이터 구조를 변조하는 것을 방지한다.

베이스와 리미트 레지스터는 오직 운영체제에 의해서만 로드되는데, 특별한 우선순위 명령어를 사용한다. 우선 순위 명령어는 커널 모드에서만 실행 가능하고, 운영체제만이 베이스와 리미트 레지스터를 로딩한다. 이 구조는 운영체제가 레지스터의 값을 바꾸는 것을 허용하면서 유저 프로그램이 레지스터의 컨텐츠를 바꾸는 것을 방지한다.

운영체제에서, 커널모드로 실행하는 것은, 운영체제 메모리와 유저 메모리의 통제되지 않은 접근을 준다. 이 공급은 운영체제가 유저의 프로그램을 유저의 메모리에 담게 해주고, 에러인 프로그램을 덤프아웃시키고, 시스템콜의 파라미터를 접근하고 수정하고, 유저 메모리로부터 I/O를 실행하고, 다양한 서비스를 제공한다. 예를 들어서, 멀티 프로세싱 시스템 시스템은 반드시 컨텍스트 스위치를 실행한다. 다음 프로세스의 컨텍스트가 메인메모리에서 레지스터로 로딩되기 전에 한가지 프로세스의 상태를 레지스터에서 메인메모리에 저장한다.

## 9.1.2 Address Binding

일반적으로, 디스크에 바이너리 실행파일로 프로그램은 자리잡고 있다. 실행하기 위해서, 프로그램은 반드시 메모리로 가지고 와야하고 가용한 CPU의 실행을 할 수 있는 프로세스의 컨텍스트에 위치해야한다. 프로세스가 실행되면, 그것은 메모리로부터 명령어와 데이터에 접근한다. 마침내, 프로세스가 종료되면, 그것의 메모리는 다른 프로세스의 사용을 위해 재정의된다.

대부분의 시스템은 유저 프로세스가 물리 메모리에 거주하게 허용한다. 그러므로, 비록 컴퓨터의 주소 공간이 00000에서 시작해도, 유저 프로세스의 시작 주소는 00000일 필요가 없다. 너는 어떻게 운영체제가 실제로 물리 메모리에 프로세스를 배치하는지 볼 것이다.

대부분의 사례에서, 유저 프로그램은 몇가지 단계를 거쳐가고, 몇몇은 실행전에 선택지가 있다. 주소는 이런 스템 동안 다른 방법으로 대표된다. 컴파일러는 대개 이런 심볼릭 주소를 relocatable 주소(모듈의 시작으로부터 14바이트)로 **binds**한다. 링커 또는 로더(2.5절)는 relocatable 주소를 절대 주소로 **binds**한다. 각 바인딩은 한가지 주소공간을 다른 것으로 매핑한다.

전통적으로, 명령어와 데이터의 바인딩부터 메모리 주소는 다음 방법으로 실행된다.

- Compile time. 만약 너가 프로세스가 거주할 메모리인 컴파일 시간을 알면, **absolute code**는 생성될 수 있다. 예를 들어서, 만약 너가 유저 프로세스가 위치 R로부터 시작하는 것을 알면, 생성된 컴파일러 코드는 그 주소에서 시작하고 그 주소에서 확장될 것이다. 만약, 어느정도 후에, 시작 점이 바뀌면, 그것은 이 코드를 반드시 리컴파일 해야한다.
- Load time. 만약 compile time을 모르면, 컴파일러는 **relocatable code**를 생성해야한다. 이런 경우에, 마지막 바인딩은 로드 타임까지 지연된다. 만약 시작 주소가 바뀌면, 너는 이 변화에 맞지 않게 바뀐 유저코드를 다시 로드해야한다.
- Excution time. 만약 프로세스가 그것의 실행중에 다른 메모리 세그먼트로 이동하면, 바인딩은 반드시 런타임까지 지연되어야한다. 특별한 하드웨어가 이 구조에 적합하고 9.1.3에서 다루겠다. 대부분의 운영체제가 이 방법을 사용한다.

이 장의 가장 큰 부분은 어떻게 다양한 바인딩이 컴퓨터 시스템에서 구현되는 것을 보여주고 적절한 하드웨어 지원을 토론한다.

### 9.1.3 논리적-물리적 주소 공간

CPU에 의해서 만들어진 주소는 **logical address**라 불리고, 메모리 유닛에 의해서 관측되는, 메모리의 **memory-adress register**에 저장되는 것은 **physical address**라고 불린다. 

컴파일러 또는 로드 타임에 생성된 바인딩 주소는 동일한 논리와 물리 주소를 생성한다. 그러나, excution time 주소 바인딩 구조는 다른 논리와 물리 주소를 가진다. 이런 경우에, 우리는 논리적 주소를 **virtual address**라고 부른다. 우리는 논리 주소와 가상 주소를 교차해서 부를 것이다. 프로그램에 의해 생성된 논리적 주소의 집합은 **logical address space**라고 불린다. 그러므로, 실행 시간 주소 바인딩 구조는 논리와 물리 주소 공간이 달라진다. 

가상에서 물리 주소로의 런타임 매핑은 **memory management unit(MMU)**라고 불리는 하드웨어 기기에 의해서 진행된다. 우리는 9.2절에서 9.3절까지 언급할 다양한 메서드를 이런 매핑을 위해서 선택해야한다. 우리는 MMU 구조로하는 매핑을 9.1.1에서 언급한 베이스 레지스터 구조의 일반화라고 한다. relocation 레지스터의 값은 유저 프로세스에 의해서 생성되는 모든 주소가 메모리로 보내지면 추가된다. 예를 들어서, 베이스가 14000이면, 0이라는 주소는 동적으로 14000에 배치되고, 346 주소로의 접근은 14346이 된다.

유저 프로그램은 절대로 실제 물리 주소에 접근하지 않는다. 프로그램은 346이라는 장소로 포인터를 생성하지만, 메모리에 저장하고, 조정하고, 그것을 다른 주소와 비교한다. 오직 그것이 메모리 주소(간접적인 로드 또는 저장)으로 사용될 때만, 그것은 베이스 레지스터에 맞게 재배치된다. 유저 프로그램은 오직 논리적 주소와 비교한다. 메모리 매핑 하드웨어는 논리적 주소를 물리적 주소로 바꾼다. 실행시간 바인딩의 형태는 9.1.2에서 언급되었다. 언급된 메모리 주소의 마지막 장소는 레퍼런스가 만들어지기 전까지 결정되지 않는다.

우리는 이제 두가지 다른 주소의타입을 가졌다. 논리적 주소(0부터 최대치)와 물리적 주소(R+0부터 R+최대치). 유저 프로그램은 오직 논리적 주소를 생성하고 프로세스가 메모리 위치에서 실행한다고 생각한다 그러나 이러한 논리적 주소는 반드시 사용되기전에 물리적 주소에 매핑되어야한다. 논리 주소의 개념은 분리된 물리적 주소 공간에 적절한 메모리 관리를 위해서 집중한다.

### 9.1.4 동적 로딩

우리의 논의에서, 모든 프로그램과 모든 프로세스의 데이터가 프로세스를 실행하기 위해서 필수적이라고 했다. 프로세스의 크기는 그러므로 물리적 메모리의 크기에 제한적이다. 더 나은 메모리 공간 활용을 위해서 우리는 **dynamic loading**을 사용한다. 동적 로딩과 함께, 루틴은 그것이 불리기 전까지 로드되지 않는다. 모든 루틴은 디스크에 재할당가능한 로드 형식으로 보존된다. 메인 프로그램은 메모리에 로드되고 실행된다. 루틴이 다른 루틴을 부를때, 루틴을 부르는 것은 우선 다른 루틴이 로드되었는지 먼저 확인한다. 만약 그렇지 않으면, 재할당 가능한 링킹 로더가 원하는 루틴을 메모리에 부르기 위해서 로드하고 프로그램의 주소를 변경사항 반영을 위해서 업데이트한다. 그때부터 새롭게 로드된 루틴으로 제어가 넘어간다.

다이나믹 로딩의 장점은 루틴이 오직 필요할 때만 로드되는 것이다. 이 메서드는 큰 코드가 가끔 일어나는 에러 루틴 같은 것을 처리하는데 특히 유용하다. 이런 상황에서, 비록 전체 프로그램의 크기는 크지만, 사용되는 부분은 훨씬 작을 수 있다.

동적 로딩은 운영체제로부터 특별한 지원을 요구하지 않는다. 그것은 유저가 이 방법의 이점을 위해서 프로그램을 디자인하는 것에 달려있다. 운영체제는 프로그래머를 도울수도 있지만, 동적 로딩을 돕기위해서 라이브러리 루틴을 제공할 뿐이다.

### 9.1.5 Dynamic linking과 공유 라이브러리

**Dynamically linked libraries(DLLs)**는 유저 프로그램이 실행될때 유저 프로그램에 연결되는 시스템 라이브러리이다. 몇몇 운영체제는 오직 시스템 라이브러리가 다른 객체 모듈을 연결하는 것처럼 취급되고 로더에 의해서 바이너리 프로그램 이미지로 합치는 **static linking**을 지원한다. 동적 링킹은 반대로, 동적 로딩과 비슷하다. 여기서, 비록 링킹은 로딩보다 실행시간까지 지연된다. 이 기능은 보통 C 스탠다드 라이브러리 같은 시스템 라이브러리로 사용된다. 이런 기능 없이, 시스템의 각 프로그램은 반드시 그것의 언어 라이브러리 카피를 실행 이미지에 포함해야한다.(또는 적어도 프로그램에 의해서 루틴이 참조되어야한다.) 이 필요는 실행 이미지의 크기를 키울뿐 아니라 메인메모리를 낭비한다. DLLs의 두번째 장점은 라이브러리가 다양한 프로세스에 의해서 공유될 수 있고, 그래서 메인 메모리의 DLL의 인스턴스가 하나만 있다. 이런 이유로, DLLs는 **shared libraries**라고 불리고, 윈도우와 리눅스 시스템에서 널리 사용된다.

프로그램이 동적 라이브러리의 루틴을 참조하면, 로더는 DLL을 메모리에 배치한다. 그것은 DLL의 주소가 저장된 메모리의 주소로 동적 라이브러리의 함수를 참조하는 주소를 조정한다. 

동적 링크드 라이브러리는 라이브러리 업데이트에도 확장가능하다. 추가적으로, 라이브러리는 새로운 버전에 의해서 대체될 수 있고, 라이브러리를 참조하는 모든 프로그램은 자동적으로 새로운 버전에 사용될 수 있다. 동적 링킹없이, 모든 프로그램은 새로운 라이브러리에 접근하기 위해서 다시 링크될 필요가 있다. 그래서 프로그램은 새롭고 적합하지 않은 라이브러리의 버전을 실행하지 않고, 버전 정보는 프로그램과 라이브러리에 모두 포함될 것이다. 한가지 이상의 버전을 가진 라이브러리가 메모리에 로드될 수 있고, 각 프로그램은 어떤 라이브러리의 카피를 쓸지 선택해야할 것이다. 새로운 라이브러리가 설치되기전에 링크된 프로그램은 구식의 라이브러리를 계속 지원할 것이다.

동적 로딩과 다르게, 동적 링킹과 공유 라이브러리는 보통 운영체제의 도움이 필요하다. 만약 메모리의 프로세스가 다른 것으로 보호되면, 운영체제는 필요한 루틴이 다른 프로세스의 메모리 공간에 있는지 다양한 프로세스가 같은 메모리에 접근하는 것을 확인해주는 유일한 엔티티이다. 우리는 이 개념을 9.3.4절의 페이징 설명하면서 DLL이 어떻게 프로세스들끼리 공유되는지 정밀하게 말해주겠다.

## 9.2 연속적 메모리 할당

메인 메모리는 반드시 운영체제와 다양한 유저 프로세스를 수용해야한다. 우리는 그러므로 가장 효율적인 방법으로 메인메모리에 할당할 필요가 있다. 이 절에서는 연속 메모리 할당이라는 초기의 메서드를 설명하겠다. 멤리는 보통 두가지 파티션으로 나뉘어져 있다. 하나는 운영체제 그리고 하나는 유저 프로세스이다. 우리는 운영체제를 낮은 메모리 주소 또는 높은 메모리 주소에 배치할 수 있다. 이 결졍은 인터럽트 벡터의 위치같은 다양한 요소에 달려있다. 그러나 리눅스와 윈도우는 운영체제를 높은 메모리 주소에 배치한다.

우리는 보통 몇가지 유저 프로세스를 동시에 메모리에 배치하기를 원한다. 우리는 그러므로 메모리에 가기를 기다리는 프로세스가 메모리에 어떻게 할당되는지 고려한다. **Contiguous memory allocation**에서 각 프로세스는 다음 프로세스에 연속적인 메모리의 단일 구역에 포함된다. 메모리 할당 구조에 대해서 논의하기전에, 우리는 반드시 메모리 보호의 이슈에 대해서 말해야한다.

### 9.2.1 메모리 보호

우리는 이전에 말한 두가지 아이디어를 홉합해서 프로세스가 가지지 않은 메모리 접근을 방지한다. 만약 우리가 재위치 레지스터, 리미트 레지스터를 가진 시스템이면, 우리는 우리의 목적을 달성했다. 재위치 레지스터는 가장 작은 물리적 주소를 가지고 리미트 레지스터는 논리 주소의 범위를 가진다. 각각의 논리 주소는 반드시 지정한 리미트 레지스터의 범위에 있어야한다. MMU는 논리적 주소를 재위치 레지스터에 더함으로서 동적으로 매핑한다. 이 매핑된 주소는 메모리로 보내진다.

CPU 스케쥴러가 실행할 프로세스를 선택하면, 디스패처는 재위치와 리미티 레지스터를 컨텍스트 스위치의 정확한 값에 로드한다. CPU에 의해서 생성된 모든 주소가 이런 레지스터에 의해서 체크되기 때문에, 우리는 운영체제와 다른 유저의 프로그램이 서로의 자료를 보호한다.

재위치 레지스터 구조는 운영체제의 크기를 동적으로 변하게하는 효과적인 방법을 제공한다. 이 유연성은 많은 상황에서 이상적이다. 예를 들어서, 운영체제는 디바이스 드라이버에 대한 코드와 버퍼 공간이 존재한다. 만약 디바이스 드라이버가 사용중이 아니면, 굳이 메모리에 둘 필요가 없다. 대신에, 그것은 오직 필요할때만 메모리에 두면 된다. 이와 같이 디바이스 드라이버가 필요하지 않으면, 그것은 제거되고 그것의 메모리는 다른 필요한 것으로 대체된다.

### 9.2.2 메모리 할당

이제 우리는 메모리 할당을 보겠다. 메모리 할당의 가장 단순한 방법은 메모리에 맞게 파티션된 프로세스를 할당하는 것이고, 각 파티션은 정확히 하나의 프로세스를 가지다. **Variable partition** 구조에서 운영체제는 현재 메모리에 가용하고 할당된 부분을 가르키는 테이블을 유지한다. 처음에는, 모든 메모리는 유저 프로세스에 존재하고 가용한 메모리의 큰 블럭을 고려된다(**hole**). 마침내, 메모리는 다양한 크기의 홀의 집합이 된다.

프로세스가 시스템에 진입하면, 운영체제는 각 프로세스의 메모리 필요량과 프로세스가 할당될 가용 메모리 공간을 계산한다. 프로세스가 공간에 할당되면, 그것은 메모리에 로드되고, CPU 시간을 경쟁한다. 프로세스가 종료되면, 그것은 운영체제가 다른 프로세스를 제공할 메모리를 해제한다.

만약 도착 프로세스에 대한 수요를 만족할 충분한 공간이 없으면 어떤 일이 생기는가? 한가지 옵션은 단순히 프로세스를 거절하고 에러메시지를 제공하는 것이다. 대안으로는, 우리는 대기 큐에 넣을 수도 있다. 메모리가 해제되면 운영체제는 대기 큐를 확인한다.

일반적으로, 말했듯이, 가용 메모리 블럭은 메모리에 있는 다양한 홀의 집합으로 구성된다. 프로세스가 도착하고 메모리를 필요로 하면, 시스템은 프로세스에게 충분히 맞는 홀을 집합에서 탐색한다. 만약 홀이 너무크면, 그것은 두 파트로 쪼갠다. 한 파트는 도착한 프로세스로 할당하고 나머지는 홀의 집합에 리턴한다. 프로세스가 종료하면, 그거은 메모리의 블럭을 해제하고, 홀의 집합에 돌려준다. 만약 새로운 홀이 다른 홀에 인접하면, 이 인접홀은 하나의 큰 홀로 합쳐지나.

이런 진행은 일반적인 **dynamic storage allocation problem**의 인스턴스이고, 여유 홀의 리스트에서 요청의 사이즈 n을 만족시키는 것을 고려한다. 이 문제에는 여러가지 솔루션이 있다. **best-fit**, **first-fit**, **worst-fit**이 일반적인 전략이다.

- First fit. 할당가능한 첫번째 홀에 할당한다. 서칭은 홀의 시작으로 시작하거나 이전 first-fist 서치가 끝난 지점이 가능하다. 우리는 여유있는 홀을 발견하면 탐색을 중지한다.
- Best fit 할당가능한 가장 작은 홀에 할당한다. 우리는 전체 리스트를 탐색해야한다. 이 전략은 가장 적은 여분 홀을 만든다.
- Worst fit 할당가능한 가장 큰 홀에 할당한다. 다시, 우리는 전체 리스트를 탐색해야한다. 이 전략은 가장 큰 여분 홀을 만들고, 여분은 best-fit 전략의 작은 여분홀 보다 효과적일 수 있다.

시뮬레이션은 first와 best가 worst보다 시간 절약과 공간 활용도에서 낫다고 한다. first와 best는 정확히 어떤게 공간활용도가 좋다는 밝혀지지 않았지만, first가 확실히 시간은 빠르다.

### 9.2.3 단편화

퍼스트와 베스트 핏 전략은 **external fragmentation**에 고통받는다. 프로세스가 메모리에 로드되고 제거되면서, 메모리 공간의 여유분들은 작은 조각으로 분할된다. 외부 단편화는 전체 메모리 공간은 충분한데 가용공간이 연속적이지 않은 것이다. 공간은 작은 공간의 큰 수들로 단편화되있다. 이 단편화 문제는 심각하다. 최악의 경우에는, 우리는 두 프로세스 간에 낭비되는 메모리를 가진다. 만약 모든 메모리의 작은 조각들이 하나의 큰 블럭이면, 우리는 몇가지 프로세스를 더 실행할 수 있다.

우리가 퍼스트 핏과 베스트 핏 전략을 사용하는 것에 따라서 단편화의 양에 영향을 미칠 수 있다.(시스템에 따라서 뭐가 좋은지는 다르다.) 다른 요인은 여유 블럭의 어떤 끝에 할당하는 가이다. 어떤 알고리즘이 사용되든지, 외부 단편화는 문제가 된다.

전체 메모리 공간과 평균 프로세스 크기, 외부단편화에 따라서 단편화는 크거나 작은 문제가 될 수 있다. 퍼스트 핏의 통계적 분석은, 아무리 최적화를 해도 N개의 할당된 블럭은 0.5N의 블럭을 단편화로 일는다. 즉 1/3의 메모리가 쓸수 없어진다. 이런 특성은 **50-percent rule**이라고 한다.

메모리 단편화는 내부화가 될 수도 있다. 다양한 파티션 할당 구조가 18464의 바이트의 홀을 가진다고 가정하겠다. 여기서 다음 프로세스는 18462를 필요로한다. 만약 우리가 정확히 요청한 블럭을 할당하면, 우리는 2바이트의 홀이 생긴다. 이 홀을 유지하면서 추적하는 간접비는 홀 그자체보다 비쌀 것이다. 이런 문제를 회피하는 일반적인 접근은 물리적 메모리를 고정된 사이즈의 블럭으로 나누고 메모리를 블록 사이즈에 맞게 할당하는 것이다. 이런 접근과 함께, 메모리는 요청 메모리보다 약간더 크게 할당한다. 이 두 숫자 간의 차이를 **internal fragmentation**이라고한다. 그리고 파티션의 내부에 존재한다.

외부단편화의 한가지 솔루션은 **compaction**이다. 목적은 메모리 컨텐츠를 이리저리 움직여서 여유 메모리를 하나의 공간에 두는 것이다. 컴팩션은 항상 가능하지는 않다. 만약 재위치가 정적이고 어셈블리 또는 로드 시간에 진행되면, 컴팩션은 실행될 수 없다. 그것은 오직 재위치가 동적이고 실행시간동안에 진행될때 가능하다. 만약 주소가 동적으로 할당되면 재위치는 오직 프로그램과 제이터를 이동하고 베이스 레지스터를 새로운 베이스 레지스터에 반영하면된다. 컴팩션이 가능하면, 우리는 반드시 그것의 비용을 고려해야한다. 가장 단순한 컴팩션 알고리즘은 모든 프로세스를 메모리의 끝으로 향하게하는 것이다. 모든 홀은 다른 방향으로 이동하고, 한개의 큰 가용 메모리 홀을 만든다. 이 구조는 값비싸다.

다른 외부 단편화를 해결하는 솔루션은 프로세스의 논리 주소공간을 비 연속적으로 만드는 것이다. 그러므로, 프로세스를 물리 메모리가 존재할때 항상 배치하는 것이다. 이 전략은 *paging*이라고 불리고, 현대 컴퓨터 시스템의 가장 일반적인 메모리 관리 테크닉이다. 우리는 페이징을 다음 절에서 다루겠다.

단편화는 데이터의 블럭을 다룰때 항상 생긴다. 우리는 이것은 11장부터 15장까지 얘기 하게 될 것이다.

## 9.3 페이징