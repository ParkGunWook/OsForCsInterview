## What we gonna learn

컴퓨터가 해야하는 두가지 주요한 업무는 I/O와 컴퓨팅이다. 많은 사례에서, 주된 업무는 I/O였고, 컴퓨팅 또는 프로세싱은 자주 없었다. 예를 들어서, 우리가 웹 페이지를 둘러보거나 파일을 수정할때, 우리의 주된 관심은 몇몇 정보를 읽거나 쓰는 것이지, 우리의 물음을 컴퓨팅하는 것이아니다.

컴퓨터 I/O에서 운영체제의 역할은 I/O 명령어와 I/O 기기를 관리하고 컨트롤하는 것이다. 비록 다른 장에서도 관련된 주제가 나오지만, 여기서 우리는 I/O의 전체 그림을 완성하기 위해서 조각들을 모아볼 것이다. 먼저, 우리는 I/O 하드웨어의 기초를 설명하는데, 하드웨어 인터페이즈의 본질이 운영체제 내부의 기능에 제한하기때문이다. 다음으로, 우리는 운영체제가 제공하는 I/O 서비스와 I/O 인터페이스 앱에 내장된 서비스를 다루겠다. 그리고, 우리는 어떻게 하드웨어 인터페이스와 앱 인터페이스 사이의 차이를 운영체제가 연결하는지 보겠다. 우리는 또한 드라이브 코드의 파이프라인을 동적으로 합치는 것을 가능하게하는 앱인 유닉스 시스템의 Vstreams 메커니즘을 보겠다. 마지막으로, 우리는 I/O의 성능 측면과 I/O 성능을 증가시키는 운영체제 디자인의 원칙을 보겠다.

## Chapter Objectives

- 운영체제 I/O 서브시스템의 구조를 살펴본다.
- I/O 하드웨어의 원리와 복잡도를 살펴보겠다.
- I/O 하드웨어와 소프트웨어의 성능 측면을 설명하겠다.

## 12.1 개요

컴퓨터에 연결된 디바이스의 조작은 운영체제 디자이너의 주된 고민이다. I/O 디바이스가 그들의 기능과 속도에서 다양하게 있기에(마우스, 하드디스크, 플래시드라이브, 테이프 로봇을 고려하자.), 다양한 방법들이 그들을 통제하기 위해서 필요하다. 커널의 I/O 서브시스템에 있는 메서드들은, I/O 기기를 관리의 복잡도와는 나머지 커널로부터 분리되어있다.

I/O 기기 기술은 두가지 트렌드가 있다. 한쪽에서는, 우리는 소프트웨어와 하드웨어 인터페이스의 표준화가 증가하고 있는 것을 볼수 있다. 이 트렌드는 존재하는 컴퓨터와 운영체제에 향상된 디바이스 세대를 포함하게 해준다. 반면에, 우리는 I/O 기기의 넓은 다양화를 볼 수 있다. 이 도전은 하드웨어와 소프트웨어 기술의 조합때문에 생긴다. 포트, 버스, 디바이스 컨트롤러 같은 기초적인 I/O 하드웨어 구성요소는 다양한 I/O기기를 수용한다. 다른 디바이스의 이상함과 상세정보를 캡슐화하려면, 운영체제의 커널은 디바이스-드라이버 모듈을 사용할 수 있게 구조화되어야한다. **device drivers**는 I/O 서브시스템에 일정한 디바이스 접근 인터페이스를 보여주고, 시스템 콜은 앱과 운영체제 사이에 표준 인터페이스를 제공한다.

## 12.2 I/O 하드웨어

컴퓨터들은 다양한 종류의 디바이스를 운영한다. 일반적인 범주의 저장소기기(디스크, 테이프), 통신기기(네트워크 연결, 블루투스), 휴먼-인터페이스기기(마우스, 키보드, 스크린, 입출력 장치)의 대부분이 알맞다. 다른 기기들은 더욱 전문화되고, 이런 것들은 제트기의 조종도 포함된다. 비행기에서, 사람은 항공기기에 조이스틱과 페달을 통해서 인풋을 주고, 컴퓨터는 방향타와 플랩을 움직이는 모터와 엔진을 점화하는 아웃풋 커맨드를 보낸다. I/O 기기의 무한한 다양성 때문에, 우리는 어떻게 기기가 부착되고 어떻게 소프트웨어가 하드웨어를 조작하는 지에 대해서는 조금의 이해만 존재한다.

디바이스는 케이블 또는 공기를 통해서 시그널을 보내서 컴퓨터 시스템과 통신한다. 디바이스는 연결점 또는 **port**를 통해서 기계와 통신한다.(**PHY**라는 용어는, OSI 계층의 물리 계층의 약어이고, 포트를 설명할때도 쓰이지만 데이터 센터 명명법에 더욱 일반적이다.) 만약 디바이스들이 일반적인 와이어의 집합을 공유하면, 연결은 버스라고 불린다. 전자학에서, 메시지는 정해진 타이밍에 맞게 와이어에 전달된 전압 패턴이다. 디바이스 A가 디바이스 B에 연결하는 케이블이 있으면, 디바이스 B는 디바이스 C에 연결되는 케이블이 있고, 디바이스 C는 컴퓨터의 포트에 플러그인 되고, 이런 정렬을 **daisy chain**이라고 부른다. 데이지 체인은 버스처럼 작동한다.

버스들이 컴퓨터 아키텍처에서 널리 쓰이고 그들의 시그널링 메서드, 속도, 산출량, 연결 메서드는 다양하다. **PCIe bus**(일반적인 PC 시스템 버스)는 프로세스-메모리 서브시스템을 빠른 기기에 연결하고 **expansion bus**는 키보드와 시리얼과 USB 포트 같은 상대적으로 느린 버스에 연결한다. **serial attached SCSI(SAS)** 버스는 SAS 컨트롤러에 연결되어있다. PCIe는 하나또는 여러 레인을 걸쳐서 데이터를 보내는 융ㄴ한 버스이다. 레인은 두가지 시그널 쌍으로 구성되었는데, 하나는 데이터 수신이고 하나는 통신이다. 각 레인은 그러므로 4개의 와이어로 구성되어서, 각 레인은 가득찬 두배의 바이트 스트림으로 사용되고, 8비트 바이트 포멧으로 동시에 양뱡향으로 데이터 패킷을 옮긴다. 물리적으로, PCIe 링크는 1,2,4,8,12,16,32 레인을 포함하고, "x" prefix로 표시되어있다. PCIe 카드 또는 커넥터는 8개를 쓰면 x8이라고 한다. 추가적으로, PCIe는 여러 세대를 거치고있고, 다음 미래또한 오고 있다. 그러므로, 카드는 "PCIe gen3 x8"은 3세대의 PCIe이고 8개의 레인을 쓴다는 것이다. 이런 기기는 최대 초당 8기가바이트의 산출량을 가진다. PCIe 상세는 https:/pcisig.com 에서 볼 수 있다.

**controller**는 포트, 버스, 디바이스를 작동하는 전자기기의 모음이다. 그것은 시리얼 포트의 와이어의 시그널을 조절하는 컴퓨터의 단일 칩이다. 반면에, **fibre channel(FC)** 버스 컨트롤러는 간단하지 않다. 왜냐하면 FC 프로토콜은 복잡하고 PCs보다 데이터 센터에서 사용되고 FC 버스 컨트롤러는 보통 분리된 회로 보드 또는 컴퓨터의 버스를 연결하는 **host bus adapter(HBA)**에서 구현된다. 그것은 보통 프로세서, 마이크로코드, FC 프로토콜 메시지 처리를 가능하게하는 몇몇 사적 메모리로 구성되어있다. 몇몇 디바이스는 그들의 자체 내장 컨트롤러를 가진다. 만약 너가 디스크 드라이브를 보면, 너는 한쪽에 붙어있는 회로 보드를 볼 수 있다. 이 보드는 디스크 컨트롤러이다. 그것은 몇몇 종류의 연결(SAS, SATA)을 위한 디스크 프로토콜을 구현한다. 그것 또한 마이크로코드와 배드섹터 매핑, 프리패칭, 버퍼링, 캐싱같은 많은 일을 할수 있는 프로세스가 존재한다.

### 12.2.1 Memory-Mapped I/O

어떻게 프로세서가 I/O 전송을 완료하기 위해서 컨트롤러에 커맨드와 데이터를 줄수 있을까? 간단한 답변은 컨트롤러가 데이터를 위한 레지스터를 가지고 시그널을 컨트롤할 수 있는 것이다. 프로세서는 레지스터의 비트 패턴을 읽고 씀으로서 컨트롤러와 통신한다. 이런 통신이 일어나는 한가지 방식은 I/O 포트 주소로 바이트 또는 워드의 전송을 지정하는 특별한 I/O 명령어의 사용이다. I/O 명령어는 적절한 기기를 선택하고 디바이스 레지스터에 비트를 넣거나 빼기위해서 버스 라인을 촉발시킨다. 대안으로, 디바이스가 **memory mapped I/O**를 지원할수도 있다. 이런 경우에, 디바이스 컨트롤 레지스터들은 프로세서의 주소 공간에 매핑된다. CPU는 그들의 물리 메모리에서 매핑된 위치의 디바이스 컨트롤 레지스터를 읽고 쓰기위해서 표준 데이터 전송 명령어를 이용해서 I/O 요청을 실행한다.

과거에는, PC들은 다른 것들을 제어하기 위해서 몇몇 디바이스와 메모리 맵드 I/O를 제어하는 I/O 명령어를 사용했다. PC의 일반적인 I/O 포트 주소를 사용했다. 그래픽 컨트롤러는 기본 컨트롤 명령어의 I/O 포트를 가졌고, 컨트롤러는 스크린 컨텐츠를 잡기위한 더 큰 메모리 맵드 리전을 가졌다. 스레드는 메모리 맵드 리전에 데이터를 씀으로서 스크린에 아웃풋을 보냈다. 컨트롤러는 이 메모리의 컨텐츠에 기반해서 스크린 이미지를 생성했다. 이 기술은 쓰기 쉽다. 더욱이, 그래픽 메모리에 수백만의 바이트를 쓰는 것은 수백만의 I/O 명령어를 제출하는 것보다 빠르다. 그러므로, 시간을 넘어서, 시스테들은 메모리 맵드 I/O로 이동했다. 오늘날, 대부분의 I/O는 메모리 맵드 I/O를 이용해서 작동한다.

I/O 디바이스는 4개의 레지스터를 포함하는데, 상태, 컨트롤, 데이터-인, 데이터-아웃 레지스터이다.
- **data-in register**는 인풋을 얻기위해서 읽는다.
- **data-out register**는 호스트에 의해서 쓰이고 아웃풋을 보낸다.
- **status register**는 호스트에 의해서 읽을 수 있는 비트를 포함한다. 이런 비트는 현재 커맨드가 완료되었는지, 데이터 인 레지스터에 있는 바이트가 읽을수 있게 준비되었는지, 디바이스 에러가 생겼는지를 알려준다.
- **control register**는 호스트에 의해서 커맨드를 시작하거나 디바이스의 모드를 바꾸기 위해서 쓰인다. 예를 들어서, 시리얼 포트의 컨트롤레지스터 특정 비트는 full-duplex와 half-duplex 통신사이에서 선택하고 다른 비트는 패리티 체킹, 3번째 비트는 워드 길이 7또는8로 세팅되고, 다른 비트들은 시리얼 포트에 의해서 지원되는 속도를 고른다.

데이터 레지스터는 일반적으로 1~4바이트이다. 몇몇 컨트롤러는 데이터 레지스터의 사이즈를 뛰어넘는 컨트롤러의 용량을 확장하기 위해서 인풋 또는 아웃풋 바이트를 저장하는 데이터 FIFO 칩을 가진다. FIFO 칩은 디바이스 호스트가 이런 데이터를 받을 수 있을떄까지의 작은 데이터의 버스트를 가진다.

### 12.2.2 Polling

호스트와 컨트롤러 사이의 상호작용을 위한 완벽한 프로토콜은 복잡하지만, 기본적인 핸드세이킹 개념은 간단하다. 우리는 핸드셰이킹을 예시로 사용하겠다. 2비트가 컨트롤러 호스트 사이를 생산자-소비자 관계로 조정하기 위해서 사용된다고 생각하겠다. 컨트롤러는 `status` 레지스터의 `busy`비트를 통해서 상태를 가르킨다.(비트를 1로 하는 것이 `set`이고 0으로하는 것이 `clear`라고 하겠다.) 컨트롤러는 현재 사용중이면 비지 비트를 세팅하고 다음 커맨드를 받을 준비가 되면 클리어한다. 호스트는 그것의 바램을 커맨드 레지스터의 `command-ready`비트를 통해서 시그널한다. 예를 들어서, 호스트는 포트를 통해서 아웃풋을 쓰고, 핸드세이킹에 따라서 컨트롤러를 조정한다.

1. 호스트는 반족적으로 비트가 클리어 될때까지 `busy` 비트를 읽는다.
2. 호스트는 커맨드 레지스터의 `write`비트를 세팅하고 `data-out` 레지스터에 바이트를 쓴다.
3. 호스트는 `command-ready`비트를 세팅한다.
4. 컨트롤러가 `command-ready` 비트가 세팅된걸 알면, 그것은 `busy`비트를 세팅한다.
5. 컨트롤러는 커맨드 레지스터를 읽고 `write` 커맨드를 본다. 그것은 바이트를 가져오기 위해서 `data-out` 레지스터를 읽고 디바이스에 I/O를 실행한다.
6. 컨트롤러는 `command-ready`비트를 클리어하고 I/O 디바이스가 성공했다고 알리기 위해서 `error`비트를 클리어하고, `busy` 비트를 클리어해서 완료를 알린다.

이 루프가 매 바이트마다 이루어진다.

첫번째 과정에서, 호스트는 **busy-waiting**또는 **polling**이다. 이것은 루프에 있고, `busy` 비트가 클리어될때까지 `status` 레지스터를 읽고 또 읽는다. 만약 컨트롤로와 디바이스가 빠르면, 이 메서드는 합리적인 선택이다. 그러나 만약에 대기가 너무 길어지고, 호스트가 다른 태스크로 변경해야한다. 그때, 호스트는 컨트롤러가 언제 유휴상태인지 알 수 있을까? 몇몇 디바이스에서, 호스트는 반드시 디바이스를 빠르게 서비스하거나, 데이터는 사라진다. 예를 들어서, 데이터가 키보드로부터 시리얼 포트를 따라서 흐르면, 컨트롤러의 작은 버퍼는 넘치고 만약 호스트가 읽은 데이터를 리턴하기전에 너무 오래기다리면 데이터를 잃게될 것이다. 

많은 컴퓨터 아키텍처에서, 3개의 CPU 명령어 사이클이 디바이스를 poll하기에 적합하다. 디바이스 레지스터를 읽고, 상태 비트를 추출하고 만약 0이 아니면 branch한다. 명백히, 기본 폴링 명령은 효율 적이다. 그러나 폴링은 디바이스가 거의 준비되지 않는 상황에서 반복적으로 시도하면 비효율적이고, 디바이스가 서비스를 할 준비가 되었을때 하드웨어 컨트롤러가 CPU에 알리도록 정렬하면 효율적이다. I/O 완료를 기다리면서 CPU를 반복적으로 poll하는 것은 비효율적이다. CPU에게 하드웨어 메커니즘이 준비되었다고 알리는 것이 바로 **interrupt**이다.

### 12.2.3 인터럽트

기본적인 인터럽트 메커니즘은 다음과 같다. CPU 하드웨어가 CPU가 매 명령어 실행마다 반응하는 **interrupt-request line**라고 불리는 와이어를 가진다. CPU가 컨트롤러가 시그널을 인터럽트 리퀘스트 라인에서 가지고 있다고 감지하면, CPU는 상태를 저장하고 고정된 메모리 주소의 **interrupt handler routine**으로 점프한다. 인터럽트 핸들러는 인터럽트의 원인을 결정하고, 필수적인 프로세싱을 실행하고, 상태를 복구하고, 인터럽트 이전에 CPU가 실행하던 상태로 리턴한다. 우리는 디바이스 컨트롤러가 인터럽트 리퀘스트 라인에 시그널을 주장함으로서 인터럽트를 *raise*했다고 말하고, CPU가 인터럽트를 *catch*하고 인터럽트 핸들러를 *dispatch*했고, 핸들러는 디바이스를 서비스함으로 인터럽트를 *clear*했다고 한다.

우리는 이 장에서 인터럽트를 강조하는데 왜냐하면 싱글 유저 현재 시스템은 초당 수백개의 인터럽트를 관리하기 때문이다. 예를 들어서, macOS의 `latency` 명령어을 실행하면, 10초간 23000개의 인터럽트가 나오기도 한다.

기본적인 인터럽트 메커니즘은 CPU가 디바이스 컨트롤러가 서비스할 준비될때 비동기 이벤트에 반응할 수 있게하는 것이다. 현대 운영체제에서, 우리는 더욱 정교한 인터럽트 핸들링 기능이 필요하다.
1. 우리는 중요한 프로세싱 중에 인터럽트 핸들링을 미룰 능력이 필요하다.
2. 우리는 먼저 인터럽트를 raise할때 모든 디바이스 폴링없이 적절한 인터럽트 핸들러를 실행할 효율적인 방법이 필요하다.
3. 우리는 멀티레벨 인터럽트가 필요하고, 그래서 운영체제가 높고 낮은 우선순위의 인터럽트를 구별하고 여러개의 동시 인터럽트가 있을때 적절한 긴급성의 급에 맞게 반응해야한다.
4. 우리는 운영체제의 주의를 직접 받을 명령어를 필요로하고, 이런 활동은 페이지 폴트 또는 0으로 나누기이다. 보았듯이, 이런 태스크는 "traps"로 해결된다.

현대 컴퓨터 하드웨어에서, 이런 기능들은 CPU와 **interrupt-controller hardware**에 의해서 제공된다.

대부분의 CPU들은 2개의 인터럽트 리퀘스트 라인을 가진다. 하나는 **nonmaskable interrupt**이고, 회복불가능한 메모리 에러같은 이벤트를 보존한다. 두번쨰 인터럽트 라인은 **maskable**이다. 그것은 인터럽트 받으면 안되는 중요한 명령어 순서의 실행전에 꺼진다. 

인터러브 메커니즘은 **address**를 수락했고, 특정한 인터럽트 핸들링 루틴이 작은 집합에서 선택된다. 대부분의 아키텍처에서, 이 주소는 **interrupt vector**라고 불리는 테이블의 오프셋이다. 벡터 인터럽트 메커니즘의 목적은 한번의 서비스만으로 가능한 모든 인터럽트의 원인을 결정하는 것이다. 실제로는, 컴퓨터들은 인터럽트 벡터의 주소 원소보다 더 많은 기기를 가지고 있다. 이 문제를 해결하는 방법은 **interrupt chaining**을 사용하는 것이고, 인터럽트 벡터의 각원소는 인터럽트 핸들러의 리스트의 헤드를 가르킨다. 인터럽트가 raise되면, 상응하는 리스트의 핸들러가 하나하나 불리고, 요청을 서비스할떄까지 찾는다. 이 구조를 큰 인터럽트의 오버헤드와 단일 인터럽트 실행의 비효율성에서 타협한다.

인텔 펜티운 프로세스는 8비트의 인터럽트 벡터를 사용한다. 0~31은 nonmaskable이고 페이지 폴트(즉각적인 행동이 필요하다.), 요청을 디버깅(일반적인 명령을 중단하고 디버거 앱으로 점프한다.)같은 다양한 에러 컨디션(시스템 충돌을 일으키는)을 처리하는데 사용된다. 32~255는 maskable이고 device generated 인터럽트같은 것을 목적으로 사용된다.

인터럽트 메커니즘은 또한 **interrupt priority levels**의 시스템을 구현한다. 이런 레벨들은 CPU가 모든 인터럽트를 마스킹하지 않고 낮은 우선순위의 인터럽트를 무시하고 높은 순위의 인터럽트가 낮은 순위의 인터럽트를 선점하게 끔 만든다. 

현대 운영체제는 몇가지 방법으로 인터럽트 메커니즘과 상호작용한다. 부팅 시점에, 운영체제는 어떤 디바이스가 있는지 하드웨어 버스를 탐색하고 인터럽트 벡터안에 상응하는 인터럽트 핸들러를 설치한다. I/O 중에, 다양한 기기 컨트롤러는 그들이 서비스가 준비되면 인터럽트를 raise한다. 이런 인터럽트들은 아웃풋이 완료되었거나, 인풋 에디터가 존재한다거나, 실패가 탐지되었다고 알려준다. 인터럽트 메커니즘은 다양한 범위의 **exceptions**도 핸들하기 위해서 사용하는데, 0으로 나누기, 보호되거나 존재하지 않는 메모리 주소로의 접근, 유저모드에서의 권한 명령어 실행이 있다. 인터럽트를 만드는 이벤트는 공통의 영역이 있다. 그들은 운영체제가 급하고 독립적인 루틴을 실행하게끔 한다.

많은 사례에서의 인터럽트 핸들링이 시간과 리소스에 제한적이고 그러므로 구현하기 복잡하기 때문에, 시스템은 인터럽트 관리를 **first-level interrupt handler(FLIH)**와 **second-level interrupt handler(SLIH)**로 나눈다. FLIH는 컨텍스트 스위치, 상태 저장, 핸들링 명령어의 큐잉를 실행하는데 비해서, 분리된 스케쥴 SLIH는 요청된 명령의 핸들링을 실행한다. 

운영체제는 인터럽트를 위한 좋은 방법을 가진다. 예를 들어서, 많은 운영체제들은 가상 메모리 페이징을 위한 인터럽트 메커니즘을 사용한다. 페이지 폴트는 인터럽트가 발생시키는 예외이다. 인터럽트는 현재의 프로세스를 중단하고 커널의 페이지 폴트 핸들러로 점프한다. 이 핸들러는 프로세스의 상태를 저장하고, 프로세스를 대기큐에 배치하고 페이지 캐시 관리를 실행하고, 페이지를 fetch하기 위해서 I/O 명령어를 스케쥴하고 명령어를 재시작하기위해서 다른 프로세스를 스케쥴하고 인터럽트로부터 리턴한다.

다른 예시는 시스템 콜의 구현에서 찾아진다. 보통, 프로그램은 시스템 콜을 발행하기 위해서 라이브러리를 사용한다. 라이브러리 루틴은 앱에 의해서 주어진 어규먼트를 체크하고, 커널에 어규먼트를 보내기위해서 데이터 구조를 빌드하고 **software interrupt**또는 **trap**이라고 불리는 특별한 명령어를 실행한다. 이 명령어는 원하는 커널 서비스를 구별하는 연산자를 가진다. 프로세스가 트랩 명령어를 실행하면, 인터럽트 하드웨어는 유저 코드의 상태를 저장하고, 커널 모드로 전환하고, 커널 루틴또는 요청된 서비스를 구현한 스레드를 실행한다. 트랩은 디바이스 인터럽트에 할당된 우선순위보다 상대적으로 낮은 우선순위를 가진다. 앱의 측면에서 시스템콜을 실행하는 것은 그것의 FIFO 큐가 오버플로하고 데이터를 잃기전에 디바이스 컨트롤러를 서비스하는 것보다 덜 급하다.

인터럽트는 또한 커널에서 컨트롤의 플로우를 관리하는데 사용된다. 예를 들어서, 프로세싱이 디스크 읽기 완료를 필요로한다고 가정하겠다. 한가지 단계는 커널 공간에서 유저 버퍼로 데이터를 복사한다. 이 복사는 시간은 잡아먹지만 급하지 않고, 그것은 다른 높은 순위 인터럽트 핸들링을 블락해서는 안된다. 다른 단계는 다른 기다리는 I/O를 시작하는 것이다. 이 단계는 높은 우선도를 가질 수 있다. 만약 디스크가 효율적으로 사용되면, 우리는 다음 I/O를 이전 것이 완료되기전에 다음 I/O를 시작할 필요가 있다. 결과적으로, 인터럽트의 쌍은 디스크 리드를 완료하는 커널 코드를 구현해야한다. 높은 우선도 핸들러는 I/O 상태를 저장하고, 디바이스 인터럽트를 클리어하고, 대기하는 I/O를 시작하고 일을 완료하기 위해서 낮은 우선순위 인터럽트를 인터럽트한다. 후에, CPU가 높은 우선도 일을 차지하지 않으면, 낮은 우선도 인터럽트가 발생한다. 상응하는 핸들러는 데이터를 커널 버퍼의 데이터를 앱 공간에 복사함으로서 유저 레벨 I/O를 완료하고 레디 큐에 앱을 위치하기 위해서 스케쥴러를 부른다.

스레드 커널 구조 또한 다중 인터럽트 우선도를 구현하고 앞의 인터럽트 핸들링을 강조한다. 우리는 이런 포인트를 솔라리스 커널로 설명하겠다. 솔라리스에서, 인터럽트 핸들러는 커널 스레드로서 실행된다. 높은 순위의 스케쥴링 범위는 이런 스레드들에 보존된다. 이런 우선도는 인터럽트 핸들러가 앱 코드와 커널 하우스 키핑을 넘어서게 하고 인터럽트 핸들러 사이에 상대적인 우선도를 구현한다. 우선도는 솔라리스 스레드 스케쥴러가 높은 우선 순위의 인터럽트 핸들러가 선점하고, 스레드 구현은 멀티 프로세서 하드웨어가 다양한 인터럽트 핸들러를 가능하게 한다. 리눅스와 윈도우는 20장과 21장에서 설명하겠다.

요약하면, 인터럽트는 운영체제를 통해서 비동기 이벤트를 핸들하고 커널에서의 감시자 모드 루틴을 트랩하기 위해서 사용된다. 가장 급한 일을 먼저 처리하게 하기위해서, 현대 컴퓨터들은 인터럽트 우선도의 시스템을 사용한다. 디바이스 컨트롤러, 하드웨어 폴트, 시스템 콜들은 커널 루틴을 실행하기 위해서 인터럽트를 raise한다. 인터럽트들이 시간에 민감한 프로세싱에 사용되기에, 효율적인 인터럽트 핸들링이 좋은 시스템 성능을 위해서 필요하다. 인터럽트 기반 I/O는 이제 폴링보다 더 일반적이고, 폴링이 사용되는 것은 높은 산출량 I/O에서만 쓰인다. 때떄로 두개는 공존한다. 몇몇 디바이스 드라이버는 I/O 속도가 느릴때 인터럽트를 사용하고 그것의 속도가 폴링이 빠르고 효율적일때 폴링으로 바꾼다.

### 12.2.4 Direct Memory Access

디스크 드라이브 같이 큰 전송을 하는 디바이스에서, 상태 비트를 감시하고 컨트롤러 레지스터에 한바이트씩 먹이는 비싼 범용 목적 프로세서를 사용하는 것은 낭비이다. 이런 프로세스는 **programmed I/O(PIO)**라고 불린다. 컴퓨터는 메인 CPU에 이 일을 **direct memory access**라는 특별 목적 프로세서가 이 일을 덜어가는 PIO로 무겁게하는 것을 피한다. DMA 전송을 시작하기 위해서, 호스트는 DMA 커맨드 블락을 메모리에 쓴다. 블락은 전송의 출처 포인터, 전송의 목적지 포인터, 전송될 바이트의 수를 포함한다. 커맨드 블락은 연속적이지 않은 목적 주소와 출처의 리스트를 포함함으로서 더욱 복잡해질 수 있다. **scatter-gather** 메서드는 DMA 커맨드를 이용해서 다중 전송을 허용할 수 있다. CPU는 DMA 컨트롤러에 커맨드 블록의 주소를 쓴다. DMA 컨트롤러는 메모리 버스를 직접 운영하기 위해서 진행하고, 메인 CPU의 도움 없이 전송 위해서 주소를 버스에 두는 것을 실행한다. 간단한 DMA 컨트롤러는 모든 현대 컴퓨터의 표준 구성요소이고, 스마트폰부터 메인프레임까지이다.

커널 주소공간에 타겟 주소를 두는 것이 가장 직관적이다. 만약 유저 스페이스이면, 유저는 전송중에 공간의 컨텐츠를 수정하고 몇몇 데이터를 잃게된다. 스레드 접근을 위해서 유저 공간에 DMA 전송 데이터를 얻으면, 두번쨰 복사 명령어, 커널 메모리에서 유저 메모리로의 시간이 필요하다. 시간을 지나, 운영체제는 I/O 전송을 디바이스와 유저 주소 공간이 직접적으로 실행하기 위한 메모리 매핑을 사용하기 시작했다.

DMA 컨트롤러와 디바이스 컨트롤러 간의 핸드쉐이킹은 **DMA-request**와 **DMA acknowledge**라고 불리는 한쌍의 와이어를 통해서 실행된다. 디바이스 컨트롤러는 데이터의 워드가 전송이 준비되면 DMA 리퀘스트 와이어에 시그널을 보낸다. 시그널은 DMA 컨트롤러가 메모리 버스를 설치하게 야기하고, 메모리 주소 와이어에 원하는 주소를 두고, DMA acknowledge 와이어에 시그널을 둔다. 디바이스 컨트롤러가 DMA acknowlege signal을 받으면, 그것은 데이터의 워드에 메모리를 전송하고 DMA 리퀘스트 시그널을 삭제한다.

전체 전송이 완료되면, DMA 컨트롤러는 CPU를 인터럽트한다. DMA 컨트롤러가 메모리 버스를 장악하면, CPU는 일시적으로 메인 메모리 접근으로부터 방지되고, 그것은 여전히 그것의 캐시 아이템에 접근이 가능하다. 비록 이 **cycle stealing**이 CPU 연산을 느리게하고, 데이터 전송 작업을 DMA에 넘기는 것은 전체 시스템의 성능을 향상시킨다. 몇몇 컴퓨터 아키텍처는 DMA를 위해서 물리 메모리 주소를 사용하지만, 다른 것들은 **direct virtual memory access(DVMA)**를 사용한다. 가상 주소가 물리 주소로 번역되게끔 사용한다. DVMA는 CPU의 개입 또는 메인메모리의 사용 없이 메모리 맵드 디바이스에서 전송을 실행한다.

보호받는 모드 커널에서, 운영체제는 보통 프로세스가 디바이스 커맨드를 직접 발생시키는 것을 방지한다. 이 규율은 접근 제어 침범으로부터 데이터를 보호하고 시스템 충돌을 야기하는 디바이스 컨트롤러의 잘못된 사용으로부터 시스템을 보호한다. 대신에, 운영 체제는 충분히 특권을 가진 프로세스가 하드웨어의 낮은 레벨 명령어 접근을 사용하게하는 함수를 전한다. 메모리 보호 없는 커널에서, 프로세스들은 디바이스 컨트롤러에 직접 접근이 가능하다. 이 직접 접근은 높은 성능을 성취하는데 쓰이고, 그것은 커널 통신, 컨텍스트 스위치, 커널 소프트웨어의 레이어를 회피하게 한다. 불행히도, 그것은 시스템 보안과 안정성에서 방해된다. 일반적인 범용 운영체제는 메모리와 디바이스를 보호하고 그래서 시스템은 악성 앱으로부터 에러를 방지한다.

### 12.2.5 I/O 하드웨어 요약

비록 I/O의 하드웨어는 전자공학적인 하드웨어 디자인의 디테일 레벨에서는 복잡하지만, 우리가 방금 표현한 컨셉들은 운영체제의 많은 I/O기능을 이해하는데 충분하다. 메인 컨셉을 다시보자.

- A bus
- A controller
- An I/O port and its registers
- The handshaking realtionship between the host and a device controller
- The offloading of this work to a DMA controller for large trasfers

우리는 디바이스 컨트롤러와 호스트 사이의 핸드세이킹 예제를 이 절에서 보았다. 실제로는, 존재하는 기기의 다양헝이 운영체제 구현에 문제를 발생시킨다. 각 종류의 디바이스는 그것의 능력, 컨트롤 비트 정의, 호스트와 상호작용할 프로토콜을 가지고 그들은 모두 다르다. 어떻게 운영체제를 새롭게 쓰이지 않고도 새로운 디바이스를 붙이도록 디자인할 수 있을까? 그리고 디바이스가 다양하면, 어떻게 운영체제는 간단하고, 일정한 I/O 인터페이스를 앱에게 제공할까?

## 12.3 Application I/O interface