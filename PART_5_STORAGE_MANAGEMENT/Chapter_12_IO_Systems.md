## What we gonna learn

컴퓨터가 해야하는 두가지 주요한 업무는 I/O와 컴퓨팅이다. 많은 사례에서, 주된 업무는 I/O였고, 컴퓨팅 또는 프로세싱은 자주 없었다. 예를 들어서, 우리가 웹 페이지를 둘러보거나 파일을 수정할때, 우리의 주된 관심은 몇몇 정보를 읽거나 쓰는 것이지, 우리의 물음을 컴퓨팅하는 것이아니다.

컴퓨터 I/O에서 운영체제의 역할은 I/O 명령어와 I/O 기기를 관리하고 컨트롤하는 것이다. 비록 다른 장에서도 관련된 주제가 나오지만, 여기서 우리는 I/O의 전체 그림을 완성하기 위해서 조각들을 모아볼 것이다. 먼저, 우리는 I/O 하드웨어의 기초를 설명하는데, 하드웨어 인터페이즈의 본질이 운영체제 내부의 기능에 제한하기때문이다. 다음으로, 우리는 운영체제가 제공하는 I/O 서비스와 I/O 인터페이스 앱에 내장된 서비스를 다루겠다. 그리고, 우리는 어떻게 하드웨어 인터페이스와 앱 인터페이스 사이의 차이를 운영체제가 연결하는지 보겠다. 우리는 또한 드라이브 코드의 파이프라인을 동적으로 합치는 것을 가능하게하는 앱인 유닉스 시스템의 Vstreams 메커니즘을 보겠다. 마지막으로, 우리는 I/O의 성능 측면과 I/O 성능을 증가시키는 운영체제 디자인의 원칙을 보겠다.

## Chapter Objectives

- 운영체제 I/O 서브시스템의 구조를 살펴본다.
- I/O 하드웨어의 원리와 복잡도를 살펴보겠다.
- I/O 하드웨어와 소프트웨어의 성능 측면을 설명하겠다.

## 12.1 개요

컴퓨터에 연결된 디바이스의 조작은 운영체제 디자이너의 주된 고민이다. I/O 디바이스가 그들의 기능과 속도에서 다양하게 있기에(마우스, 하드디스크, 플래시드라이브, 테이프 로봇을 고려하자.), 다양한 방법들이 그들을 통제하기 위해서 필요하다. 커널의 I/O 서브시스템에 있는 메서드들은, I/O 기기를 관리의 복잡도와는 나머지 커널로부터 분리되어있다.

I/O 기기 기술은 두가지 트렌드가 있다. 한쪽에서는, 우리는 소프트웨어와 하드웨어 인터페이스의 표준화가 증가하고 있는 것을 볼수 있다. 이 트렌드는 존재하는 컴퓨터와 운영체제에 향상된 디바이스 세대를 포함하게 해준다. 반면에, 우리는 I/O 기기의 넓은 다양화를 볼 수 있다. 이 도전은 하드웨어와 소프트웨어 기술의 조합때문에 생긴다. 포트, 버스, 디바이스 컨트롤러 같은 기초적인 I/O 하드웨어 구성요소는 다양한 I/O기기를 수용한다. 다른 디바이스의 이상함과 상세정보를 캡슐화하려면, 운영체제의 커널은 디바이스-드라이버 모듈을 사용할 수 있게 구조화되어야한다. **device drivers**는 I/O 서브시스템에 일정한 디바이스 접근 인터페이스를 보여주고, 시스템 콜은 앱과 운영체제 사이에 표준 인터페이스를 제공한다.

## 12.2 I/O 하드웨어

컴퓨터들은 다양한 종류의 디바이스를 운영한다. 일반적인 범주의 저장소기기(디스크, 테이프), 통신기기(네트워크 연결, 블루투스), 휴먼-인터페이스기기(마우스, 키보드, 스크린, 입출력 장치)의 대부분이 알맞다. 다른 기기들은 더욱 전문화되고, 이런 것들은 제트기의 조종도 포함된다. 비행기에서, 사람은 항공기기에 조이스틱과 페달을 통해서 인풋을 주고, 컴퓨터는 방향타와 플랩을 움직이는 모터와 엔진을 점화하는 아웃풋 커맨드를 보낸다. I/O 기기의 무한한 다양성 때문에, 우리는 어떻게 기기가 부착되고 어떻게 소프트웨어가 하드웨어를 조작하는 지에 대해서는 조금의 이해만 존재한다.

디바이스는 케이블 또는 공기를 통해서 시그널을 보내서 컴퓨터 시스템과 통신한다. 디바이스는 연결점 또는 **port**를 통해서 기계와 통신한다.(**PHY**라는 용어는, OSI 계층의 물리 계층의 약어이고, 포트를 설명할때도 쓰이지만 데이터 센터 명명법에 더욱 일반적이다.) 만약 디바이스들이 일반적인 와이어의 집합을 공유하면, 연결은 버스라고 불린다. 전자학에서, 메시지는 정해진 타이밍에 맞게 와이어에 전달된 전압 패턴이다. 디바이스 A가 디바이스 B에 연결하는 케이블이 있으면, 디바이스 B는 디바이스 C에 연결되는 케이블이 있고, 디바이스 C는 컴퓨터의 포트에 플러그인 되고, 이런 정렬을 **daisy chain**이라고 부른다. 데이지 체인은 버스처럼 작동한다.

버스들이 컴퓨터 아키텍처에서 널리 쓰이고 그들의 시그널링 메서드, 속도, 산출량, 연결 메서드는 다양하다. **PCIe bus**(일반적인 PC 시스템 버스)는 프로세스-메모리 서브시스템을 빠른 기기에 연결하고 **expansion bus**는 키보드와 시리얼과 USB 포트 같은 상대적으로 느린 버스에 연결한다. **serial attached SCSI(SAS)** 버스는 SAS 컨트롤러에 연결되어있다. PCIe는 하나또는 여러 레인을 걸쳐서 데이터를 보내는 융ㄴ한 버스이다. 레인은 두가지 시그널 쌍으로 구성되었는데, 하나는 데이터 수신이고 하나는 통신이다. 각 레인은 그러므로 4개의 와이어로 구성되어서, 각 레인은 가득찬 두배의 바이트 스트림으로 사용되고, 8비트 바이트 포멧으로 동시에 양뱡향으로 데이터 패킷을 옮긴다. 물리적으로, PCIe 링크는 1,2,4,8,12,16,32 레인을 포함하고, "x" prefix로 표시되어있다. PCIe 카드 또는 커넥터는 8개를 쓰면 x8이라고 한다. 추가적으로, PCIe는 여러 세대를 거치고있고, 다음 미래또한 오고 있다. 그러므로, 카드는 "PCIe gen3 x8"은 3세대의 PCIe이고 8개의 레인을 쓴다는 것이다. 이런 기기는 최대 초당 8기가바이트의 산출량을 가진다. PCIe 상세는 https:/pcisig.com 에서 볼 수 있다.

**controller**는 포트, 버스, 디바이스를 작동하는 전자기기의 모음이다. 그것은 시리얼 포트의 와이어의 시그널을 조절하는 컴퓨터의 단일 칩이다. 반면에, **fibre channel(FC)** 버스 컨트롤러는 간단하지 않다. 왜냐하면 FC 프로토콜은 복잡하고 PCs보다 데이터 센터에서 사용되고 FC 버스 컨트롤러는 보통 분리된 회로 보드 또는 컴퓨터의 버스를 연결하는 **host bus adapter(HBA)**에서 구현된다. 그것은 보통 프로세서, 마이크로코드, FC 프로토콜 메시지 처리를 가능하게하는 몇몇 사적 메모리로 구성되어있다. 몇몇 디바이스는 그들의 자체 내장 컨트롤러를 가진다. 만약 너가 디스크 드라이브를 보면, 너는 한쪽에 붙어있는 회로 보드를 볼 수 있다. 이 보드는 디스크 컨트롤러이다. 그것은 몇몇 종류의 연결(SAS, SATA)을 위한 디스크 프로토콜을 구현한다. 그것 또한 마이크로코드와 배드섹터 매핑, 프리패칭, 버퍼링, 캐싱같은 많은 일을 할수 있는 프로세스가 존재한다.

### 12.2.1 Memory-Mapped I/O

어떻게 프로세서가 I/O 전송을 완료하기 위해서 컨트롤러에 커맨드와 데이터를 줄수 있을까? 간단한 답변은 컨트롤러가 데이터를 위한 레지스터를 가지고 시그널을 컨트롤할 수 있는 것이다. 프로세서는 레지스터의 비트 패턴을 읽고 씀으로서 컨트롤러와 통신한다. 이런 통신이 일어나는 한가지 방식은 I/O 포트 주소로 바이트 또는 워드의 전송을 지정하는 특별한 I/O 명령어의 사용이다. I/O 명령어는 적절한 기기를 선택하고 디바이스 레지스터에 비트를 넣거나 빼기위해서 버스 라인을 촉발시킨다. 대안으로, 디바이스가 **memory mapped I/O**를 지원할수도 있다. 이런 경우에, 디바이스 컨트롤 레지스터들은 프로세서의 주소 공간에 매핑된다. CPU는 그들의 물리 메모리에서 매핑된 위치의 디바이스 컨트롤 레지스터를 읽고 쓰기위해서 표준 데이터 전송 명령어를 이용해서 I/O 요청을 실행한다.

과거에는, PC들은 다른 것들을 제어하기 위해서 몇몇 디바이스와 메모리 맵드 I/O를 제어하는 I/O 명령어를 사용했다. PC의 일반적인 I/O 포트 주소를 사용했다. 그래픽 컨트롤러는 기본 컨트롤 명령어의 I/O 포트를 가졌고, 컨트롤러는 스크린 컨텐츠를 잡기위한 더 큰 메모리 맵드 리전을 가졌다. 스레드는 메모리 맵드 리전에 데이터를 씀으로서 스크린에 아웃풋을 보냈다. 컨트롤러는 이 메모리의 컨텐츠에 기반해서 스크린 이미지를 생성했다. 이 기술은 쓰기 쉽다. 더욱이, 그래픽 메모리에 수백만의 바이트를 쓰는 것은 수백만의 I/O 명령어를 제출하는 것보다 빠르다. 그러므로, 시간을 넘어서, 시스테들은 메모리 맵드 I/O로 이동했다. 오늘날, 대부분의 I/O는 메모리 맵드 I/O를 이용해서 작동한다.

I/O 디바이스는 4개의 레지스터를 포함하는데, 상태, 컨트롤, 데이터-인, 데이터-아웃 레지스터이다.
- **data-in register**는 인풋을 얻기위해서 읽는다.
- **data-out register**는 호스트에 의해서 쓰이고 아웃풋을 보낸다.
- **status register**는 호스트에 의해서 읽을 수 있는 비트를 포함한다. 이런 비트는 현재 커맨드가 완료되었는지, 데이터 인 레지스터에 있는 바이트가 읽을수 있게 준비되었는지, 디바이스 에러가 생겼는지를 알려준다.
- **control register**는 호스트에 의해서 커맨드를 시작하거나 디바이스의 모드를 바꾸기 위해서 쓰인다. 예를 들어서, 시리얼 포트의 컨트롤레지스터 특정 비트는 full-duplex와 half-duplex 통신사이에서 선택하고 다른 비트는 패리티 체킹, 3번째 비트는 워드 길이 7또는8로 세팅되고, 다른 비트들은 시리얼 포트에 의해서 지원되는 속도를 고른다.

데이터 레지스터는 일반적으로 1~4바이트이다. 몇몇 컨트롤러는 데이터 레지스터의 사이즈를 뛰어넘는 컨트롤러의 용량을 확장하기 위해서 인풋 또는 아웃풋 바이트를 저장하는 데이터 FIFO 칩을 가진다. FIFO 칩은 디바이스 호스트가 이런 데이터를 받을 수 있을떄까지의 작은 데이터의 버스트를 가진다.

### 12.2.2 Polling

호스트와 컨트롤러 사이의 상호작용을 위한 완벽한 프로토콜은 복잡하지만, 기본적인 핸드세이킹 개념은 간단하다. 우리는 핸드셰이킹을 예시로 사용하겠다. 2비트가 컨트롤러 호스트 사이를 생산자-소비자 관계로 조정하기 위해서 사용된다고 생각하겠다. 컨트롤러는 `status` 레지스터의 `busy`비트를 통해서 상태를 가르킨다.(비트를 1로 하는 것이 `set`이고 0으로하는 것이 `clear`라고 하겠다.) 컨트롤러는 현재 사용중이면 비지 비트를 세팅하고 다음 커맨드를 받을 준비가 되면 클리어한다. 호스트는 그것의 바램을 커맨드 레지스터의 `command-ready`비트를 통해서 시그널한다. 예를 들어서, 호스트는 포트를 통해서 아웃풋을 쓰고, 핸드세이킹에 따라서 컨트롤러를 조정한다.

1. 호스트는 반족적으로 비트가 클리어 될때까지 `busy` 비트를 읽는다.
2. 호스트는 커맨드 레지스터의 `write`비트를 세팅하고 `data-out` 레지스터에 바이트를 쓴다.
3. 호스트는 `command-ready`비트를 세팅한다.
4. 컨트롤러가 `command-ready` 비트가 세팅된걸 알면, 그것은 `busy`비트를 세팅한다.
5. 컨트롤러는 커맨드 레지스터를 읽고 `write` 커맨드를 본다. 그것은 바이트를 가져오기 위해서 `data-out` 레지스터를 읽고 디바이스에 I/O를 실행한다.
6. 컨트롤러는 `command-ready`비트를 클리어하고 I/O 디바이스가 성공했다고 알리기 위해서 `error`비트를 클리어하고, `busy` 비트를 클리어해서 완료를 알린다.

이 루프가 매 바이트마다 이루어진다.

첫번째 과정에서, 호스트는 **busy-waiting**또는 **polling**이다. 이것은 루프에 있고, `busy` 비트가 클리어될때까지 `status` 레지스터를 읽고 또 읽는다. 만약 컨트롤로와 디바이스가 빠르면, 이 메서드는 합리적인 선택이다. 그러나 만약에 대기가 너무 길어지고, 호스트가 다른 태스크로 변경해야한다. 그때, 호스트는 컨트롤러가 언제 유휴상태인지 알 수 있을까? 몇몇 디바이스에서, 호스트는 반드시 디바이스를 빠르게 서비스하거나, 데이터는 사라진다. 예를 들어서, 데이터가 키보드로부터 시리얼 포트를 따라서 흐르면, 컨트롤러의 작은 버퍼는 넘치고 만약 호스트가 읽은 데이터를 리턴하기전에 너무 오래기다리면 데이터를 잃게될 것이다. 

많은 컴퓨터 아키텍처에서, 3개의 CPU 명령어 사이클이 디바이스를 poll하기에 적합하다. 디바이스 레지스터를 읽고, 상태 비트를 추출하고 만약 0이 아니면 branch한다. 명백히, 기본 폴링 명령은 효율 적이다. 그러나 폴링은 디바이스가 거의 준비되지 않는 상황에서 반복적으로 시도하면 비효율적이고, 디바이스가 서비스를 할 준비가 되었을때 하드웨어 컨트롤러가 CPU에 알리도록 정렬하면 효율적이다. I/O 완료를 기다리면서 CPU를 반복적으로 poll하는 것은 비효율적이다. CPU에게 하드웨어 메커니즘이 준비되었다고 알리는 것이 바로 **interrupt**이다.