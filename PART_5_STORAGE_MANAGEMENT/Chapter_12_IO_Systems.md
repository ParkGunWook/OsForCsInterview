## What we gonna learn

컴퓨터가 해야하는 두가지 주요한 업무는 I/O와 컴퓨팅이다. 많은 사례에서, 주된 업무는 I/O였고, 컴퓨팅 또는 프로세싱은 자주 없었다. 예를 들어서, 우리가 웹 페이지를 둘러보거나 파일을 수정할때, 우리의 주된 관심은 몇몇 정보를 읽거나 쓰는 것이지, 우리의 물음을 컴퓨팅하는 것이아니다.

컴퓨터 I/O에서 운영체제의 역할은 I/O 명령어와 I/O 기기를 관리하고 컨트롤하는 것이다. 비록 다른 장에서도 관련된 주제가 나오지만, 여기서 우리는 I/O의 전체 그림을 완성하기 위해서 조각들을 모아볼 것이다. 먼저, 우리는 I/O 하드웨어의 기초를 설명하는데, 하드웨어 인터페이즈의 본질이 운영체제 내부의 기능에 제한하기때문이다. 다음으로, 우리는 운영체제가 제공하는 I/O 서비스와 I/O 인터페이스 앱에 내장된 서비스를 다루겠다. 그리고, 우리는 어떻게 하드웨어 인터페이스와 앱 인터페이스 사이의 차이를 운영체제가 연결하는지 보겠다. 우리는 또한 드라이브 코드의 파이프라인을 동적으로 합치는 것을 가능하게하는 앱인 유닉스 시스템의 Vstreams 메커니즘을 보겠다. 마지막으로, 우리는 I/O의 성능 측면과 I/O 성능을 증가시키는 운영체제 디자인의 원칙을 보겠다.

## Chapter Objectives

- 운영체제 I/O 서브시스템의 구조를 살펴본다.
- I/O 하드웨어의 원리와 복잡도를 살펴보겠다.
- I/O 하드웨어와 소프트웨어의 성능 측면을 설명하겠다.

## 12.1 개요

컴퓨터에 연결된 디바이스의 조작은 운영체제 디자이너의 주된 고민이다. I/O 디바이스가 그들의 기능과 속도에서 다양하게 있기에(마우스, 하드디스크, 플래시드라이브, 테이프 로봇을 고려하자.), 다양한 방법들이 그들을 통제하기 위해서 필요하다. 커널의 I/O 서브시스템에 있는 메서드들은, I/O 기기를 관리의 복잡도와는 나머지 커널로부터 분리되어있다.

I/O 기기 기술은 두가지 트렌드가 있다. 한쪽에서는, 우리는 소프트웨어와 하드웨어 인터페이스의 표준화가 증가하고 있는 것을 볼수 있다. 이 트렌드는 존재하는 컴퓨터와 운영체제에 향상된 디바이스 세대를 포함하게 해준다. 반면에, 우리는 I/O 기기의 넓은 다양화를 볼 수 있다. 이 도전은 하드웨어와 소프트웨어 기술의 조합때문에 생긴다. 포트, 버스, 디바이스 컨트롤러 같은 기초적인 I/O 하드웨어 구성요소는 다양한 I/O기기를 수용한다. 다른 디바이스의 이상함과 상세정보를 캡슐화하려면, 운영체제의 커널은 디바이스-드라이버 모듈을 사용할 수 있게 구조화되어야한다. **device drivers**는 I/O 서브시스템에 일정한 디바이스 접근 인터페이스를 보여주고, 시스템 콜은 앱과 운영체제 사이에 표준 인터페이스를 제공한다.

## 12.2 I/O 하드웨어

컴퓨터들은 다양한 종류의 디바이스를 운영한다. 일반적인 범주의 저장소기기(디스크, 테이프), 통신기기(네트워크 연결, 블루투스), 휴먼-인터페이스기기(마우스, 키보드, 스크린, 입출력 장치)의 대부분이 알맞다. 다른 기기들은 더욱 전문화되고, 이런 것들은 제트기의 조종도 포함된다. 비행기에서, 사람은 항공기기에 조이스틱과 페달을 통해서 인풋을 주고, 컴퓨터는 방향타와 플랩을 움직이는 모터와 엔진을 점화하는 아웃풋 커맨드를 보낸다. I/O 기기의 무한한 다양성 때문에, 우리는 어떻게 기기가 부착되고 어떻게 소프트웨어가 하드웨어를 조작하는 지에 대해서는 조금의 이해만 존재한다.

디바이스는 케이블 또는 공기를 통해서 시그널을 보내서 컴퓨터 시스템과 통신한다. 디바이스는 연결점 또는 **port**를 통해서 기계와 통신한다.(**PHY**라는 용어는, OSI 계층의 물리 계층의 약어이고, 포트를 설명할때도 쓰이지만 데이터 센터 명명법에 더욱 일반적이다.) 만약 디바이스들이 일반적인 와이어의 집합을 공유하면, 연결은 버스라고 불린다. 전자학에서, 메시지는 정해진 타이밍에 맞게 와이어에 전달된 전압 패턴이다. 디바이스 A가 디바이스 B에 연결하는 케이블이 있으면, 디바이스 B는 디바이스 C에 연결되는 케이블이 있고, 디바이스 C는 컴퓨터의 포트에 플러그인 되고, 이런 정렬을 **daisy chain**이라고 부른다. 데이지 체인은 버스처럼 작동한다.

버스들이 컴퓨터 아키텍처에서 널리 쓰이고 그들의 시그널링 메서드, 속도, 산출량, 연결 메서드는 다양하다. **PCIe bus**(일반적인 PC 시스템 버스)는 프로세스-메모리 서브시스템을 빠른 기기에 연결하고 **expansion bus**는 키보드와 시리얼과 USB 포트 같은 상대적으로 느린 버스에 연결한다. **serial attached SCSI(SAS)** 버스는 SAS 컨트롤러에 연결되어있다. PCIe는 하나또는 여러 레인을 걸쳐서 데이터를 보내는 융ㄴ한 버스이다. 레인은 두가지 시그널 쌍으로 구성되었는데, 하나는 데이터 수신이고 하나는 통신이다. 각 레인은 그러므로 4개의 와이어로 구성되어서, 각 레인은 가득찬 두배의 바이트 스트림으로 사용되고, 8비트 바이트 포멧으로 동시에 양뱡향으로 데이터 패킷을 옮긴다. 물리적으로, PCIe 링크는 1,2,4,8,12,16,32 레인을 포함하고, "x" prefix로 표시되어있다. PCIe 카드 또는 커넥터는 8개를 쓰면 x8이라고 한다. 추가적으로, PCIe는 여러 세대를 거치고있고, 다음 미래또한 오고 있다. 그러므로, 카드는 "PCIe gen3 x8"은 3세대의 PCIe이고 8개의 레인을 쓴다는 것이다. 이런 기기는 최대 초당 8기가바이트의 산출량을 가진다. PCIe 상세는 https:/pcisig.com 에서 볼 수 있다.

**controller**는 포트, 버스, 디바이스를 작동하는 전자기기의 모음이다. 그것은 시리얼 포트의 와이어의 시그널을 조절하는 컴퓨터의 단일 칩이다. 반면에, **fibre channel(FC)** 버스 컨트롤러는 간단하지 않다. 왜냐하면 FC 프로토콜은 복잡하고 PCs보다 데이터 센터에서 사용되고 FC 버스 컨트롤러는 보통 분리된 회로 보드 또는 컴퓨터의 버스를 연결하는 **host bus adapter(HBA)**에서 구현된다. 그것은 보통 프로세서, 마이크로코드, FC 프로토콜 메시지 처리를 가능하게하는 몇몇 사적 메모리로 구성되어있다. 몇몇 디바이스는 그들의 자체 내장 컨트롤러를 가진다. 만약 너가 디스크 드라이브를 보면, 너는 한쪽에 붙어있는 회로 보드를 볼 수 있다. 이 보드는 디스크 컨트롤러이다. 그것은 몇몇 종류의 연결(SAS, SATA)을 위한 디스크 프로토콜을 구현한다. 그것 또한 마이크로코드와 배드섹터 매핑, 프리패칭, 버퍼링, 캐싱같은 많은 일을 할수 있는 프로세스가 존재한다.

### 12.2.1 Memory-Mapped I/O

어떻게 프로세서가 I/O 전송을 완료하기 위해서 컨트롤러에 커맨드와 데이터를 줄수 있을까? 간단한 답변은 컨트롤러가 데이터를 위한 레지스터를 가지고 시그널을 컨트롤할 수 있는 것이다. 프로세서는 레지스터의 비트 패턴을 읽고 씀으로서 컨트롤러와 통신한다. 이런 통신이 일어나는 한가지 방식은 I/O 포트 주소로 바이트 또는 워드의 전송을 지정하는 특별한 I/O 명령어의 사용이다. I/O 명령어는 적절한 기기를 선택하고 디바이스 레지스터에 비트를 넣거나 빼기위해서 버스 라인을 촉발시킨다. 대안으로, 디바이스가 **memory mapped I/O**를 지원할수도 있다. 이런 경우에, 디바이스 컨트롤 레지스터들은 프로세서의 주소 공간에 매핑된다. CPU는 그들의 물리 메모리에서 매핑된 위치의 디바이스 컨트롤 레지스터를 읽고 쓰기위해서 표준 데이터 전송 명령어를 이용해서 I/O 요청을 실행한다.

과거에는, PC들은 다른 것들을 제어하기 위해서 몇몇 디바이스와 메모리 맵드 I/O를 제어하는 I/O 명령어를 사용했다. PC의 일반적인 I/O 포트 주소를 사용했다. 그래픽 컨트롤러는 기본 컨트롤 명령어의 I/O 포트를 가졌고, 컨트롤러는 스크린 컨텐츠를 잡기위한 더 큰 메모리 맵드 리전을 가졌다. 스레드는 메모리 맵드 리전에 데이터를 씀으로서 스크린에 아웃풋을 보냈다. 컨트롤러는 이 메모리의 컨텐츠에 기반해서 스크린 이미지를 생성했다. 이 기술은 쓰기 쉽다. 더욱이, 그래픽 메모리에 수백만의 바이트를 쓰는 것은 수백만의 I/O 명령어를 제출하는 것보다 빠르다. 그러므로, 시간을 넘어서, 시스테들은 메모리 맵드 I/O로 이동했다. 오늘날, 대부분의 I/O는 메모리 맵드 I/O를 이용해서 작동한다.

I/O 디바이스는 4개의 레지스터를 포함하는데, 상태, 컨트롤, 데이터-인, 데이터-아웃 레지스터이다.
- **data-in register**는 인풋을 얻기위해서 읽는다.
- **data-out register**는 호스트에 의해서 쓰이고 아웃풋을 보낸다.
- **status register**는 호스트에 의해서 읽을 수 있는 비트를 포함한다. 이런 비트는 현재 커맨드가 완료되었는지, 데이터 인 레지스터에 있는 바이트가 읽을수 있게 준비되었는지, 디바이스 에러가 생겼는지를 알려준다.
- **control register**는 호스트에 의해서 커맨드를 시작하거나 디바이스의 모드를 바꾸기 위해서 쓰인다. 예를 들어서, 시리얼 포트의 컨트롤레지스터 특정 비트는 full-duplex와 half-duplex 통신사이에서 선택하고 다른 비트는 패리티 체킹, 3번째 비트는 워드 길이 7또는8로 세팅되고, 다른 비트들은 시리얼 포트에 의해서 지원되는 속도를 고른다.

데이터 레지스터는 일반적으로 1~4바이트이다. 몇몇 컨트롤러는 데이터 레지스터의 사이즈를 뛰어넘는 컨트롤러의 용량을 확장하기 위해서 인풋 또는 아웃풋 바이트를 저장하는 데이터 FIFO 칩을 가진다. FIFO 칩은 디바이스 호스트가 이런 데이터를 받을 수 있을떄까지의 작은 데이터의 버스트를 가진다.

### 12.2.2 Polling

호스트와 컨트롤러 사이의 상호작용을 위한 완벽한 프로토콜은 복잡하지만, 기본적인 핸드세이킹 개념은 간단하다. 우리는 핸드셰이킹을 예시로 사용하겠다. 2비트가 컨트롤러 호스트 사이를 생산자-소비자 관계로 조정하기 위해서 사용된다고 생각하겠다. 컨트롤러는 `status` 레지스터의 `busy`비트를 통해서 상태를 가르킨다.(비트를 1로 하는 것이 `set`이고 0으로하는 것이 `clear`라고 하겠다.) 컨트롤러는 현재 사용중이면 비지 비트를 세팅하고 다음 커맨드를 받을 준비가 되면 클리어한다. 호스트는 그것의 바램을 커맨드 레지스터의 `command-ready`비트를 통해서 시그널한다. 예를 들어서, 호스트는 포트를 통해서 아웃풋을 쓰고, 핸드세이킹에 따라서 컨트롤러를 조정한다.

1. 호스트는 반족적으로 비트가 클리어 될때까지 `busy` 비트를 읽는다.
2. 호스트는 커맨드 레지스터의 `write`비트를 세팅하고 `data-out` 레지스터에 바이트를 쓴다.
3. 호스트는 `command-ready`비트를 세팅한다.
4. 컨트롤러가 `command-ready` 비트가 세팅된걸 알면, 그것은 `busy`비트를 세팅한다.
5. 컨트롤러는 커맨드 레지스터를 읽고 `write` 커맨드를 본다. 그것은 바이트를 가져오기 위해서 `data-out` 레지스터를 읽고 디바이스에 I/O를 실행한다.
6. 컨트롤러는 `command-ready`비트를 클리어하고 I/O 디바이스가 성공했다고 알리기 위해서 `error`비트를 클리어하고, `busy` 비트를 클리어해서 완료를 알린다.

이 루프가 매 바이트마다 이루어진다.

첫번째 과정에서, 호스트는 **busy-waiting**또는 **polling**이다. 이것은 루프에 있고, `busy` 비트가 클리어될때까지 `status` 레지스터를 읽고 또 읽는다. 만약 컨트롤로와 디바이스가 빠르면, 이 메서드는 합리적인 선택이다. 그러나 만약에 대기가 너무 길어지고, 호스트가 다른 태스크로 변경해야한다. 그때, 호스트는 컨트롤러가 언제 유휴상태인지 알 수 있을까? 몇몇 디바이스에서, 호스트는 반드시 디바이스를 빠르게 서비스하거나, 데이터는 사라진다. 예를 들어서, 데이터가 키보드로부터 시리얼 포트를 따라서 흐르면, 컨트롤러의 작은 버퍼는 넘치고 만약 호스트가 읽은 데이터를 리턴하기전에 너무 오래기다리면 데이터를 잃게될 것이다. 

많은 컴퓨터 아키텍처에서, 3개의 CPU 명령어 사이클이 디바이스를 poll하기에 적합하다. 디바이스 레지스터를 읽고, 상태 비트를 추출하고 만약 0이 아니면 branch한다. 명백히, 기본 폴링 명령은 효율 적이다. 그러나 폴링은 디바이스가 거의 준비되지 않는 상황에서 반복적으로 시도하면 비효율적이고, 디바이스가 서비스를 할 준비가 되었을때 하드웨어 컨트롤러가 CPU에 알리도록 정렬하면 효율적이다. I/O 완료를 기다리면서 CPU를 반복적으로 poll하는 것은 비효율적이다. CPU에게 하드웨어 메커니즘이 준비되었다고 알리는 것이 바로 **interrupt**이다.

### 12.2.3 인터럽트

기본적인 인터럽트 메커니즘은 다음과 같다. CPU 하드웨어가 CPU가 매 명령어 실행마다 반응하는 **interrupt-request line**라고 불리는 와이어를 가진다. CPU가 컨트롤러가 시그널을 인터럽트 리퀘스트 라인에서 가지고 있다고 감지하면, CPU는 상태를 저장하고 고정된 메모리 주소의 **interrupt handler routine**으로 점프한다. 인터럽트 핸들러는 인터럽트의 원인을 결정하고, 필수적인 프로세싱을 실행하고, 상태를 복구하고, 인터럽트 이전에 CPU가 실행하던 상태로 리턴한다. 우리는 디바이스 컨트롤러가 인터럽트 리퀘스트 라인에 시그널을 주장함으로서 인터럽트를 *raise*했다고 말하고, CPU가 인터럽트를 *catch*하고 인터럽트 핸들러를 *dispatch*했고, 핸들러는 디바이스를 서비스함으로 인터럽트를 *clear*했다고 한다.

우리는 이 장에서 인터럽트를 강조하는데 왜냐하면 싱글 유저 현재 시스템은 초당 수백개의 인터럽트를 관리하기 때문이다. 예를 들어서, macOS의 `latency` 명령어을 실행하면, 10초간 23000개의 인터럽트가 나오기도 한다.

기본적인 인터럽트 메커니즘은 CPU가 디바이스 컨트롤러가 서비스할 준비될때 비동기 이벤트에 반응할 수 있게하는 것이다. 현대 운영체제에서, 우리는 더욱 정교한 인터럽트 핸들링 기능이 필요하다.
1. 우리는 중요한 프로세싱 중에 인터럽트 핸들링을 미룰 능력이 필요하다.
2. 우리는 먼저 인터럽트를 raise할때 모든 디바이스 폴링없이 적절한 인터럽트 핸들러를 실행할 효율적인 방법이 필요하다.
3. 우리는 멀티레벨 인터럽트가 필요하고, 그래서 운영체제가 높고 낮은 우선순위의 인터럽트를 구별하고 여러개의 동시 인터럽트가 있을때 적절한 긴급성의 급에 맞게 반응해야한다.
4. 우리는 운영체제의 주의를 직접 받을 명령어를 필요로하고, 이런 활동은 페이지 폴트 또는 0으로 나누기이다. 보았듯이, 이런 태스크는 "traps"로 해결된다.

현대 컴퓨터 하드웨어에서, 이런 기능들은 CPU와 **interrupt-controller hardware**에 의해서 제공된다.

대부분의 CPU들은 2개의 인터럽트 리퀘스트 라인을 가진다. 하나는 **nonmaskable interrupt**이고, 회복불가능한 메모리 에러같은 이벤트를 보존한다. 두번쨰 인터럽트 라인은 **maskable**이다. 그것은 인터럽트 받으면 안되는 중요한 명령어 순서의 실행전에 꺼진다. 

인터러브 메커니즘은 **address**를 수락했고, 특정한 인터럽트 핸들링 루틴이 작은 집합에서 선택된다. 대부분의 아키텍처에서, 이 주소는 **interrupt vector**라고 불리는 테이블의 오프셋이다. 벡터 인터럽트 메커니즘의 목적은 한번의 서비스만으로 가능한 모든 인터럽트의 원인을 결정하는 것이다. 실제로는, 컴퓨터들은 인터럽트 벡터의 주소 원소보다 더 많은 기기를 가지고 있다. 이 문제를 해결하는 방법은 **interrupt chaining**을 사용하는 것이고, 인터럽트 벡터의 각원소는 인터럽트 핸들러의 리스트의 헤드를 가르킨다. 인터럽트가 raise되면, 상응하는 리스트의 핸들러가 하나하나 불리고, 요청을 서비스할떄까지 찾는다. 이 구조를 큰 인터럽트의 오버헤드와 단일 인터럽트 실행의 비효율성에서 타협한다.

인텔 펜티운 프로세스는 8비트의 인터럽트 벡터를 사용한다. 0~31은 nonmaskable이고 페이지 폴트(즉각적인 행동이 필요하다.), 요청을 디버깅(일반적인 명령을 중단하고 디버거 앱으로 점프한다.)같은 다양한 에러 컨디션(시스템 충돌을 일으키는)을 처리하는데 사용된다. 32~255는 maskable이고 device generated 인터럽트같은 것을 목적으로 사용된다.

인터럽트 메커니즘은 또한 **interrupt priority levels**의 시스템을 구현한다. 이런 레벨들은 CPU가 모든 인터럽트를 마스킹하지 않고 낮은 우선순위의 인터럽트를 무시하고 높은 순위의 인터럽트가 낮은 순위의 인터럽트를 선점하게 끔 만든다. 

현대 운영체제는 몇가지 방법으로 인터럽트 메커니즘과 상호작용한다. 부팅 시점에, 운영체제는 어떤 디바이스가 있는지 하드웨어 버스를 탐색하고 인터럽트 벡터안에 상응하는 인터럽트 핸들러를 설치한다. I/O 중에, 다양한 기기 컨트롤러는 그들이 서비스가 준비되면 인터럽트를 raise한다. 이런 인터럽트들은 아웃풋이 완료되었거나, 인풋 에디터가 존재한다거나, 실패가 탐지되었다고 알려준다. 인터럽트 메커니즘은 다양한 범위의 **exceptions**도 핸들하기 위해서 사용하는데, 0으로 나누기, 보호되거나 존재하지 않는 메모리 주소로의 접근, 유저모드에서의 권한 명령어 실행이 있다. 인터럽트를 만드는 이벤트는 공통의 영역이 있다. 그들은 운영체제가 급하고 독립적인 루틴을 실행하게끔 한다.

많은 사례에서의 인터럽트 핸들링이 시간과 리소스에 제한적이고 그러므로 구현하기 복잡하기 때문에, 시스템은 인터럽트 관리를 **first-level interrupt handler(FLIH)**와 **second-level interrupt handler(SLIH)**로 나눈다. FLIH는 컨텍스트 스위치, 상태 저장, 핸들링 명령어의 큐잉를 실행하는데 비해서, 분리된 스케쥴 SLIH는 요청된 명령의 핸들링을 실행한다. 

운영체제는 인터럽트를 위한 좋은 방법을 가진다. 예를 들어서, 많은 운영체제들은 가상 메모리 페이징을 위한 인터럽트 메커니즘을 사용한다. 페이지 폴트는 인터럽트가 발생시키는 예외이다. 인터럽트는 현재의 프로세스를 중단하고 커널의 페이지 폴트 핸들러로 점프한다. 이 핸들러는 프로세스의 상태를 저장하고, 프로세스를 대기큐에 배치하고 페이지 캐시 관리를 실행하고, 페이지를 fetch하기 위해서 I/O 명령어를 스케쥴하고 명령어를 재시작하기위해서 다른 프로세스를 스케쥴하고 인터럽트로부터 리턴한다.

다른 예시는 시스템 콜의 구현에서 찾아진다. 보통, 프로그램은 시스템 콜을 발행하기 위해서 라이브러리를 사용한다. 라이브러리 루틴은 앱에 의해서 주어진 어규먼트를 체크하고, 커널에 어규먼트를 보내기위해서 데이터 구조를 빌드하고 **software interrupt**또는 **trap**이라고 불리는 특별한 명령어를 실행한다. 이 명령어는 원하는 커널 서비스를 구별하는 연산자를 가진다. 프로세스가 트랩 명령어를 실행하면, 인터럽트 하드웨어는 유저 코드의 상태를 저장하고, 커널 모드로 전환하고, 커널 루틴또는 요청된 서비스를 구현한 스레드를 실행한다. 트랩은 디바이스 인터럽트에 할당된 우선순위보다 상대적으로 낮은 우선순위를 가진다. 앱의 측면에서 시스템콜을 실행하는 것은 그것의 FIFO 큐가 오버플로하고 데이터를 잃기전에 디바이스 컨트롤러를 서비스하는 것보다 덜 급하다.

인터럽트는 또한 커널에서 컨트롤의 플로우를 관리하는데 사용된다. 예를 들어서, 프로세싱이 디스크 읽기 완료를 필요로한다고 가정하겠다. 한가지 단계는 커널 공간에서 유저 버퍼로 데이터를 복사한다. 이 복사는 시간은 잡아먹지만 급하지 않고, 그것은 다른 높은 순위 인터럽트 핸들링을 블락해서는 안된다. 다른 단계는 다른 기다리는 I/O를 시작하는 것이다. 이 단계는 높은 우선도를 가질 수 있다. 만약 디스크가 효율적으로 사용되면, 우리는 다음 I/O를 이전 것이 완료되기전에 다음 I/O를 시작할 필요가 있다. 결과적으로, 인터럽트의 쌍은 디스크 리드를 완료하는 커널 코드를 구현해야한다. 높은 우선도 핸들러는 I/O 상태를 저장하고, 디바이스 인터럽트를 클리어하고, 대기하는 I/O를 시작하고 일을 완료하기 위해서 낮은 우선순위 인터럽트를 인터럽트한다. 후에, CPU가 높은 우선도 일을 차지하지 않으면, 낮은 우선도 인터럽트가 발생한다. 상응하는 핸들러는 데이터를 커널 버퍼의 데이터를 앱 공간에 복사함으로서 유저 레벨 I/O를 완료하고 레디 큐에 앱을 위치하기 위해서 스케쥴러를 부른다.

스레드 커널 구조 또한 다중 인터럽트 우선도를 구현하고 앞의 인터럽트 핸들링을 강조한다. 우리는 이런 포인트를 솔라리스 커널로 설명하겠다. 솔라리스에서, 인터럽트 핸들러는 커널 스레드로서 실행된다. 높은 순위의 스케쥴링 범위는 이런 스레드들에 보존된다. 이런 우선도는 인터럽트 핸들러가 앱 코드와 커널 하우스 키핑을 넘어서게 하고 인터럽트 핸들러 사이에 상대적인 우선도를 구현한다. 우선도는 솔라리스 스레드 스케쥴러가 높은 우선 순위의 인터럽트 핸들러가 선점하고, 스레드 구현은 멀티 프로세서 하드웨어가 다양한 인터럽트 핸들러를 가능하게 한다. 리눅스와 윈도우는 20장과 21장에서 설명하겠다.

요약하면, 인터럽트는 운영체제를 통해서 비동기 이벤트를 핸들하고 커널에서의 감시자 모드 루틴을 트랩하기 위해서 사용된다. 가장 급한 일을 먼저 처리하게 하기위해서, 현대 컴퓨터들은 인터럽트 우선도의 시스템을 사용한다. 디바이스 컨트롤러, 하드웨어 폴트, 시스템 콜들은 커널 루틴을 실행하기 위해서 인터럽트를 raise한다. 인터럽트들이 시간에 민감한 프로세싱에 사용되기에, 효율적인 인터럽트 핸들링이 좋은 시스템 성능을 위해서 필요하다. 인터럽트 기반 I/O는 이제 폴링보다 더 일반적이고, 폴링이 사용되는 것은 높은 산출량 I/O에서만 쓰인다. 때떄로 두개는 공존한다. 몇몇 디바이스 드라이버는 I/O 속도가 느릴때 인터럽트를 사용하고 그것의 속도가 폴링이 빠르고 효율적일때 폴링으로 바꾼다.

### 12.2.4 Direct Memory Access

디스크 드라이브 같이 큰 전송을 하는 디바이스에서, 상태 비트를 감시하고 컨트롤러 레지스터에 한바이트씩 먹이는 비싼 범용 목적 프로세서를 사용하는 것은 낭비이다. 이런 프로세스는 **programmed I/O(PIO)**라고 불린다. 컴퓨터는 메인 CPU에 이 일을 **direct memory access**라는 특별 목적 프로세서가 이 일을 덜어가는 PIO로 무겁게하는 것을 피한다. DMA 전송을 시작하기 위해서, 호스트는 DMA 커맨드 블락을 메모리에 쓴다. 블락은 전송의 출처 포인터, 전송의 목적지 포인터, 전송될 바이트의 수를 포함한다. 커맨드 블락은 연속적이지 않은 목적 주소와 출처의 리스트를 포함함으로서 더욱 복잡해질 수 있다. **scatter-gather** 메서드는 DMA 커맨드를 이용해서 다중 전송을 허용할 수 있다. CPU는 DMA 컨트롤러에 커맨드 블록의 주소를 쓴다. DMA 컨트롤러는 메모리 버스를 직접 운영하기 위해서 진행하고, 메인 CPU의 도움 없이 전송 위해서 주소를 버스에 두는 것을 실행한다. 간단한 DMA 컨트롤러는 모든 현대 컴퓨터의 표준 구성요소이고, 스마트폰부터 메인프레임까지이다.

커널 주소공간에 타겟 주소를 두는 것이 가장 직관적이다. 만약 유저 스페이스이면, 유저는 전송중에 공간의 컨텐츠를 수정하고 몇몇 데이터를 잃게된다. 스레드 접근을 위해서 유저 공간에 DMA 전송 데이터를 얻으면, 두번쨰 복사 명령어, 커널 메모리에서 유저 메모리로의 시간이 필요하다. 시간을 지나, 운영체제는 I/O 전송을 디바이스와 유저 주소 공간이 직접적으로 실행하기 위한 메모리 매핑을 사용하기 시작했다.

DMA 컨트롤러와 디바이스 컨트롤러 간의 핸드쉐이킹은 **DMA-request**와 **DMA acknowledge**라고 불리는 한쌍의 와이어를 통해서 실행된다. 디바이스 컨트롤러는 데이터의 워드가 전송이 준비되면 DMA 리퀘스트 와이어에 시그널을 보낸다. 시그널은 DMA 컨트롤러가 메모리 버스를 설치하게 야기하고, 메모리 주소 와이어에 원하는 주소를 두고, DMA acknowledge 와이어에 시그널을 둔다. 디바이스 컨트롤러가 DMA acknowlege signal을 받으면, 그것은 데이터의 워드에 메모리를 전송하고 DMA 리퀘스트 시그널을 삭제한다.

전체 전송이 완료되면, DMA 컨트롤러는 CPU를 인터럽트한다. DMA 컨트롤러가 메모리 버스를 장악하면, CPU는 일시적으로 메인 메모리 접근으로부터 방지되고, 그것은 여전히 그것의 캐시 아이템에 접근이 가능하다. 비록 이 **cycle stealing**이 CPU 연산을 느리게하고, 데이터 전송 작업을 DMA에 넘기는 것은 전체 시스템의 성능을 향상시킨다. 몇몇 컴퓨터 아키텍처는 DMA를 위해서 물리 메모리 주소를 사용하지만, 다른 것들은 **direct virtual memory access(DVMA)**를 사용한다. 가상 주소가 물리 주소로 번역되게끔 사용한다. DVMA는 CPU의 개입 또는 메인메모리의 사용 없이 메모리 맵드 디바이스에서 전송을 실행한다.

보호받는 모드 커널에서, 운영체제는 보통 프로세스가 디바이스 커맨드를 직접 발생시키는 것을 방지한다. 이 규율은 접근 제어 침범으로부터 데이터를 보호하고 시스템 충돌을 야기하는 디바이스 컨트롤러의 잘못된 사용으로부터 시스템을 보호한다. 대신에, 운영 체제는 충분히 특권을 가진 프로세스가 하드웨어의 낮은 레벨 명령어 접근을 사용하게하는 함수를 전한다. 메모리 보호 없는 커널에서, 프로세스들은 디바이스 컨트롤러에 직접 접근이 가능하다. 이 직접 접근은 높은 성능을 성취하는데 쓰이고, 그것은 커널 통신, 컨텍스트 스위치, 커널 소프트웨어의 레이어를 회피하게 한다. 불행히도, 그것은 시스템 보안과 안정성에서 방해된다. 일반적인 범용 운영체제는 메모리와 디바이스를 보호하고 그래서 시스템은 악성 앱으로부터 에러를 방지한다.

### 12.2.5 I/O 하드웨어 요약

비록 I/O의 하드웨어는 전자공학적인 하드웨어 디자인의 디테일 레벨에서는 복잡하지만, 우리가 방금 표현한 컨셉들은 운영체제의 많은 I/O기능을 이해하는데 충분하다. 메인 컨셉을 다시보자.

- A bus
- A controller
- An I/O port and its registers
- The handshaking realtionship between the host and a device controller
- The offloading of this work to a DMA controller for large trasfers

우리는 디바이스 컨트롤러와 호스트 사이의 핸드세이킹 예제를 이 절에서 보았다. 실제로는, 존재하는 기기의 다양헝이 운영체제 구현에 문제를 발생시킨다. 각 종류의 디바이스는 그것의 능력, 컨트롤 비트 정의, 호스트와 상호작용할 프로토콜을 가지고 그들은 모두 다르다. 어떻게 운영체제를 새롭게 쓰이지 않고도 새로운 디바이스를 붙이도록 디자인할 수 있을까? 그리고 디바이스가 다양하면, 어떻게 운영체제는 간단하고, 일정한 I/O 인터페이스를 앱에게 제공할까?

## 12.3 Application I/O interface

이 절에서, 우리는 운영체제가 I/O 디바이스를 표준적이고 일정하게 다루게 해주는 인터페이스와 기술을 구조화하겠다. 우리는, 예를 들어서, 어떻게 앱이 디스크의 파일을 어떤 디스크인지 모르고 열고 새로운 디스크 또는 다른 디바이스가 운영체제의 혼란없이 컴퓨터에 추가되는지 보겠다.

다른 복잡한 소프트웨어 엔지니어링 문제처럼, 이 문제는 추상화, 캡슐화, 소프트웨어 레이어링을 포함한다. 특별히, 우리는 몇몇 일반적인 종류를 구별함으로서 I/O 디바이스의 자세한 차이를 추상화하겠다. 각 일반적인 종류들은 **interface**라는 표준 함수의 집합을 통해서 접근된다. 차이점은 특정기기에 맞춤형이지만 표준적인 인터페이스를 전달하는 디바이스 드라이버라고 불리는 커널 모듈에 캡슐화된 점이다. 

디바이스 드라이버 층의 목적은 커널의 I/O 서브시스템으로부터 드라이버 컨트롤러의 차이점을 숨기는 것이고, I/O 시스템콜은 디바이스의 행동을 앱으로부터 하드웨어의 차이를 숨기는 몇몇 제너릭 클래스에 캡슐화하는 것이다. I/O 서브시스템을 하드웨어로부터 독립적으로 만드는 것은 운영체제 개발자의 일을 단순화한다. 그것은 또한 하드웨어 생산자에게도 이득을 준다. 그들은 새로운 디바이스를 존재하는 호스트 컨트롤러 인터페이스에 적용가능하게 디자인하거나, 그들은 새로운 하드웨어를 인터페이스하는 디바이스 드라이버를 유명한 운영체제에 쓴다. 그러므로, 우리는 컴퓨터에 새로운 주변장치를 운영체제 판매자가 지원 코드를 개발하는 것을 기다릴 필요가 없어진다.

하드웨어 생산자에게 불행히도, 운영체제의 각 타입은 그들의 자체적인 디바이스 드라이버 인터페이스를 가진다. 주어진 디바이스는 다양한 디바이스 드라이버를 가지고 있다. 디바이스는 여러가지 차원을 가진다.
|aspect|variation|example|
|---|---|---|
|data-transfer mode| character, block | terminal, disk|
|access method| sequential, random| modem, CD-ROM|
|transfer schedule | synchronous, asynchronous| tape, keyboard|
|sharing | dedicated, sharable|tape, keyboard|
|device speed| latency, seek time, transfer rate, delay between operations | |
|I/O direction | read/write only, read-write | CD-ROM, graphics controller, dist|

- **Character-stream or block** character-stream 디바이스는 전송을 바이트씩하고, block 디바이스는 바이트의 블럭을 단위로 전송한다.
- **Sequential or random access** sequential 디바이스는 디바이스의 결정된 고정 순서대로 데이터를 전송하고, random access 디바이스는 존재하는 데이터 저장소의 위치를 찾아서 디바이스를 수행한다.
- **Synchronous or asynchronous** synchronous 디바이스는 데이터 전송을 예측된 반응시간안에 시스템의 다른 측면과 조정하며 수행한다. Asynchronous 디바이스는 시스템의 다른 측면과 조정하지 않기 때문에 비정규적이거나 예측불가한 반응시간을 가진다.
- **Sharable or dedicated** sharable 디바이스는 여러 프로세스 또는 스레드에 의해서 동시에 사용되지만, dedicated 디바이스는 그렇지 않다.
- **Speed of operation** 디바이스 속도는 초당 몇 바이트에서 기가바이트까지 다양하다.
- **Read-write, read only, write once** 몇몇 디바이스는 인풋과 아웃풋을 동시에 시행하지만, 다른 것들은 오직 한방향 데이터 통신을 지원한다. 몇몇은 쓰기 후에 데이터를 수정하게 허용하지만, 다른 것들은 한번쓰이면 읽기만 가능하다.

앱 접근의 목적상, 이런 차이점들은 운영체제의 뒤에 숨어있고, 디바이스들은 몇몇 관습적인 타입으로 그룹지어있다. 디바이스 접근의 결과적인 스타일을 유용하다고 알려지고 널리 적용이 가능하다. 비록 정확한 시스템콜을 운영체제마다 다르지만, 디바이스 카테고리들은 꽤 일반적이다. 주된 접근 관습은 block I/O, character-stream I/O, memory-mapped file access와 network sockets을 포함한다. 운영체제는 또한 TOD 클락과 타이머 같은 몇몇 추가적인 디바이스를 엑세스하는 특별한 시스템콜을 제공한다. 몇몇 운영체제는 graphical display, video, audio devices같은 시스템콜의 집합을 제공한다.

대부분의 운영체제들은 임의의 커맨드를 앱에서 디바이스로 투명하게 전달하는 **escape**(or **back door**)를 가진다. UNIX에서 시스템콜 `ioctl()`이다. `ioctl()` 시스템 콜은 앱이 새로운 시스템콜의 개발 필요 없이 디바이스 드라이버에 의해 구현된 모든 기능에 접근하게 허용하는 것이다. `ioctl()` 시스템 콜은 3가지 아규먼트를 가진다. 첫번째는 앱을 드라이버로 연결하는 드라이버에 의해서 관리되는 하드웨어 디바이스를 언급하는 디바이스 식별자이다. 두번쨰는 드라이버에 구현된 커맨드를 선택하는 정수이다. 세번쨰는 앱과 드라이버가 필요한 컨트롤 정보 또는 데이터를 가능하게하는 메모리의 임의의 데이터 구조 포인터이다.

LINUX와 UNIX의 디바이스 식별자는 "major와 minor" 디바이스 번호의 튜플이다. major number는 디바이스 종류이고, minor는 디바이스의 인스턴스이다. 예를 들어서, 시스템의 SSD 디바이스를 생각해보자. 만약 다음과 같은 커맨드를 입력했다. `% ls -l /dev/sda*` 그러면 다음과 같은 출력이 나온다.

```cpp
brw-rw---- root disk 8, 0 Mar 16 09 :18 /dev/sda
brw-rw---- root disk 8, 1 Mar 16 09 :18 /dev/sda1
brw-rw---- root disk 8, 2 Mar 16 09 :18 /dev/sda2
brw-rw---- root disk 8, 3 Mar 16 09 :18 /dev/sda3
```
여기서 8은 major 디바이스 번호이다. 운영체제는 이 정보를 사용해서 디바이스 드라이브의 적절한 I/O 요청을 찾아낸다. minor 번호는 0,1,2,3이고 디바이스의 인스턴스를 뜻하고, 요청의 정확한 기기를 I/O로의 요청을 선택하도록 돕는다.

### 12.3.1 Block and Character Devices

**block device interface**는 디스크 드라이브와 다른 블록 기반 디바이스에 접근하는 모든 필요한 것을 캡쳐한다. 디바이스는 `read()`와 `write()`같은 커맨드를 알아야한다. 만약 그것이 랜덤 엑세스 디바이스면, 그것은 또한 어떤 블럭이 다음에 전송될지 `seek()`을 통해서 예측한다. 앱들은 보통 디바이스를 통해서 파일 시스템 인터페이스에 접근한다. 우리는 `read()`, `write()`와 `seek()`이 블록 저장소 디바이스의 본질적인 행동을 캡쳐하는 것을 알수 있고, 그래서 앱들은 이런 디바이스 사이에서 낮은 레벨 차이를 보호한다.

운영체제 자체적으로, 데이터 베이스 관리 시스템 같은 특별한 앱들은 단순한 선형 블럭의 행렬로 블럭 디바이스에 접근하느 것을 선호한다. 접근의 모드는 가끔 **raw I/O**라고 불린다. 만약 앱이 그것의 버퍼링을 수행중이면, 파일 시스템을 사용하는 것은 추가적이고, 불필요한 버퍼링이 될 것이다. 이와 같이, 만약 앱이 그것의 블럭 또는 리전의 락을 제공하면, 운영체제 락 서비스는 최소일떄는 불필요하고 최악일때는 모순적일 것이다. 이런 충돌을 피하기 위해서, raw-디바이스 접근은 디바이스의 제어권을 앱에 직접 건내주고, 운영체제가 한발 물러서게 한다. 불행히도, 이 디바이스에 대해서 어떠한 운영체제도 실행하지 않게 된다. 일반적인 것이되는 타협은 운영체제 시스템으로 하여금 버퍼링과 락을 비활성화해서 파일에 명령어의 모드를 허용한다. 유닉스 세계에서는, 이것은 **direct I/O**라고 불린다.

메모리 맵드 파일 접근은 블록 디바이스 드라이브의 꼭대기에 존재한다. 읽기와 쓰기 명령어를 제공하기보다는, 메모리 맵드 인터페이스는 메인 메모리의 바이트 행렬을 통해서 디스크 저장소에 접근하게 한다. 파일을 메모리에 매핑하는 시스템콜은 파일의 복사본을 포함하는 가상메모리 주소를 리턴한다. 실제 데이터 전송은 오직 메모리 이미지에 접근을 만족할때 일어난다. 전송이 디맨드 페이지 가상 메모리 접근과 같은 메커니즘에 의해서 핸들되기 때문에, 메모리 맵드 I/O는 효율적이다. 메모리 매핑은 또한 프로그래머에게 간편한데, 메모리 맵드 파일로의 접근은 메모리로부터 읽기와 메모리에 쓰기가 간단하다. 가상 메모리를 제공하는 운영체제는 커널 서비스의 매핑 인터페이스를 일반적으로 사용한다. 예를 들어서, 프로그램을 실행하려면, 운영체제는 메모리에 실행가능한 파일을 매핑하고 실행가능한 파일의 엔트리 주소로 컨트롤을 전송해야한다. 매핑 인터페이스는 보통 커널 엑세스가 디스크에서 공간을 스왑할때 자주 쓰인다.

키보드는 **character stream interface**로 접근하는 디바이스의 예시다. 이 인터페이스의 기본 시스템콜은 앱이 한 단어를 `get()` 또는 `put()`하게 하는 것이다. 이 인터페이스의 상단에, 라이브러리는 버퍼링과 수정 서비스를 가진 line at a time 접근을 가진다.(우리가 백스페이스를 치면, 인풋 스트림의 이전 글자는 제거된다.) 이 접근의 스타일은 동시에 인풋을 만드는 키보드, 마우스, 모뎀 같은 인풋 디바이스에 편리하다. 즉, 앱에 의해서 정확하게 예측이 될 수가 없다. 이 엑세스 스타일은 또한 프린터, 오디오보드 같은 바이트의 리니어 스트림 개념에 맞는 아웃풋 기기에도 좋다.

### 12.3.2 Network Devices.

네트워크 I/O의 성능과 주소 방식이 disk I/O에 따라서 다르기 때문에, 대부분의 운영체제는 네트워크 I/O 인터페이스에서 디스크에 사용된 `read()`-`write()`-`seek()` 인터페이스와 다르게 제공한다. 많은 운영체제에서 보이는 한가지 인터페이스는 네트워크 **socket** 인터페이스이다.

전기를 위한 wall socket을 생각해보자. 전기 기구는 플러그인될 수 있다. 비유하면, 소켓 인터페이스의 시스템 콜은 앱이 소켓을 만들고, 먼 주소에 로컬 소켓을 연결하고, 멀리 있는 앱에 로컬 소켓을 플러그해서 듣게하고, 연결을 통해서 패킷을 주고 받는다. 네트워크 서버의 구현을 지원하기 위해서, 소켓은 소켓의 집합을 관리하는 `select()`라는 함수를 제공한다. `select()`콜은 어떤 소켓이 수신 대기중인 패킷을 가지고 있는지, 어떤 소켓이 보낼 패킷을 허용할 공간을 가지고 있는지에 대한 정보를 리턴한다. `select()`의 사용은 네트워크 I/O에 어쩌면 필요한 폴링과 비지 웨이팅을 제거한다. 이런 함수들은 존재하는 네트워크 하드웨어와 프로토콜 스택에 사용하는 분산 앱의 생성을 가능하게하는 네트워크의 주요한 행동을 캡슐화한다.

IPC와 네트워크 통신에 많은 접근이 구현되었다. 예를 들어서, 윈도우는 네트워크 인터페이스 카드에 한가지 인터페이스를 제공하고 두번쨰 인터페이스는 네트워크 프로토콜을 제공한다. 유닉스에서는, 네트워크 기술의 검증을 했고, 우리는 half duplex pipe, full duplex FIFOs, full duplex STREAMS, 메시지큐, 소켓등이 있다. 

### 12.3.3 Clock and Timers

대부분의 컴퓨터들은 3가지 기본 함수를 제공하는 하드웨어 클락과 타이머를 가진다.
- 현재 시간을 제공한다.
- 경과한 시간을 제공한다.
- 시간 T에 명령어 X를 실행할 타이머를 세팅한다.

이런 함수들은 운영체제와 시간 정보가 필요한 앱들에 의해서 많이 사용된다. 불행히도, 이런 기능을 구현하는 함수들은 운영체제에서 일정하게 구현되지 않았다.

하드웨어는 경과한 시간을 측정하고 **programmable interval timer**라고 불리는 명령어를 실행한다. 그것은 특정 시간을 기다리도록 세팅하고 인터럽트를 생성하고, 그것은 한번또는 여러번 프로세스가 주기적인 인터럽트를 발생하게 세팅한다. 스케쥴러는 이 메커니즘을 프로세스의 타임슬라이스에 선점하는 인터럽트를 생성하기 위해서 이용한다. 디스크 I/O 서브시스템은 디스크에 더러운 캐시버퍼를 주기적인 플러시하기 위해서 사용하고, 네트워크 서브시스템은 네트워크 혼잡또는 실패로 인해서 너무 느린 일을 취소하기 위해서 사용한다. 운영체제는 유저 시간에 유저 프로세스에 대한 인터페이스를 제공한다. 운영체제는 가상 클락을 시뮬레이팅 함으로서 타이머 하드웨어의 채널보다 많은 수의 타이머 리퀘스트를 지원한다. 그렇게 하기 위해서, 커널(또는 타이머 디바이스 드라이버)는 유저 리퀘스트와 루틴에 의해서 원하는 인터럽트의 리스트를 유지하고, earliest time first order로 정렬한다. 그것은 타이머를 가장 빠른 시간에 맞춘다. 타이머가 인터럽트하면, 커널은 요청자에게 시그널을 보내고 다음 이른 시간을 타이머에 재 로딩한다.

컴퓨터는 다양한 목적으로 사용되는 클락 하드웨어를 가진다. 현대 PC들은 10메가 헤르츠의 범위의 속도로 작동하는 **high performance event timer(HPET)**를 포함한다. 그것은 그들이 가진 값과 HPET의 값을 매칭하는 한번또는 여러번 실행되도록 세팅가능한 비교측정기를 가진다. 트리거는 인터럽트를 발생시키고, 운영체제의 클락 관리 루틴은 타이머가 무엇이었는지 결정하고 어떤 액션을 취할지 결정한다. 트리거의 정확도는 타이머의 해상도에 제한되고, 가상 클락의 유지 오버헤드도 포함된다. 더 나아가, 만약 타이머 틱들이 시스템 tod 클락을 유지하는데 사용하면, 시스템 클락은 표류한다. Drift는 **network time protocol**같은 컴퓨터의 클락을 원자 시계 레벨과 거의 일치하게 지연 시간을 계산하는데 사용하는 목적의 프로토콜을 이용해서 수정이된다. 대부분의 컴퓨터에서, 하드웨어 클락은 높은 주기 카운터에의해서 건설된다. 몇몇 컴퓨터들에서, 카운터의 값은 디바이스 레지스터로부터 읽을수 있고, 카운터는 높은 해상도 클락으로 고려된다. 비록 클락은 인터럽트를 만들지 않지만 그것은 시간 간격의 정확한 측정을 제공한다.

### 12.3.4 Nonblocking and Asynchronous I/O