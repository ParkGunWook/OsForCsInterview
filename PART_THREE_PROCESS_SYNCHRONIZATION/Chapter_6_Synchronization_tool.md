# what we gonna study

**Cooperating process**는 시스템에서 존재하는 다른 프로세스에게 영향을 주거나 받는 것이다. 협업 프로세스들은 논리적인 주소공간을 직접 공유하거나 공유 메모리 또는 메시지 패싱만으로 데이터를 공유할 수도 있다. 공통 데이터에 동시 접근은 데이터 불완전성을 초래할 수 있다. 이 장에서는, 우리는 협업 프로세스들이 순서대로 작동하게 하는 다양한 메커니즘을 배워서, 데이터 일관성을 유지시키겠다.

# Objectives

- 임계-영역 문제와 레이스 컨디션에 대해서 설명한다.
- 하드웨어 솔루션인 메모리 베리어, 컴패어-스왑 명령어, atomic 변수로 임계영역 문제 해결법 설명하겠다.
- 뮤텍스 락, 세마포, 모니터, condition variables로 임계영역 문제를 해결하겠다.
- low, moderate, high 경쟁 상황에 따른 임계영역 문제 해결 툴을 측정하겠다.

## 6.1 Background

우리는 concurrently or parallel하게 작동하는 프로세스를 보았다. 3.3.2 절에서는 프로세스 스케쥴링의 역할을 소개하고 어떻게 CPU 스케쥴러가 빠르게 스위칭하면서 concurrent하게 작동하는지 보여줬다. 실제로, 이것은 한개의 프로세스가 다른 프로세스가 스케쥴되기전에 부분적으로 완료할 수 있다는 것이다. 실제로, 프로세스는 특정 명령어의 스트림에서 인터럽트되고, 프로세싱 코어는 다른 프로세스의 명령어를 할당한다. 4.2절에서는 병렬 실행, 두개의 명령어 스트림이 구별된 코어에서 나오는 것을 보였다. 이 챕터에서는, 우리는 어떻게 병렬 실행이 몇가지 프로세스가 공유하는 데이터의 무결성에 이슈를 만드는지 설명하겠다.

어떻게 이런 일이 생기는지 알아보자. 3장에서, 우리는 연속 협업 프로세스 또는 스레드의 모델을 보았고, 비동기로 작동하고 데이터를 공유했다. 우리는 생산자-소비자 문제로 모델을 설명했고, 운영체제 함수의 대표 패러다임이다. 특별하게도, 3.5절에서, 우리는 메모리를 공유하기 위해서 프로세스에 바운디드 버퍼를 주는 것을 설명했다.

우리는 이제 바운디드 버퍼의 고려로 돌아오겠다. 말했듯이, 우리의 본래의 해결책은 BUFFER_SIZE-1의 아이템이 버퍼에 있을떄였다. 우리가 이 알고리즘의 결점을 감소하려고 수정해보겠다. 한가지 가능성은 정수 변수, 카운트를 0으로 초기화하는 것이다. 카운트는 새로운 아이템이 버퍼에 들어올때마다 증가하고 빠질때마다 감소한다. 

생산자 코드는 다음과 같다.

```c
while(true){
    /* produce an item in next produced */
    
    while(count == BUFFER_SIZE) ;
    
    buffer[in] = next_produced;
    in = (in +1) % BUFFER_SIZE;
    count++;
}
```

소비자 코드는 다음과 같다.

```c
while(true) {
    while(count == 0) ;

    next_consumed = buffer[out];
    out = (out +1) % BUFFER_SIZE;
    count--;
}
```

비록 생산자와 소비자 루틴이 개별적으로는 옳아보이지만, 그들은 동시에 작동할때 문제가 생길 수 있다. count의 값이 현재 5이고 생산자와 소비자가 동시에 "count++", "count--"를 실행한다고 생각해보자. 두개의 실행은, 4 또는 5 또는 6이 될 수 있다. 기계어로 count++이 해석될때에 총 3가지 단계를 다음과 같이 가진다. 그리고 이 기계어가 순서에 맞지 않게 끼워지면 문제가 생기는 것이다.

> register_1 = count
> register_1 = register_1 + 1
> count = register_1

우리는 우리가 두개의 프로세스가 count 변수를 동시에 조작해서 문제가 된것을 알고있다. 몇가지 프로세스가 같은 데이터를 동시에 접근하고 조작하는 상황에서는 실행의 결과는 접근이 일어난 시점의 특정한 순서에 따라서 달라지고 **race condition**이라고 부른다. 이런 race condition을 막기위해서는, 우리는 count를 동시에 한개의 프로세스만 조작하게하면된다. 이것을 보장하기 위해서, 우리는 프로세스가 몇가지 방식으로 동기화 되게 한다.

운영체제에서는 시스템의 다른 파트가 자원을 관리할때 자주 일어난다. 더욱이, 우리가 앞서 언급했듯이, 멀티코어 시스템의 발전은 멀티스레드 앱의 개발의 중요성을 올렸다. 이런 앱에서, 데이터를 공유하는 몇가지 스레드들은 다른 프로세싱 코어에서 병렬로 작동중이다. 확실하게, 우리는 이런 활동들이 다른 것을 방해하는 변화를 원하지 않는다. 이 이슈의 중요성 때문에, 우리는 **process synchronization**과 **coordination**에 많은 투자를 했다.


## 6.2 Critical-Section Problem

우리는 프로세스 동기화의 첫 번째 고려를 임계-영역 문제로 시작하겠다. n개의 프로세스를 가진 시스템을 생각하겠다. 각각의 프로세스는 **critical-section**이라는 공유된 데이터가 하나 이상의 프로세스에게 접근되고 업데이트되는 코드의 부분이 있다. 시스템의 중요한 기능은,한 프로세스가 임계영역을 실행중이면, 다른 프로세스는 임계영역을 실행하는게 허용되지 않는다. 각 프로세스는 그것의 임계영역에 들아가기전에 승인 요청을 해야한다. 이런 요청을 하는 코드를 **entry section**이라고 한다. 그리고 임계영역 후에는 **exit section**을 가진다. 나머지 코드는 **remainder section**이라고 부른다. 

3가지 조건으로 임계영역 문제를 해결할 수 있다.

1. Mutex exclusion - 만약 P1이 임계영역을 실행중이면, 다른 프로세스들은 그들의 임계영역을 실행할 수 없다.
2. Progress - 만약 프로세스가 임계영역을 실행중이지 않고 몇몇 프로세스가 임계영역 실행을 원하면, 그들의 잔여 섹션를 실행중이지 않은 코드들중 하나가 선택되어서 임계영역을 실행한다. 그리고 이 선택은 무기한으로 연기될 수 없다.
3. Bounded waiting - 만약에 바운드, 리미트가 시간에 따라 존재하면, 다른 프로세스들은 프로세스가 임계영역에 입장 요청을 보낸후에 그들의 임계 영역에 들어가는 것을 허용받는다.

프로세스들은 0이 아닌 속도로 실행중이라고 가정한다. 그러나 우리는 n프로세스의 상대적인 속도를 추측할 수 없다.

주어진 시점에서, 많은 커널 모드 프로세스는 운영체제 안에서 활동중이다. 결과적으로, 운영체제를 구현하는 코드(커널 코드)는 몇가지 레이스 컨디션을 만들수 밖에 없다. 커널 데이터 구조가 시스템에서 오픈 파일의 리스트를 유지한다. 이 리스트는 반드시 새로운 파일이 열리고 닫히면 수정되어야한다. 만약 두가지 프로세스들이 파일을 열려고하면, 리스트를 향한 분리된 업데이트는 레이스 컨디션을 유발한다. 

다른 예시는 두가지 프로세스 P0와 P1이 fork() 시스템 콜로 자식 프로세스를 만든다고 생각하자. 이 예제에서, 다음의 프로세스 식별자의 값인 커널 변수 next_available_pid에서 레이스 컨디션은 생길수 있다. 상호 배제가 없다면, 같은 프로세스 식별자가 두개의 분리된 프로세스에 배정된다.

레이스 컨디션을 잘 일으키는 다른 커널 데이터 구조는 메모리 할당을 위한 구조, 프로세스 리스트 관리, 인터럽트 핸들링을 포함한다. 이것은 커널 개발자에게 운영체제가 레이스 컨디션에 자유롭도록할지 달려있다.

임계 영역 문제는 싱글 코어 환경에서는 만약 공유 변수가 실행중일때 인터럽트를 방지함으로서 간단하게 해결할수있다. 이런 방법으로, 우리는 현재 명령어의 시퀀스가 선점없이 명령의 순서를 지키게 할수 있다. 다른 명령어들은 실행되지 않고, 예측하지 못한 변경은 생기지 않을 것이다.

불행히도, 이 해결책은 멀티프로세서 환경에서는 적절하지 않다. 멀티 프로세서에 대해서 인터럽트를 비활성화하는 것은 모든 프로세스끼리 메시지를 주고 받아야해서 비용이 많이 든다. 이 메시지 패싱은 임계영역에 들어갈때마다 딜레이시키고, 시스템 효율성은 감소한다. 또한 시스템의 클락이 인터럽트에 의해서 업데이된다면 그 효과를 생각해보아라.

두가지 방법이 운영체제에서 임계영역을 다루기 위해서 사용된다. **Preemptive kernels**과 **Nonpreemptive kernels**이다. 선점 커널은 커널 모드 실행중에 선점이 가능하게 허용하고 비선점은 커널에서 실행중인 프로세스가 선점되지 않게 한다. 커널 모드 프로세스는 커널 모드를 종료, 블락, 자발적으로 CPU의 컨트롤을 포기할때까지 실행된다.

명백하게, 비선점 커널은 커널 데이터 구조에서 레이스 컨디션으로 부터 자유로운데, 한개의 프로세스가 커널에서 한개만 실행되기 때문이다. 우리는 선점 커널에서는 같게 얘기하지 못하는데, 그들은 공유 커널 데이터를 레이스 컨디션으로부터 자유롭도록 보장해야한다. 선점 커널들은 SMP 디자인에서 특히 디자인하기 힘든데, 두개의 커널 모드 프로세스가 CPU 코어에서 동시에 실행할수있기 때문이다.

왜, 우리는 선점을 비선점보다 선호할까? 선점 커널은 더욱 반응성있고, 커널 프로세스가 너무 길게 작동하기전에 기다리는 프로세스를 위해서 포기하기 때문이다. 더욱이, 선점 커널은 리얼타임 프로그래밍에 적합하고, 리얼 타임 프로세스는 커널에서의 프로세스를 선점한다.

## 6.3 피터슨 솔루션

다음으로, 우리는 피터슨 솔루션이라는 임계영역 문제를 해결하는 소프트웨어 기반 해결법을 보겠다. 현대 컴퓨터 구조가 *load*나 *Store*같은 기본 기계어 명령어로 작동하기에, 우리는 피터슨의 해결책이 이런 구조에서 잘 작동한다는 보장이 없다. 그러나, 우리는 이 해결법이 임계영역을 해결하는 좋은 알고리즘 설명이 있고 소프트웨어를 디자이할 때 상호 배제, 프로그레서, 바운디드 웨이팅의 필요를 알려주는 복잡성을 보이기 때문에 소개하겠다. 

피터슨 해결법은 임계영역과 나머지 영역을 번갈아가며 실행하는 두개의 프로세스로 제한된다. 프로세스의 이름은 j = 1-i인 P_i와 P_j로 대표된다.

피터슨 방법은 두개의 프로세스가 turn과 flag[2]라는 2개의 데이터 아이템을 공유하도록 한다. 
```c
while(true) {
    flag[i] = true;
    turn = j;
    while(flag[j] && turn == j) ;
        
        /* critical section */
    
    flag[i] = false;

        /* remainder section */
}
```
여기서 변수 turn은 임계영역에 들어가야하는 프로세스의 차례를 알린다. 즉, 만약 turn == i이면, P_i가 임계영역에서 실행되도록 허가된다. flag 행렬은 만약 프로세스가 그것의 임계영역으로 들어갈 준비가 되었는지를 알리기 위해서 사용된다. 예를 들어서, 만약 flag[i]가 참이면 P_i가 임계영역에 들어가 준비가 되었다. 

P_i가 임계영역에 들어갈려면 flag[i]는 참이고 turn은 j여야하고, 만약 다른 프로세스가 임계영역에 들어가기를 주장하면, 그것은 가능하다. 만약 두개의 프로세스가 같은 시간에 들어가려하면, turn은 꽤나 같은 시간에 i와 j로 세팅될수 있다. 오직 하나의 할당만 남는다. 다른 것은 즉시 덮어쓰일 것이다. turn의 값은 마침내 두 프로세스중 어떤 것이 먼저 임계영역에 들어갈지 허가할 것이다.

우리는 이 해결법이 옳다고 증명하겠다.

1. 상호배제는 보장된다.
2. Progress 필요는 만족된다.
3. 바운디드 대기또한 만족된다.

1번째 영역은, 우리가 P_i가 오직 flag[j] == false or turn == i일때 접근한다는 것을 알고있다. 또한, 만약 두개의 프로세스가 임계영역 실행중이면, flag[0]==flag[1]==true일 것이다. 이 두개의 관측은 P0와 P1이 그들의 while 문을 정상적으로 작동하지 못한다는 것인데, turn의 값은 0또는 1일수 밖에 없기 때문이다. 따라서, 한개의 프로세스는 반드시 while문을 실행중이어야하는 것이다. 반면에 P_i는 적어도 하나의 추가적인 명령어를 ("turn==j") 실행해야한다. 그러나, flag[j] == true이고 trun ==j이면, P_j는 임계영역에 있을 것이다. 결과적으로 상호배제를 시킨 것이다.

두번째 영역과 세번째 영역을 증명하려면, P_i는 만약 flag[j] == true and turn==j의 while 상태에 빠져서 임계영역에 못들어간다는 것을 명심해야한다. 루프는 오직 한가지 가능성만 있다. 만약 P_j가 준비되지 않으면, flag[j] == false일 것이고, P_i는 임계영역에 들어간다. 만약 P_j가 flag[j]를 참으로하고 while문을 실행중이라면, turn==i or turn==j일 것이다. 만약에 turn == i이면, P_i가 임계영역에 들어간다. 만약에 turn == j이면 P_j가 실행된다. 그러나, P_j가 임계영역을 탈출하면, flag[j]는 거짓으로 리셋되고 또한 P_i가 임계영역으로 진입하게 한다. 만약 P_j가 flag[j]를 참으로 설정하면, 그것은 또한 turn을 i에게 줄것이다. 그러므로, P_i는 아무런 값을 바꾸지 않아도 P_i는 임계영역으로 진입하게 되고(Progress) P_j에 의해서 진입을 한다.(bounded waiting)

앞의 절에서 말했듯이, 피터슨 해결법은 현대 컴퓨터 구조에서는 작동이 보장되지 않는다. 시스템 성능을 향상시키기 위해서, 프로세서/컴파일러들은 의존성없는 read와 write를 재배치하기 때문이다. 싱글 스레드 앱을 위해서, 이 재배치는 프로그램이 최종값이 예상한것과 일치하게 할당되는 정확한 동작을 하기에 중요하지 않다.(이것은 수표장부를 밸런싱하는것과 비슷하다. 인출과 입금의 순서는 중요하지 않고 마지막 잔액이 중요한 것이다.) 그러나, 공유 데이터를 사용하는 멀티 스레드 앱에서는, 명령어의 재배치는 불일치와 예상하지 못한 결과를 초래할 수 잇다.

예를 들어서, 두개의 스레드 간에 공유되는 데이터로 아래와 같이 초기화된다.
`boolean flag = false;  int x = 0;`
스레드 1은 다음 문장을 실행한다.
`while(!flag);    print x;`
그리고 스레드 2는 다음을 실행한다.
`x = 100;    flag = true;`
예상되는 행동은 물론, 스레드 1에서 변수 x는 출력 결과가 100이 되는 것이다. 그러나 flag와 x사이에 아무런 의존성이 없기 때문에, 프로세서는 스레드 2의 명령어를 재배치할 수 있다. 그래서 flag가 참으로 배치되고 x가 100으로 할당된다. 이런 상황에서, 스레드 1은 0을 결과로 내게된다. 덜 중요한 것은 프로세서는 스레드 1을 다시 재배치해서 flag를 불러오기전에 x의 값을 불러올 수 있는 것이다. 이게 일어나면 x가 스레드2에서 재배치되지 않아도 0을 출력하게 된다.

이게 어떻게 피터슨 해결법에 영향을 줄까? 만약 피터슨 해결법의 entry section의 두개의 명령어가 재배치되면 무슨일이 일어날까? 그러면 두개의 스레드가 동시에 임계영역에서 활동할 수 있다.

다음 절에서 우리는, 적절한 동기화 도구를 이용해서 상호배제를 만족시키겠다. 이런 툴은 원시적인 하드웨어 지원과 커널 개발자와 앱 프로그래머 모두가 쓸수있는 추상화, 하이 레벨, 스프트웨어 기반 API를 통해서 만들어낸다.

## 6.2 동기화를 위한 하드웨어 지원

우리는 임계 영역 문제 해결을 위한 소프트웨어 기반을 설명했다.(*소프트웨어 기반*이라는 이유는 알고리즘이 운영체제 또는 특정 하드웨어 명령어을 포함하지 않기 때문이다.) 그러나, 말했듯이, 소프트웨어 기반 해결법은 현대 컴퓨터 구조에서 제대로 작동한다는 보장이 없다. 이 절에서는, 우리는 임계영역 문제 해결을 위한 3가지 하드웨어 명령어를 소개하겠다. 원시적인 명령어는 직접 동기화 툴로 사용되거나, 그들은 추상적인 동기화 메커니즘의 기초로서 사용될 수 있다.

### 6.4.1 메모리 배리어

6.3절에서는, 우리는 시스템이 명령어를 재배치할 수 있고, 이 정책은 신뢰할수 없는 데이터로 이끈다. 컴퓨터 구조가 어떤 메모리가 보장될지 결정하는 기능을 가진 프로그램을 **memory model**이라고 한다. 일반적으로, 메모리 모델은 2가지 카테고리로 나뉜다.

1. Strongly ordered - 프로세서에서의 메모리 수정은 다른 모든 프로세서에 즉시반영이 된다.
2. Weakly ordered - 프로세서의 메모리 변경이 다른 프로세서에 즉시 보이지 않는다.

메모리 모델은 프로세서 타입에 따라 다르고, 커널 개발자들은 공유 메모리 멀티 프로세서에서의 메모리 수정의 가시성에 따라서 가정을 할 수 없다. 이 문제를 해결하기 위해서, 컴퓨터 구조는 어떤 메모리에서의 변경이든 모든 프로세서에 알리는 명령어를 제공함으로서, 메모리 수정이 다른 프로세서에서 작동하는 모든 스레드가 반영하게 해준다. 이런 명령어는 **memory barriers** 또는 **memory fences**라고 불린다. 메모리 베리어 명령어가 실행되면, 시스템은 모든 로드와 스토어가 뒤따라오는 로드와 스토어 이전에 완료되는 것을 보장한다. 그러므로, 만약 명령어가 재배치 되어도, 메모리 배리어가 스토어 명령어가 다른 프로세서에게 읽히기 이전에 완료되는 것을 보장한다. 

이제 명령어의 재배치가 잘못된 아웃풋을 보이는 예제를 메모리 배리어로 해결해보겠다.

만약 우리가 스레드 1에 메모리 배리어를 추가한다면
`while(flag) memory_barrier();  print x;`
우리는 플래그의 값이 x의 값이 로드 되기 이전에 로드되는 것을 보장할 수 있다.

비슷하게 만약 우리가 스레드 2의 할당사이에 메모리 배리어를 두겠다.
`x = 100;  memory_barrier();   flag = true;`
우리는 x의 할당이 flag이전에 할당되는 것을 보장하게 된다.

이런 관점에서 피터슨 해결법을 쓴다면, 우리는 entry 섹션에서의 두개의 할당사이에 메모리 베리어를 두어서 명령어의 재배치를 피할 수 있다. 메모리 배리어는 low-level 명령어이고 오직 커널 개발자만이 상호배제를 위해서 쓸 수 있다.

### 6.4.2 하드웨어 명령어

많은 현대 컴퓨터 시스템은 워드의 내용물을 테스트하고 수정하거나 두 워드의 내용물을 **atomically** 바꾸는 특별한 하드웨어 명령어를 제공한다. 우리는 이런 특별한 명령어를 임계영역 문제를 간단하게 해결할때 많이 쓰인다. 특정한 머신을 위해서 특정한 명령어를 사용하는 것보다는, 우리는 test_and_set()과 comapre_and_swap() 명령어로 이런 종류의 명령어를 추상화하는 주요한 개념을 추상화했다.

```cpp
bool test_and_set(bool *target){
    bool rv = *target;
    *target = true;

    return rv;
}
```

```cpp
do{
    while(test_and_set(&lock)) ;

    /* critical section */

    lock = false;
}while(true);
``` 

test_and_set() 명령의 가장 중요한 요소는 그것이 atomically하게 실행되는 것이다. 그러므로, 만약에 두개의 test_and_set() 명령어가 동시에 작동한다면, 그들은 몇가지 임의의 순서로 연속적으로 실행될 것이다. 만약에 기계가 test_and_set() 명령어를 지원한다면, 우리는 상호배제를 불 변수 lock를 거짓으로 선언함으서 구현할 수 있다.

```cpp
int compare_and_swap(int *value, int expected, int new_value){
    int temp = *value;

    if(*value == expected) 
        *value = new_value;
    
    return temp;
}
```

```cpp
while(true){
    while(compare_and_swap(&lock, 0, 1) != 0) ;

    /*critical section */

    lock = 0;
    
    /*remainder section */
}
```

compare_and_swap() 명령어는 test_and_set()명령어처럼, 두개의 워드에서 atomically 수행되지만, 두개의 워드의 내용을 바꾼다는 것에서 다른 메커니즘이다. 

CAS 명령어는 3가지 피연산자를 사용한다. value는 오직 (*value == expected) 일때만 new_value로 설정된다. 무관하게, CAS는 항상 value의 원래 값만 리턴한다. 이 명령어의 중요한 특성은 그것이 atomically 실행된다는 것이다. 그러므로, 만약 두개의 CAS가 동시에 작동하면, 그들은 임의의 순서로 연속적으로 실행된다.

CAS를 이용한 상호배제는 다음과 같다. 전역 변수(lock)는 0으로 초기화된다. compare_and_wap()을 실행하는 첫번째 프로세스는 lock을 1로 설정한다. 그것은 그것의 임계 영역에 들어가고, 기본의 lock은 여전히 예측한 값 0과 같기 때문이다. 프로세스가 그것의 임계영역을 탈출하면, lock는 다시 0이되고, 다른 프로세스가 그것의 임계영역에 들어가게 허용한다. 

```cpp
while(true) {
    waitin[i] = true;
    key = 1;
    while(waiting[i] && key == 1)
        key = compare_and_swap(&lock, 0, 1);
    waiting[i] = false;

    /* critical section */

    j = (i+1) % n;
    while( (j != i) && !waiting[j] )
        j = (j+1) % n;

    if(j==i)
        lock = 0;
    else
        waiting[j] = false;
    
    /*remainder section */
}
```
비록 이 알고리즘이 상호배제를 만족하지만, 그것은 바운디드 웨이팅은 만족하지 못한다. 우리는 모든 임계 영역 조건을 만족하는 것을 만들었다. 여기서 공통 데이터 구조는 다음과 같다.
`bool waiting[n];   int lock;`
waiting 행렬의 원소는 false로 초기화 되고, lock는 0으로 초기화 된다. 상호 배제가 충족되는 것을 입증하기 위해서, 우리는 P_i가 임계영역에 들어갈 때는 오직 waiting[i] == false or key == 0일 때이다. compare_and_swap()은 실행되면 key의 값은 0이 된다. 이를 통해서 다른 것들은 key가 0이므로 계속 대기할 것이다. 만약 waiting[i]가 거짓이 되는 것은 오직 다른 프로세스가 임계영역을 벗어났을 때이다. 따라서 상호-배제가 만족된다.

프로그레스 조건이 만족됨을 보이기 위해서, 우리는 상호배제에서 쓴 방법을 다시 생각해서, 임계영역을 탈출할때 lock이 0이되거나 waiting[j]가 거짓으로 될 것이다. 두가지는 모두 다른 대기중인 프로세스가 다음으로 임계영역에 들어가는 것을 허용한다.

바운디드 웨이팅을 만족하기 위해서는, 우리는, 프로세스가 임계영역을 떠날때, 그것은 waiting 행렬을 스캔하는 것을 고려할 수 있다. 그것은 이 순서의 첫번쨰 프로세스가 entry 섹션에 있으면 다음 것을 바로 임계영역에 들어가게 해준다. 어떤 대기중인 프로세스도 n-1안에 그 차례에 돌아가게 할 수 있다.

test_and_set()과 compare_and_swap()은 컴퓨터 구조에 관한 책에서 더욱 깊게 소개될 것이다.

### 6.4.3 Atomic Variables

일반적으로, CAS 명령어는 상호배제를 위해서 잘 쓰이지 않는다. 오히려 그것은 임계영역을 해결하는 다른 툴을 위한 기본적인 블락으로 쓰인다. 그러한 한가지 툴이 **atomic variable**이다. 이것은 인티저나 불값에 대해서 기본적인 atomic operation을 제공한다. 우리는 6.1에서 상수값을 증가/감소하는 것이 레이스 컨디션을 유발할 수 있다고 했다. 아토믹 변수는 한가지 데이터가 업데이트되면서 레이스 상황에 처할 때 상호배제를 확실하게 해줄때 쓰인다.

대부분의 시스템은 아토믹 변수를 특별한 아토믹 데이터 타입(아토믹 변수에 접근하고 조작하는 함수를 포함)으로 제공한다. 이런 함수들은 보통 CAS 명령어로 구현된다. 예시에서는 아토믹 정수 sequence가 증가되는 것을 보이겠다.
`increment(&sequence);`
여기서 increment함수는 CAS를 통해서 구현된다.
```c
void increment(atomic_int *v)
{
    int temp;

    do{
        temp = *v;
    }\
    while( temp != compare_and_swap(v, temp, temp+1) );
}
```

아토믹 변수는 아토믹 업데이트를 제공한다. 그들은 모든 상황에서 레이스 컨디션에 빠지지 않는다. 예를 들어서, 바운디드 버퍼 문제에서, 우리는 아토믹 정수를 count에 쓸 수 있다. 이렇게 해서 count는 atomic하게 업데이트된다. 그러나 생산자-소비자 프로세스는 또한 count의 값에 따라서 while 루프에 빠진다. 버퍼가 현재 비었고 두명의 소비자가 count>0이길 기다린다고 가정한다. 만약 생산자가 버퍼에 하나의 아이템을 넣으면 두 소비자는 while루프를 소비하려고 나온다. 물론 count는 1일 뿐이다.

아토믹 변수는 비록 그것이 카운터나 연속 생산자같은 공유데이터에만 쓰일수 있어도 운영체제에서 많이 쓰인다. 다음 절에서는, 더 좋은 툴을 보겠다.

## 6.5 Mutex Locks

6.4절에서 하드웨어 기반의 임계 영역 문제는 앱 프로그래머가 접근하기 힘들다. 대신에, 운영체제 디자이너는 하이레벨 소프트웨어 툴을 임계영역 문제 해결을 위해서 제공한다. 가장 간단한 도구는 **Mutex lock**이라고 한다. 우리는 뮤텍스 락을 임계영역 보호와 레이스 컨디션 방지를 위해서 사용한다. 즉, 프로세스는 반드시 임계영역에 도달하기 전에 락을 얻어야한다. 그리고 임계영역 종료휴에 락을 해제한다. acquire()함수는 락을 얻고, realease() 함수는 락을 해제한다.

뮤텍스 락은 *available*이라는 락이 있는지 없는지 알리는 불 변수를 가진다. 만약 락이 가용하면, acquire()은 성곤하고 락은 불가용해진다. 불가용한 락을 요청하는 프로세스는 락이 해제될때까지 블락된다.

acquire()의 정의는 다음과 같다.
```cpp
acquire(){
    while(!available) ; /* busy wait */
    available = false;
}
```
release()는 다음과 같다.
```cpp
release(){
    available = true;
}
```

acquire()와 realease()는 반드시 아토믹하게 실행되어야한다. 그러므로, 뮤텍스 락은 CAS 명령어를 이용해서 구현되고 우리는 이 기술의 설명을 예제로 두었다.

여기서 구현된 것의 가장 큰 문제는 **busy waiting**을 필요로 하는 것이다. 프로세스가 그것의 임계영역에 있는 동안, 그것의 임계영역에 들어가려는 프로세스는 반드시 acquire() 콜안의 루프에 갇혀야한다. 이 반복되는 루프는 한개의 CPU 코어가 많은 프로세스들에게 공유되는 멀티프로그래밍 시스템에서 확실히 문제가 된다. busy wait는 또한 다른 프로세스가 생산적으로 일할 수 있는 CPU 사이클을 낭비한다.(6.6절에서, 우리는 이 busy wait를 회피하는 방법을 보여주겠다.)

뮤텍스 락의 종류는 또한 **spin-lock**이라고도 불리는데 왜냐하면 프로세스가 락을 기다리는 동안 "spin"하기 때문이다. 스핀락은 장점이있는데, 락을 기다리는 프로세스에 대해서 컨텍스트 스위치를 필요로하지 않기 때문이다. 멀티 코어 시스템의 특정 상황에서, 스핀락은 락킹보다 좋은 선택이 될수 있다. 만약 락을 짧은 시간동안 잡고있으면, 한 스레드는 임계영역에 도달하기 전까지 "spin"하면 되기 때문이다. 현대의 멀티코어 컴퓨터 시스템에서는, 스핀락은 많은 운영체제에서 쓰이고 있다.