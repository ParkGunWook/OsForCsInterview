# what we gonna study

현대의 컴퓨터들은 한 시점에 한개의 프로그램을 허용했다. 이 프로그램은 완벽하게 시스템의 제어를 가지고 모든 시스템의 리소스에 접근가능하다. 반면에, 현대 컴퓨터 시스템은 다양한 프로그램이 메모리에 로드되고 동시에 실행된다. 이런 혁신은 더 단단한 조절이 필요하고 다양한 프로그램의 구역을 필요로한다. 이들은 프로세스의 개념을 필요로하게 했다. 프로세스는 현대 컴퓨팅 시스템의 단위 일 요소이다.

운영체제가 더 복잡할수록, 그것은 유저의 역할을 더욱 필요로한다. 비록 주된 걱정은 유저 프로그램의 실행이지만, 또한 다양한 시스템 일들이 커널안보다는 유저 공간에서 더욱 잘된다. 시스템은 그러므로 프로세스, 몇몇 유저 코드, 실행중인 운영체제 시스템 코드의 집합이다. 잠재적으로, 모든 프로세스들은 동시에 실행되는데, CPU가 그들 사이에서 멀티플렉스되어있다. 이 챕터에서는, 너는 프로세스가 무엇이고, 그들이 어떻게 운영체제를 대표하는지, 그들이 어떻게 일하는지 알게한다.

# Chapter Objectives

1. 프로세스의 컴포넌트를 구별하고 그들이 운영체제에서 어떻게 실행되고 스케쥴되는지 알게된다.
2. 운영체제 안에서 어떻게 프로세스가 생성되고 종료되는지 설명한다. 개발중인 프로그램이 명령어를 수행하기 위한 적절한 시스템콜을 사용하는 것을 포함한다.
3. 공유 메모리와 메시지 패싱을 통한 IPC를 설명하고 비교한다.
4. 파이프와 POSIX 공유메모리를 IPC에서 사용하는 프로그램을 설명한다.
5. 소켓과 remote procedure calls를 이용한 Client-Server를 설명한다.
6. 리눅스 운영체제와 상호작용하는 커널 모듈을 디자인한다.

## 3.1 프로세스 개념

운영체제에서 떠오르는 질문은 CPU 활동을 위해서 무엇을 부르는지가 포함된다. 현대의 컴퓨터들은 **jobs**를 시공유 시스템의 긴급성을 따라서 유저 프로그램이나 태스크를 실행하는 배치 시스템이었다. 싱글 유저 시스템에서도, 유저는 여러개의 프로그램을 실행한다.: 워드프로세서, 웹브라우저, 이메일 패키지. 만약 컴퓨터가 한 프로그램만 실행해도 운영체제는 그것의 내부 프로그램된 활동(메모리 관리)가 필요할 것이다. 많은 관점에서 모든 활동은 비슷한데, 그들을 프로세스라고 부른다.

비록 우리가 현대 언어인 프로세스를 선호하지만, "job" 또한 운영체제 이론과 용어학에서 역사적으로 많이 쓰였었다. 그리고 운영체제의 메이저 활동은 잡프로세싱이었다. 그러므로, 운영체제의 역할로 설명될떄는 우리는 *job*이라고 설명할 것이다.

### 3.1.1 프로세스

공식적으로, 앞서 말했듯이 프로세스는 실행중인 프로그램이다. 현재 실행중인 프로세스의 활동은 program counter의 값과 프로세서의 레지스터 내용으로 표현한다. 프로세스의 메모리 레이아웃은 보통 여러개의 섹션으로 나누어져있다.

- Text section - 실행 코드
- Data section - 전역 변수
- Heap section - 프로그램이 실행중일때 동적으로 할당되는 메모리.
- Stack section - 함수를 실행할때 임시로 생기는 데이터 공간

텍스트와 데이터 섹션은 고정되어있는데, 그들의 사이즈는 프로그램 실행중에는 바뀌지 않는다. 그러나, 스택과 힙 구역은 줄거나 프로그램 실행중에 동적으로 커진다. 함수가 불러질 때마다, **activation record**(함수 파라미터, 지역 변수, 스택의 귀환 주소)가 포함되있다. 함수에서 제어가 반환되면, activation record는 스택에서 팝된다. 비슷하게 힙은 메모리가 동적으로 할당될 때마다 커지고, 시스템에 메모리가 반환되면 줄어든다. 비록 스택과 힙 구역이 서로에게 다가서지만, 운영체제는 그들이 확실히 오버랩되지 않게 보장한다.

우리는 프로그램이 그 자체로 프로세스가 아니라고 강조한다. 프로그램은 수동적인 집합이고, 디스크에 명령어의 리스트를 포함할뿐이다. 반대로, 프로세스는 능동적인 집합이고, 프로그램 카운터가 실행할 다음 명령어를 가르키고 관련된 리소스를 가진다. 실행가능 파일을 실행하는 두가지 일반적인 기술은 더블 클릭과 커맨드라인에 입력하는 것이다.

비록 두개의 프로세스가 같은 프로그램이어도, 그들은 두개의 분할된 실행 시퀀스를 가진다. 예를 들어, 여러명의 유저가 메일 프로그램의 다른 카피를 실행해도, 아니면, 같은 유저가 웹 브라우저 프로그램의 카피를 실행한다. 각각은 분리된 프로세스이고, 비록 텍스트 섹션이 같아도, 데이터, 힙, 스택 구역은 다르다. 그것은 또한 프로세스를 실행하는 프로세스 또한 일반적이다. 

프로세스 자체가 다른 코드를 실행하는 실행 환경이 될수있다. 자바 프로그래밍 환경은 좋은 에시를 제공한다. 대부분의 상황에서, 실행가능한 자바 프로그램은 JVM에서 실행된다. JVM은 로딩된 자바 코드를 해석하고 코드의 편에서 행동을 하는 것이다. 예를 들어, 컴파일된 자바프로그램을 실행하는 것은 java program이라고 입력하는 것이다.

커맨드 java는 JVM라는 프로세스를 실행하고, 자바 프로그램 Program을 가상 머신에서 실행한다. 이 개념은 시뮬레이션과 같은데, 코드가 명령어로 쓰이는 것대신에 자바 언어로 쓰인다는 코드적 차이만 있다.

### 3.1.2 프로세스 상태

프로세스가 실행되면, 그것은 상태를 바꾼다. 프로세스의 상태는 현재 프로세스의 활동에 의해서 정의된다. 프로세스는 다음과 같은 상태가 있다.
- New : 프로세스가 생성되었다.
- Running : 명령어가 실행된다.
- Waiting : 프로세스가 몇가지 이벤트가 일어나기를 기다린다.(I/O가 완성되거나 시그널을 받았다.)
- Ready : 프로세스는 프로세서에 할당되기를 기다린다.
- Terminated : 프로세스는 실행을 마친다.

이런 이름들은 추상적이고 그들은 운영체제마다 다르다. 모든 시스템에서 하지만 상태는 발견된다. 일부 운영체제는 프로세스 상태를 기술하기도 한다. 한개의 프로세서에 한개의 프로세스만 running인 것을 아는 것은 중요하다. 많은 프로세스들은 ready와 waiting이다.

### 3.1.3 Process Control Block

각각의 프로세스는 운영체제의 task control block이라고도 불리는 PCB로 표현된다. 특정 프로세스의 몇가지 정보 조각은 다음을 포함한다. 
- 프로세스 상태 : 상태는, new, running, waiting, halted 등이 있다.
- 프로그램 카운터 : 카운터는 다음 명령어를 실행할 주소를 저장한다.
- CPU 레지스터 : 레지스터들은 숫자와 타입에 따라 다양하고, 컴퓨터 아키텍처에 달려있다. 그들은 누산기, 인덱스 레지스터, 스택 포인터, 범용 레지스터, 특정 상황코드 정보가 포함된다. 프로그램 카운터를 따라서, 이런 상태 정보들은 반드시 인터럽트 발생시에 저장되어야하고, 프로세스가 재 스케쥴 되었을 때 바로 진행되도록 허용한다.
- CPU 스케쥴 정보 : 이 정보는 프로세스 우선순위, 스케쥴링 큐 포인터, 다른 스케쥴링 파라미터를 포함한다.
- 메모리 관리 정보 : 이 정보는 베이스와 리미트 레지스터의 값과 페이지 테이블, 세그먼트 테이블 같은 갑슬 포함한다.
- Accounting information : 이 정보는 CPU와 real time 사용량, 시간 제한, account numbers, job or process numbers 등을 포함한다.
- I/O 상태 정보 : 이 정보는 프로세스에 할당된 I/O 장치의 리스트와 열린 파일의 리스트를 포함한다.

간단하게 말해서, PCB는 시작 또는 재시작할때 필요한 모든 데이터를 포함한다..

### 3.1.4 쓰레드

프로세스 모델은 내부에 단일 쓰레드의 실행으로 이루어진 프로그램을 내포한다. 예를 들어 프로세스가 실행중이면, 워드 프로세서 프로그램은 단일 쓰레드의 명령으로 실행된다. 이 싱글 스레드의 조작은 프로세스가 한번에 한가지 일만 하도록 허용한다. 그러므로, 유저는 동시에 글자를 치면고 스펠체크를 할 수 없다. 대부분의 현대 운영체제는 프로세스를 여러개의 쓰레드를 허용하도록 했고 그래서 동시에 여러가지 작업을 실행한다. 이 기능은 멀티코어 시스템에서 이득이고, 다중 쓰레드가 병렬적으로 실행된다. 멀티쓰레드 워드 프로세서는 예를 들어서, 한개의 쓰레드에 유저를 관리하게 할당하고 다른 쓰레드는 여전히 스펠 체크를 한다. 쓰레드의 도움을 받는 시스템은, PCB는 쓰레드 정보또한 포함하게 되었다. 4장에서 자세히 다루도록 하겠다.

## 3.2 프로세스 스케쥴링

멀티프로그래밍의 목적은 CPU 효율을 최대화 하기위해서 몇몇 프로세스를 모든 시간동안 실행시키는 것이다. 시공유의 목적은 프로세스 사이에서 CPU를 교체하고 유저가 각 프로그램을 실행중에 상호작용하게 한다. 이러한 목적을 달성하기 위해서, 프로세스 스케쥴러는 가용항 프로세스를 선택하고 코어에서 프로그램을 실행한다. 각 CPU 코어는 한개의 프로세스를 한번에 실행할 수 있다. 단일 CPU 코어 시스템에서, 한번에 한개 이상의 프로세스는 실행되지 않는다. 반면에, 멀티코어 시스템은 한번에 여러개의 프로세스를 실행한다. 만약 코어보다 프로세스가 많으면, 초과된 프로세스는 코어가 자유롭거나 재스케쥴 되기 전까지는 기다린다. 현재 메모리에 있는 프로세스의 수는 멀티프로그래밍의 디그리라고도 한다.

멀티 프로그래밍과 시공유의 목적을 밸런스 맞추는 것은 프로세스의 일반적인 행동을 취하는 것을 필요로한다. 일반적으로 대부분의 프로세스는 I/O 바운드 또는 CPU 바운드로 설명된다. I/O bound 프로세스는 I/O 하는 시간을 계산시간보다 더 쓴다. CPU-바운드 프로세스는 I/O는 거의 안부르고 계산하는데 시간을 더 쓴다.

### 3.2.1 스케쥴링 큐

프로세스가 시스템에 입력되면, 그들은 레디큐에 들어가는데 그들이 CPU 코어에서 레디나 실행을 대기중인 것들이다. 이 큐는 링크드 리스트로 저장되는데, 레디 큐 헤더는 리스트의 첫번쨰 PCB의 주소를 포함하고 각각의 PCB는 레디큐의 다음 PCB를 가르키고 있다.

시스템은 또한 다른 큐를 포함한다. 프로세스가 CPU 코어에 할당되면, 그것은 종료되거나, 인터럽트되거나, 특정 이벤트가 생길때 까지 실행한다. 프로세스가 I/O 요청을 디스크 같은 디바이스에 했다고 가정하자. 드라이버가 프로세서보다 느리기 때문에, 프로세스는 I/O가 가용해질 때까지 기다려야한다. 프로세스는 그러면 I/O의 완료까지 기다리고 wait queue에 위치하게 된다.

일반적인 프로세스 스케쥴링의 표현은 **queueing diagram**이다. 두가지 타입의 큐가 존재하는데 레디큐와 웨이트 큐이다. 프로세스는 생성되면 레디큐에 들어간다. 그것은 실행될때까지 대기한다. 한번 CPU 코어에 프로세스가 할당되면, 몇몇 이벤트가 생긴다.

- 프로세스는 I/O 요청을 실행하고 I/O wait 큐에 들어간다.
- 프로세스는 새로운 자식 프로세스를 만들고 자식이 종료할때까지 wait 큐에서 대기한다.
- 프로세스는 그것의 타임 지분 만료로 코어에서 강제로 제거되고 레디큐에 다시 들어간다

첫번쨰 2가지 케이스는, 프로세스는 waiting 상태에서 ready 상태로 바뀌면서 ready 큐에 들어간다. 프로세스는 종료될때까지 이 사이클을 유지하고 사이클이 끝나면, 모든 큐에서 제거되고 그것의 PCB와 리소스들은 할당이 해제된다.

### 3.2.2 CPU 스케쥴링

프로세스는 그것의 생애동안 레디큐와 다양한 wait 큐를 이동한다. CPU 스케쥴러의 역할은 레디큐에 있는 프로세스를 선택하고 그둘중 하나에 CPU 코어를 할당하는 것이다. CPU 스케쥴러는 반드시 새로운 프로세스를 위해서 CPU를 선택해야한다. I/O 바운드 프로세스는 몇 미리세컨드동안 실행하기전에 I/O 요청을 기다린다. 비록 CPU 바운드 프로세스가 긴 수명을 요구하지만, 스케쥴러는 프로세스에게 확장된 주기를 보장하지 않는다. 대신에, 그것은 프로세스를 CPU에서 강제로 제거하고 다른 프로세스를 실행한다. 그러므로, CPU 스케쥴러는 100milliseoncds 마다 실행하고, 더 많이 그런다. 

몇몇 운영체제는 스케쥴링의 중개자를 가지고 있는데, **swapping**이라고 하고 이것의 메인 아이디어는 프로세스를 메모리에서 제거하고 멀티프로그래밍의 차수를 줄이는 것이다. 그리고 프로세스는 메모리로 다시 들어오고, 그것의 실행은 떠날때까지 지속된다. 이런 기술은 스와핑이라고 하는데 왜냐하면 프로세스가 메모리에서 디스크로 스왑 아웃 당하기 때문이다. 그리고 디스크에는 현재의 상태가 저장되고, 메모리로 다시 스왑인을 하고 그것의 상태가 복구된다. 스와핑은 보통 메모리가 과용적되고 해제가 필요할때 필수적이다.

### 3.2.3 Context switch

인터럽트는 운영체제가 CPU의 현재 진행중인 일을 바꾸고 커널 루틴을 실행하게 한다. 인터럽트가 발생하면, 시스템은 현재 프로세스의 컨텍스트를 저장하고 프로세싱이 끝나면 컨텍스트를 복구한다. 즉 프로세스를 멈추고 재시작하게 한다. 컨텍스트는 프로세스의 PCB를 표현한다. 그것은 CPU 레지스터 값, 프로세스 상태, 메모리 관리 정보를 포함한다. 일반적으로 그들은 CPU 코어의 현재 상태를 저장하고, 커널이나 유저모드로 바꾸고, 그리고 상태를 복구하고 명령어를 재시작한다.

다른 프로세스로 CPU 코어 스위칭은 현재 프로세스의 상태 저장과 다른 프로세스 상태의 복구가 필요로한다. 이 일들은 컨텍스트 스위치라고한다. 컨텍스트 스위치가 일어나면, 커널은 PCB 속의 예전 프로세스의 컨텍스트를 저장하고 새롭게 스케쥴된 프로세스의 컨텍스트를 부른다. 컨텍스트 스위치 시간은 순수한 간접비인데 시스템이 스위칭 간에 유용한 일을 하지 않기 때문이다. 스위칭 속도는 기계마다 다르고, 메모리 속도에 따라서 변하고, 복사되는 레지스터의 수에 따라서 바뀌고, 특별한 명령(한번의 명령으로 모든 레지스터를 저장하거나 부르는 것)에 달려있다.

컨텍스트 스위치 시간은 하드웨어 지원에 깊게 의존한다. 예를 들어서, 몇몇 프로세서는 여러가지 종류의 레지스터 셋을 지원한다. 컨텍스트 스위치는 현재 레지스터 셋의 포인터를 바꾸는 것을 필요로 한다. 물론, 만약에 활동중인 프로세서보다 레지스터가 많으면, 시스템은 메모리로부터 레지스터 데이터를 복사한다. 또한, 운영체제가 더 복잡할수록, 컨텍스트 스위치 간에 더욱 많은 일이 필요하다.

9장에서는, 진보된 메모리 관리 기술이 각 컨텍스트마다 스위칭에 추가 데이터를 필요로 할 것이다. 예를 들어서, 현재 프로세스의 주소 공간은 반드시 새로운 일의 공간이 사용준비가 될때 보존되어야한다. 어떻게 주소공간이 보존되고 무슨 일들이 보존될지는 메모리 관리 기술에 달려있다.

## 3.3 Operation on Processes

대부분의 시스템안의 프로세스는 동시다발적으로 실행되는데, 그들은 동적으로 생성되거나 삭제된다. 그러므로, 이러한 시스템들은 반드시 프로세스 생성과 종료에 대한 메커니즘을 제공해야한다. 이 절에서는, 우리는 프로세스 생성과 리눅스와 윈도우 시스템에서의 프로세스 생성을 설명할 것이다.

### 3.3.1 Process Creation

실행 과정중에, 프로세스는 몇가지 새로운 프로세스를 생성한다. 앞서 말했듯이, 프로세스 생성하기는 부모 프로세스라고 불리고, 새로운 프로세스는 그 프로세스의 자식이라고 불린다. 각각의 새로운 프로세스는 다른 프로세스를 만들고, 프로세스의 트리를 구성한다. 대부분의 운영체제는 유일한 **process identifier(pid)**를 통해서 구별되고 일반적으로는 정수 숫자이다. pid는 시스템의 프로세스의 고유한 값을 제공하고, 커널 안에서 다양한 프로세스의 성질을 접근하기 위한 인덱스로 사용된다.

리눅스의 프로세스 시스템을 알아보겠다. 트리의 헤드에는 systemd라는 pid 1을 가진 프로세스(보통은 프로세스라고 하지만, 리눅스에서는 *task*를 선호한다.)는 보든 유저 프로세스의 루트 부보 프로세스이고 시스템이 부팅되면서 생긴 첫번째 유저 프로세스이다. 시스템이 한번 부팅되면, systemd 프로세스는 웹, 프린트서버, ssh서버같은 부가기능을 지원하는 프로세스를 생성한다. 그리고 그중에서 logind라는 프로세스는 시스템에 직접적으로 로그인하는 고객을 관리하는 책임을 가진다. 예를 들어서, bash 쉘을 사용해서 로그인 하는 클라이언트는 pid 8416을 할당받았다. bash CLI를 사용하면서, 이 유저는 ps 프로세스와 vim editor 프로세스를 생성한다. sshd 프로세스는 ssh를 통해서 접속하는 클라이언트를 관리한다. 

유닉스와 리눅스 시스템에서 우리는 ps 커맨드를 통해서 현재 실행중인 프로세스를 확인할 수 있다. ps -el이라는 명령어는 시스템에서 현재 활성화된 모든 프로세스의 정보 리스트를 제공한다. 또한 트리 모양은 pstree 명령어로 확인할 수도 있다.

보통은, 프로세스가 자식 프로세스를 만들면, 자식 프로세스는 그것의 일을 완수하기위해서 일부 자원(CPU 시간, 메모리, 파일, I/O디바이스)가 필요할 것이다. 또는 그것은 부모 프로세스의 리소스 일부분으로 제한될 수도 있다. 부모는 그것의 자원을 자식들간에 배분해야할 수도 있고, 몇몇 자식들간에 일부자원을 공유하게 해야할 수도 있다. 자식 프로세스를 제한하는 것은 많은 자식 프로세스의 생성에 따른 오버로딩을 막을수 있다.

다양한 물리적 논리적 자원을 제공하기 위해서, 부모 프로세스는 자식 데이터에게 초기화 데이터를 건내줄수도 있다. 예를 들어서, 파일의 컨텐츠를 보여주는 함수를 가진 프로세스를 고려하겠다. 프로세스가 생성되었을 때, 그것은 그것의 부모 프로세스로 부터 인풋을 받을 것이고, 파일을 열고 컨텐츠를 보여줄 것이다. 그것은 또한 출력 장치의 이름을 얻을 수도 있다. 몇몇 운영체제는 자식 프로세스에게 리소스를 넘길 수도 있다. 이런 시스템에서는, 프로세스는 두개의 오픈 파일을 가지고, hw1.c와 터미널 디바이스는 datum을 둘 사이에서 주고받을 것이다. 프로세스가 새로운 프로세스를 만들면, 실행이 존재하는 두가지 가능성이 있다.

1. 부모가 자식과 함께 실행한다.
2. 부모가 자식이 끝날때까지 기다린다.

새로운 프로세스를 위한 주소공간도 두가지 방법이 있다.

1. 자식 프로세스가 부모 프로세스의 복제본이된다.(그것은 부모와 같은 프로그램과 데이터를 가진다.)
2. 자식 프로세스가 새로운 프로그램을 불러온다.

이러한 차이를 설명하기 위해서, 유닉스 운영체제를 고려해보자. 유닉스에서는 각각의 프로세스는 그것의 pid로 구별된다. 새로운 프로세스는 fork() 시스템 콜에 의해서 생성된다. 그 새로운 프로세스는 원본 프로세스의 주소공간의 복사본을 가진다. 두 프로세스는 fork() 명령어 이후에, 한가지 차이를 가진다. : 새로운 프로세스의 fork()의 리턴 값은 0이고 pid가 0이아닌 자식들의 리턴 값은 부모이다.

fork() 시스템 콜 이후에, 프로세스는 exec() 시스템콜은 메모리에 이진 파일을 넣고 그것의 실행을 시작한다. 이런 상황에서, 두개의 프로세스는 소통이 가능해지고 그들의 분리된 길을 간다. 부모는 더욱 많은 자식을 가질수 있고, 자식이 실행중에 하는 일이 없다면, wait() 시스템콜을 발행하고 자식의 종료때까지 ready 큐밖에서 기다린다. exec() 콜은 새로운 프로그램과 함께 프로세스의 공간이 포개어지기 때문에, exec()는 에러가 발생하기 이전까지는 리턴하지 않는다.

### 3.3.2 프로세스 종료

프로세스는 마지막 절을 실행하고 운영체제에게 exit() 시스템 콜을 통해서 종료해달라고 한다. 그런 점에서, 프로세스는 기다리는 부모 프로세스에게 상태 값을 리턴할수도 있다(wait() 시스템 콜을 통해서). 프로세스의 리소스는 물리/가상 메모리, 오픈 파일들, I/O 버퍼들은 운영체제에 의해서 해제되고 재 설정딘다.

종료는 다른 상황에도 일어날 수 있다. 프로세스는 적절한 시스템 콜을 통해서 다른 프로세스를 종료시킬 수 있다.(TerminateProcess() 윈도우에서). 보통 이런 시스템 콜은 종료되려고하는 부모 프로세스에 의해서 실행된다. 다른 경우에는 유저 또는 잘못 동작하는 앱은 다른 유저의 프로세스를 죽일수 있다. 부모 프로세스는 자식 프로세스를 죽이기 위해서는 그것의 이름을 아는 것이 필요하다. 그러므로, 프로세스가 새로운 프로세스를 만들면, 새롭게 생성된 프로세스는 그것의 부모에게 넘어간다.

부모는 다양한 이유로 자식을 죽일수 있는데 다음과 같다.
- 자식이 할당된 리소스보다 많은 사용을 했을때이다.(이걸 확인하려면, 부모는 자식의 상태를 관찰할 매커니즘이 필요하다.)
- 자식에게 할당된 일이 더이상 필요가 없을떄.
- 부모가 종료되고 시스템이 부모가 종료되었을때 더이상 자식을 허용하지 않을떄.

몇몇 시스템은 부모가 종료되면 자식을 허용하지 않는다. 이러 ㄴ시스템에서는 만약 프로세스가 (정상적으로나 비정상적으로) 종료가 되면, 그것의 자식들은 반드시 종료되어야한다. 이런 현상을 **cascading termination**이라고 한다. 그리고 운영체제에 의해서 실행된다.

프로세스가 실행중인지 아닌지 설명하려면, 리눅스와 유닉스에서는 우리는 exit() 시스템콜을 통해서 프로세스를 종료할수 있는데, exit은 파라미터를 제공한다.

실제로, 정상적인 종료에서, exit()는 직/간접적으로 디폴트 값으로 exit() 콜을 포함할 것이다.

부모 프로세스는 wait()를 통해서 자식 프로세스의 종료를 기다릴 수 있다. wait() 시스템 콜은 자식의 exit 상태를 얻을수있는 파라미터를 가진다. 이 시스템 콜은 종료된 자식의 식별자를 리턴하고 부모는 어떤 자식이 종료되었다는 것을 말할 수 있다.

'''c
    pid_t pid;
    int status;

    pid = wait(&status);
'''

프로세스가 종료되면, 그것의 자원들은 운영체제에 의해서 해제된다. 그러나 프로세스 테이블의 엔트리는 부모가 wait()를 부를떄까지 유지하는데, 프로세스 테이블은 프로세스의 exit 상태를 포함하기 때문이다. 종료된 프로세스는, 하지만 부모에 의해서 wait()로 불리지 않은 것은 좀비 프로세스라고 불린다. 모든 프로세스가 이 상태로 이동하면, 좀비로 간편하게 존재한다. 한번 부모가 wait()를 콜하면, 좀비 프로세스의 pid와 프로세스 테이블의 엔트리는 풀려난다.

이제 만약 부모가 wait를 부르지 않으면 어떤 일이 일어나는지 알아보자. 대신에 그것의 자식을 고아로 만드는 상황을 생각해보겠다. 전통적인 유닉스 시스템은 init 프로세스를 새로운 부모 부터 고아 프로세스로 할당한다. init 프로세스는 주기적으로 wait() 콜을 생성하고, 따라서 어떤 고아가된 프로세스든 모이고 고아의 pid와 프로세스 테이블 엔트리를 해제한다.

비록 리눅스 시스템이 init을 systemd로 바꾸었어도 여전히 같은 동작을 취한다. 그리고 고아 프로세스의 관리를 systemd이외의 프로세스를 허용한다.

### 3.3.2.1 안드로이드 프로세스 계보

제한된 메모리같은 리소스 제한때문에, 모바일 운영체제는 제한된 시스템 리소스를 재설정하기위해서 존재하는 프로세스를 종료한다. 제멋대로인 프로세스를 종료하는 것보다, 안드로이드는 시스템이 새로운, 더 중요한 프로세스를 위해서 존재하는 것을 종료해야할때를 위한 프로세스의 중요성 계보를 가지고 있다. 그것은 중요도가 증가하는 순서대로 프로세스를 종료한다. 최대부터 최소 중요성까지, 프로세스 분류 계보는 다음을 따른다.

- Foreground process - 스크린에서 현재 보이는 프로세스, 현재 유저가 상호작용하는 앱이다.
- Visible process - 프로세스가 보이지는 않지만, foreground 프로세스가 언급하는 현재 활동중인 앱이다.
- Service process - 백그라운드 프로세서와 비슷하지만, 유저에게 분명한 활동을 하는 프로세스이다.(음악 스트리밍)
- Background process - 활동중이지만 유저에게 분명하지 않은 프로세스
- Empty process - 아무런 활동적인 활동없는 프로세스

만약 시스템 리소스가 재정의되면, 안드로이드는 먼저 empty를 지우고 background를 멈추고 더 나아간다. 프로세스는 중요도 랭킹으로 할당되고, 안드로이드는 최대한 높은 등수를 프로세스에 할당하려고 한다. 예를 들어서, 만약 프로세스가 서비스를 제공하고 눈에 보이면, 그것은 visible 프로세스 분류에서 가장 중요하다고 한다.

더 나아가서, 안드로이드 개발 실습은 프로세스 라이프 사이클의 가이드라인을 제시한다. 이 가이드라인이 따라오면, 프로세스의 상태는 종료전까지 우선을 가지고 만약 유저가 다시 앱으로 돌아가면 그것의 저장된 상태를 재시작한다.

## 3.4 IPC

운영체제에서 동시에 실행중인 프로세스는 독립적이거나 협력하는 프로세스일 것이다. 프로세스는 만약에 시스템 속에서 실행중인 다른 프로세스와 데이터를 공유하지 않으면 독립적이라고 한다. 협력하는 프로세스는 만약에 시스템의 다른 프로세스에게 영향을 받거나 주면 협력적이라고 한다. 분명하게, 데이터를 공유하는 프로세스는 협력 프로세스라고 한다. 프로세스끼리 협력하는 환경을 제공하는 이유는 다음과 같다.

- 정보 공유 - 앱들이 같은 정보의 조각들에 관심이 있다면, 우리는 반드시 이런 정보에 동시에 접근하도록 허용해야한다.
- 컴퓨테이션 가속 - 만약 몇몇 작업이 빠르길 원하면, 우리는 그것을 분할해서 다른 것들과 병행으로 실행하게 해야한다. 이런 스피드업은 오직 컴퓨터가 다중 프로세싱 코어를 가질때 가능하다.
- modularity - 우리는 시스템을 모듈러 상태로 건설하기를 원하고 시스템을 분리된 프로세스나 쓰레드로 가지길 원한다.

협력 프로세스는 **Iterprocess communication(IPC)**를 필요로하는데 이것은 데이터를 교환하게한다. 즉, 데이터를 서로에게 보내고 받는다. 두가지 기본적인 통신 방식이 있다. 메모리 공유와 메시지 패싱이다. 공유 메모리 모델에서는, 메모리의 영역은 프로세스가 만들어지면서 생긴다. 프로세스는 공유된 영역을 읽고 씀으로서 정보를 교환한다. 메시지 패싱 모델에서, 협력 프로세스들 사이에서 메시지 교환의 목적으로 통신이 자리잡는다.

두 모델은 다양한 시스템에서 일반적으로 언급된다. 메시지 패싱은 작은 양의 데이터를 교환하는데 도움이되는데, 충돌을 피할필요가 없기 때문이다. 메시지 패싱은 공유메모리보다 분산 시스템에서 더욱 쉽게 실행된다. 공유 메모리는 메시지 패싱보다 빠른데, 메시지 패싱은 커널의 시스템 콜을 필요로하기 때문이다. 공유메모리에서, 시스템 콜은 오직 공유 메모리 영역을 건설할때 필요로한다. 한번 공유메모리가 생기면 모든 접근은 일반적인 메모리 접근으로 여겨지고 커널의 도움은 전혀 필요없다.

## 3.5 IPC in shared memory system

공유 메모리 IPC를 통해 통신하는 프로세스는 공유메모리의 영역을 건설할 필요가 있다. 보통, 공유 메모리 영역은 공유 메모리를 만드는 프로세스의 주소 공간에 거주한다. 통신을 원하는 다른 프로세스는 그들의 주소공간에 반드시 공유메모리 세그먼트를 부착해야한다. 보통 운영체제는 한 프로세스가 다른 프로세스의 메모리를 접근하는 것을 방지하려고 한다. 공유 메모리는 이런 제한을 없애는 것을 허용해야한다. 그들은 그러면 공유된 영역에서 공통 영역에서 데이터를 읽고 쓸수 있다. 데이터의 모양과 위치는 프로세스에 의해서 결정되고 운영체제의 영향을 받지 않는다. 프로세스는 그들이 같은 위치에 동시에 쓰지 않도록 하기도 해야한다. 협력 프로세스의 개념을 설명하기 위해서 생산자-컨슈머 문제를 고려해보겠다. 생산자 프로세스는 소비자 프로세스에 의해서 소비되는 정보를 생산한다. 예를 들어서, 컴파일러는 어셈블러에 의해서 소비되는 어셈블리 코드를 생산한다. 에섬블러의 입장에서는 로더가 소비하는 오브젝트 모듈을 생산할 수도 있다. 생산자-소비자 문제는 제공자로 생산자, 고객으로 소비자를 생각한다. 예를 들어 웹서버가 HTML같은 웹 컨텐츠를 제공하고 웹 브라우저에 요청된 자원은 소비된다.

한가지 생산자-소비자 문제를 해결하는 방법은 공유메모리이다. 두 프로세스가 동시에 작동하기 위해서 우리는 반드시 생산자에 의해서 채워지고 소비자에 의해서 비워지는 아이템의 버퍼가 필요하다. 이 버퍼는 생산자와 소비자 프로세스가 공유하는 메모리의 영역에 상주한다. 생산자는 소비자가 다른 아이템을 소비하는 동안 다른 아이템을 생산할 수 있다. 생산자와 소비자는 반드시 동기화되어야하고, 소비자는 생산되지 않은 상품을 소비하려고 하지 않아야한다.

두가지 타입의 버퍼가 사용가능하다. **Unbounded buffer**은 버퍼의 크기를 가지지 않는다. 그 소비자는 새로운 아이템을 기다리지만, 생산자는 항상 새로운 아이템을 생산한다. **Bounded buffer**는 고정된 버퍼 크기를 가진다. 이 경우에는, 소비자는 버퍼가 비게되면 기다리고 생산자는 버퍼가 차게되면 기다린다.

bounded buffer가 어떻게 사용되는지 보겠다. 다음과 같은 변수가 생산자-소비자 프로세스의 공유 영역에 머문다.

'''c
    #define BUFFER_SIZE 10

    typedef struct {
        . . .
    }item;

    item buffer[BUFFER_SIZE];
    int in = 0;
    int out = 0;
'''

공유된 버퍼는 두가지 논리 포인터로 환형 배열로 실행된다. in 포인트는 버퍼에서 다음 빈 공간을 가르키고, out 포인트는 버퍼의 첫번째 가득찬 위치를 가르킨다. 버퍼는 in==out일때 비어있고 (in+1)%BUFFER_SIZE == out일때 가득 찼음을 가르킨다. 생산자 프로세스는 next_produced 지역변수를 통해서 생산된 새로운 아이템이 저장될 곳을 가르킨다. 마찬가지로 소비자 프로세스는 소비될 아이템이 있는 위치를 알린다. 3.7.1에서 POSIX 공유메모리 API를 알려주겠다.

한가지 걱정은 공유된 버퍼에 동시에 두 프로세스가 접근하는 것이다. 이것은 6장과 7장에서 동기화를 배우고 효과적으로 공유 메모리 환경을 실행하는 법을 배우겠다.

## 3.6 IPC in Message-Passing Systems.

3.5절에서, 우리는 공유 메모리 환경에서 협력프로세스가 어떻게 통신하는지 보여줬다. 이 기술은 메모리의 영역을 공유해서 코드가 앱 프로그래머에 의해서 공유된 메모리에 쓰여지고 접근된다. 다른 방법은 운영체제가 지원하는 메시지 패싱 기술을 이용해서 통신하는 것이다.

메시지 패싱은 프로세스가 통신하는 것을 허용하는 메커니즘을 제공하고 공유된 주소 공간 없이 그들의 행동을 동기화한다. 그것은 특히 분산 환경에서 유용한데, 통신 프로세스는 네트워크로 연결된 다른 컴퓨터에 있을 수 있기 때문이다. 예를 들어서, 인터넷 챗 프로그램은 챗 참가자들이 메시지 교환을 통해서 소통하게끔 디자인된다.

메시지 패싱 기능은 2가지 명령어를 제공한다. send(message)와 recieve(message)이다.

메시지는 사이즈에 상관없이 프로세스에 의해서 보내진다. 만약 고정된 사이즈 메시지가 보내지면, 시스템 레벨 실행은 꽤나 직관적이다. 이 제한은, 그러나, 프로그래미의 일을 더욱 힘들게 만든다. 반대로, 다양한 사이즈의 메시지는 복잡한 시스템 레벨 실행을 요구하지만, 프로그래밍 업무는 간단하다. 이것은 운영체제 디자인에서 흔히 보이는 트레이드오프이다. 만약 프로세스 P와 Q가 통신을 원하면, 그들은 반드시 서로에게 메시지를 보내고 받아야한다. 통신 링크는 그들 사이에 반드시 존재한다. 이 링크는 다양한 방법으로 추가된다. 우리는 링크의 물리적 설치는 보지 않겠다.(예를 들어서, 공유메모리, 하드웨어 버스, 네트워크는 19장에서 나온다.) 오히려 논리적 설치를 보겠다. 여기에 논리적 링크 설치를 위한 몇가지 방법과 send()/receive() 명령어가 있다.

- Direct or indirect 통신
- 동기화 또는 비동기화 통신
- 자동 또는 노골적인 버퍼링

### 3.6.1 네이밍

통신을 원하는 프로세스는 서로를 언급할 방법이 있어야한다. 그들은 직접 또는 간접 통신을 사용한다. 직접 통신에서는 각각의 프로세스는 통신의 수신자와 발신자를 명백하게 이름지어서 통신하기를 원한다. 이 기술에서, send()와 receive() 원조는 다음과 같다.

- send(P, message) - Send a message to process P.
- receive(Q, message) -Receive a message from process Q.

이 기술속의 통신 기술은 다음과 같은 재산을 가진다.

- 링크는 통신을 원하는 모든 프로세스의 쌍으로 자동적으로 생긴다. 프로세스는 통신하기위해서 각자의 이름을 안다.
- 링크는 오직 2개의 프로세스에만 있다.
- 두 프로세스의 사이에, 오직 하나의 선만이 있다.

이 기술은 어드레싱에서 대칭적이다. 전송자 프로세스와 수신자 프로세스는 각자의 이름을 반드시 사용해야한다. 이 기술의 다른 방법은 어드레싱이 비대칭적이다. 여기서는 오직 발신자만 수신자를 정하고, 수신자는 발신자의 이름을 필요로 하지 않는다. 이런 경우에는 명령어는 다음과 같다.

- send(P, message) - Send a message to process P
- receive(id, message) - Receive a message from any process. id는 통신가능한 프로세스의 이름 집합이 차지하고 있다.

두가지 방법의 단점은 프로세스 정의가 만드는 결말의 제한된 모듈성이다. 프로세스의 id를 바꾸는 것은 모든 프로세스 정의를 재검사하는 것을 필요로한다. 오래된 식별자로의 레퍼런스는 반드시 찾아지고 새로운 식별자로 바뀌어야한다. 보통, 하드 코딩 기술에서, 식별자가 명확하게 언급된, 다음에 언급될 비간접 방법보다 덜 효과적이다.

*indirect communication*에서 메시지는 메일박스나 포트를 통해서 보내지거나 받아진다. 메일 박스는 추상적인 객체로 보여지고 메시지는 프로세스에 의해서 위치하거나 제거될수 있다. 각각의 메일 박스는 유일한 식별자가 있다. 예를 들어 POSIX 메시지 큐는 메일 박스를 구별한 정수 값이 있다. 프로세스는 다른 프로세스와 다양한 메일 박스를 통해서 통신할수 있다. 하지만, 두개의 프로세스는 오직 공유된 메일 박스가 있을떄만 통신할 수 있다. 명령어는 다음과 같다.

- send(A, message) - Send a message to mailbox A.
- receive(A, message) - Receive a message from mailbox A.

이런 기술에서, 통신 링크는 다음과 같은 재산을 가진다.

- 링크는 멤버 쌍이 공유된 메일 박스를 가질떄 생긴다.
- 링크는 2개 이상의 프로세스와 관련되어있다.
- 통신하는 프로세스의 쌍들 사이에, 다양한 링크가 존재하고, 각 링크는 메일박스와 관련되어있다.

이제 P1, P2, P3가 공유 메일박스 A를 가졌다고 가정하겠다. P1은 A에 메시지를 보내고 P2, P3는 A로 부터 receive()를 실행한다. 어떤 프로세스가 P1에 의해서 받아졌을까? 다음과 같은 대답은 우리가 고르게 될 방법에 따라 달라진다.

- 링크를 최대 두개의 프로세스만 가지도록 허용한다.
- 오직 하나의 프로세스만 receive 명령어를 동시에 실행하도록 한다.
- 시스템이 어떤 프로세스가 메시지를 받을지 무자구이로 정하도록 한다. 그 시스템은 어떤 프로세스가 메시지를 받을지를 선택하는 알고리즘을 정의한다(예를 들어 round robin, 프로세스가 메시지를 받는 시간을 가진다.). 시스템은 송신자에게 수신자르 알린다.

메일박스는 프로세스에 의해서 소유되거나 운영체제에 의해서 소유된다. 만약에, 메일박스가 프로세스에 의해서 소유되면(메일 박스가 프로세스의 주소공간에 존재한다.), 우리는 주인(오직 메일 박스를 통해서 메시지를 받는 것만 가능하다.)와 유저(메일박스로 메시지를 보내는 것만 가능하다.)를 구별한다. 각 메일 박스가 특별한 주인을 가지면, 프로세스는 보낸 메시지를 누가 받았는지를 헷갈릴 필요가 없다. 그리고 만약에 메일박스를 가진 프로세스가 종료되면, 메일박스는 사라진다. 그리고 메시지를 보내는 프로세스들은 반드시 이 메일박스가 더이상 존재하지 않은 것을 통지받아야한다.

반대로, 메일박스가 운영체제에 의해서 소유된다. 그것은 독립적이고 어떤 프로세스에도 부착되어 있지 않다. 운영체제 시스템은 다음과 같은 메커니즘을 프로세스에게 제공한다.

- 새로운 메일박스 생성
- 메일박스를 통한 송신과 수신
- 메일박스 삭제

새로운 메일 박스를 생성하는 프로세스는 기본으로 메일박스의 주인이다. 초기에, 주인은 이 메일박스를 통해서 메시지를 받는것만 가능했다. 그러나, 주인권한과 우선권 받기는 적절한 시스템 콜을 통해서 다른 프로세스에 옮겨질 수 있다. 물론, 이 영역은 각 메일 박스의 다중 수신자를 만들 수 있다.

### 3.6.2 동기화

프로세스간의 통신은 send와 receive 콜을 통해서 실행될 수 있다. 각각의 원조를 실행하는 것에는 다양한 디자인 옵션이 있다. 메시지 패싱은 블록킹또는 논블록킹이라는 동기화와 비동기화 방식이다.

- Blocking send - 보내는 프로세스는 메일 박스 또는 받는 프로세스에 의해서 받아지는 동안 멈춰진다.
- Nonblocking send - 보내는 프로세스는 메시지를 보내고 다시 명령을 실행한다.
- Blocking receive - 메시지가 존재할때까지 수신을 멈춘다.
- Nonblocking receive - 있던 없던 계속 수신한다.

다른 종류의 send 와 rececive 조합은 가능하다. 만약 두개의 명령이 blocking이면 우리는 수신자와 송신자의 만남을 가진다. 생산자 소비자 문제의 해결은 blocking send와 receive 상태에서는 사소하다. 생산자는 고작 blocking send 콜을 생성하고 메일박스나 수신자에게 메시지가 전해질때까지 기다린다. 비슷하게 소비자는 오직 메시지가 도착할떄만, receive를 생성한다. 

### 3.6.3 버퍼링.

통신이 직접적이든 간접적이든, 통신하는 프로세스의 메시지 교환은 임시 큐에 상주한다. 기본적으로, 이런 큐들은 3가지 방법으로 만들어진다.

- Zero capacity - 큐는 0의 최대길이를 가지고, 링크는 어떠한 메시지도 가질수 없다. 이런 경우에는 sender는 반드시 수신자가 메시지를 받을떄까지 기다려야한다.

- Bounded capacity - 큐는 제한된 길이 n을 가진다. 최대한 n의 메시지가 안에 존재한다. 만약 메시지가 보내졌을떄 가득차지 않으면, 메시지는 큐에 존재하고 송신자는 기다림 없이 계속 보낼수 있다. 링크의 크기가 제한되어있다. 만약 링크가 풀이면, 송신자는 반드시 큐의 공간이 빌떄까지 기다려야한다.

- Unbounded capacity - 큐의 길이는 무한이다. 그러므로 어떤 메시지도 들어가는 것을 기다린다. 송신자는 절대로 block 하지 않는다.