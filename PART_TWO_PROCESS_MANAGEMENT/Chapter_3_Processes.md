# what we gonna study

현대의 컴퓨터들은 한 시점에 한개의 프로그램을 허용했다. 이 프로그램은 완벽하게 시스템의 제어를 가지고 모든 시스템의 리소스에 접근가능하다. 반면에, 현대 컴퓨터 시스템은 다양한 프로그램이 메모리에 로드되고 동시에 실행된다. 이런 혁신은 더 단단한 조절이 필요하고 다양한 프로그램의 구역을 필요로한다. 이들은 프로세스의 개념을 필요로하게 했다. 프로세스는 현대 컴퓨팅 시스템의 단위 일 요소이다.

운영체제가 더 복잡할수록, 그것은 유저의 역할을 더욱 필요로한다. 비록 주된 걱정은 유저 프로그램의 실행이지만, 또한 다양한 시스템 일들이 커널안보다는 유저 공간에서 더욱 잘된다. 시스템은 그러므로 프로세스, 몇몇 유저 코드, 실행중인 운영체제 시스템 코드의 집합이다. 잠재적으로, 모든 프로세스들은 동시에 실행되는데, CPU가 그들 사이에서 멀티플렉스되어있다. 이 챕터에서는, 너는 프로세스가 무엇이고, 그들이 어떻게 운영체제를 대표하는지, 그들이 어떻게 일하는지 알게한다.

# Chapter Objectives

1. 프로세스의 컴포넌트를 구별하고 그들이 운영체제에서 어떻게 실행되고 스케쥴되는지 알게된다.
2. 운영체제 안에서 어떻게 프로세스가 생성되고 종료되는지 설명한다. 개발중인 프로그램이 명령어를 수행하기 위한 적절한 시스템콜을 사용하는 것을 포함한다.
3. 공유 메모리와 메시지 패싱을 통한 IPC를 설명하고 비교한다.
4. 파이프와 POSIX 공유메모리를 IPC에서 사용하는 프로그램을 설명한다.
5. 소켓과 remote procedure calls를 이용한 Client-Server를 설명한다.
6. 리눅스 운영체제와 상호작용하는 커널 모듈을 디자인한다.

## 3.1 프로세스 개념

운영체제에서 떠오르는 질문은 CPU 활동을 위해서 무엇을 부르는지가 포함된다. 현대의 컴퓨터들은 **jobs**를 시공유 시스템의 긴급성을 따라서 유저 프로그램이나 태스크를 실행하는 배치 시스템이었다. 싱글 유저 시스템에서도, 유저는 여러개의 프로그램을 실행한다.: 워드프로세서, 웹브라우저, 이메일 패키지. 만약 컴퓨터가 한 프로그램만 실행해도 운영체제는 그것의 내부 프로그램된 활동(메모리 관리)가 필요할 것이다. 많은 관점에서 모든 활동은 비슷한데, 그들을 프로세스라고 부른다.

비록 우리가 현대 언어인 프로세스를 선호하지만, "job" 또한 운영체제 이론과 용어학에서 역사적으로 많이 쓰였었다. 그리고 운영체제의 메이저 활동은 잡프로세싱이었다. 그러므로, 운영체제의 역할로 설명될떄는 우리는 *job*이라고 설명할 것이다.

### 3.1.1 프로세스

공식적으로, 앞서 말했듯이 프로세스는 실행중인 프로그램이다. 현재 실행중인 프로세스의 활동은 program counter의 값과 프로세서의 레지스터 내용으로 표현한다. 프로세스의 메모리 레이아웃은 보통 여러개의 섹션으로 나누어져있다.

- Text section - 실행 코드
- Data section - 전역 변수
- Heap section - 프로그램이 실행중일때 동적으로 할당되는 메모리.
- Stack section - 함수를 실행할때 임시로 생기는 데이터 공간

텍스트와 데이터 섹션은 고정되어있는데, 그들의 사이즈는 프로그램 실행중에는 바뀌지 않는다. 그러나, 스택과 힙 구역은 줄거나 프로그램 실행중에 동적으로 커진다. 함수가 불러질 때마다, **activation record**(함수 파라미터, 지역 변수, 스택의 귀환 주소)가 포함되있다. 함수에서 제어가 반환되면, activation record는 스택에서 팝된다. 비슷하게 힙은 메모리가 동적으로 할당될 때마다 커지고, 시스템에 메모리가 반환되면 줄어든다. 비록 스택과 힙 구역이 서로에게 다가서지만, 운영체제는 그들이 확실히 오버랩되지 않게 보장한다.

우리는 프로그램이 그 자체로 프로세스가 아니라고 강조한다. 프로그램은 수동적인 집합이고, 디스크에 명령어의 리스트를 포함할뿐이다. 반대로, 프로세스는 능동적인 집합이고, 프로그램 카운터가 실행할 다음 명령어를 가르키고 관련된 리소스를 가진다. 실행가능 파일을 실행하는 두가지 일반적인 기술은 더블 클릭과 커맨드라인에 입력하는 것이다.

비록 두개의 프로세스가 같은 프로그램이어도, 그들은 두개의 분할된 실행 시퀀스를 가진다. 예를 들어, 여러명의 유저가 메일 프로그램의 다른 카피를 실행해도, 아니면, 같은 유저가 웹 브라우저 프로그램의 카피를 실행한다. 각각은 분리된 프로세스이고, 비록 텍스트 섹션이 같아도, 데이터, 힙, 스택 구역은 다르다. 그것은 또한 프로세스를 실행하는 프로세스 또한 일반적이다. 

프로세스 자체가 다른 코드를 실행하는 실행 환경이 될수있다. 자바 프로그래밍 환경은 좋은 에시를 제공한다. 대부분의 상황에서, 실행가능한 자바 프로그램은 JVM에서 실행된다. JVM은 로딩된 자바 코드를 해석하고 코드의 편에서 행동을 하는 것이다. 예를 들어, 컴파일된 자바프로그램을 실행하는 것은 java program이라고 입력하는 것이다.

커맨드 java는 JVM라는 프로세스를 실행하고, 자바 프로그램 Program을 가상 머신에서 실행한다. 이 개념은 시뮬레이션과 같은데, 코드가 명령어로 쓰이는 것대신에 자바 언어로 쓰인다는 코드적 차이만 있다.

### 3.1.2 프로세스 상태

프로세스가 실행되면, 그것은 상태를 바꾼다. 프로세스의 상태는 현재 프로세스의 활동에 의해서 정의된다. 프로세스는 다음과 같은 상태가 있다.
- New : 프로세스가 생성되었다.
- Running : 명령어가 실행된다.
- Waiting : 프로세스가 몇가지 이벤트가 일어나기를 기다린다.(I/O가 완성되거나 시그널을 받았다.)
- Ready : 프로세스는 프로세서에 할당되기를 기다린다.
- Terminated : 프로세스는 실행을 마친다.

이런 이름들은 추상적이고 그들은 운영체제마다 다르다. 모든 시스템에서 하지만 상태는 발견된다. 일부 운영체제는 프로세스 상태를 기술하기도 한다. 한개의 프로세서에 한개의 프로세스만 running인 것을 아는 것은 중요하다. 많은 프로세스들은 ready와 waiting이다.

### 3.1.3 Process Control Block

각각의 프로세스는 운영체제의 task control block이라고도 불리는 PCB로 표현된다. 특정 프로세스의 몇가지 정보 조각은 다음을 포함한다. 
- 프로세스 상태 : 상태는, new, running, waiting, halted 등이 있다.
- 프로그램 카운터 : 카운터는 다음 명령어를 실행할 주소를 저장한다.
- CPU 레지스터 : 레지스터들은 숫자와 타입에 따라 다양하고, 컴퓨터 아키텍처에 달려있다. 그들은 누산기, 인덱스 레지스터, 스택 포인터, 범용 레지스터, 특정 상황코드 정보가 포함된다. 프로그램 카운터를 따라서, 이런 상태 정보들은 반드시 인터럽트 발생시에 저장되어야하고, 프로세스가 재 스케쥴 되었을 때 바로 진행되도록 허용한다.
- CPU 스케쥴 정보 : 이 정보는 프로세스 우선순위, 스케쥴링 큐 포인터, 다른 스케쥴링 파라미터를 포함한다.
- 메모리 관리 정보 : 이 정보는 베이스와 리미트 레지스터의 값과 페이지 테이블, 세그먼트 테이블 같은 갑슬 포함한다.
- Accounting information : 이 정보는 CPU와 real time 사용량, 시간 제한, account numbers, job or process numbers 등을 포함한다.
- I/O 상태 정보 : 이 정보는 프로세스에 할당된 I/O 장치의 리스트와 열린 파일의 리스트를 포함한다.

간단하게 말해서, PCB는 시작 또는 재시작할때 필요한 모든 데이터를 포함한다..

### 3.1.4 쓰레드

프로세스 모델은 내부에 단일 쓰레드의 실행으로 이루어진 프로그램을 내포한다. 예를 들어 프로세스가 실행중이면, 워드 프로세서 프로그램은 단일 쓰레드의 명령으로 실행된다. 이 싱글 스레드의 조작은 프로세스가 한번에 한가지 일만 하도록 허용한다. 그러므로, 유저는 동시에 글자를 치면고 스펠체크를 할 수 없다. 대부분의 현대 운영체제는 프로세스를 여러개의 쓰레드를 허용하도록 했고 그래서 동시에 여러가지 작업을 실행한다. 이 기능은 멀티코어 시스템에서 이득이고, 다중 쓰레드가 병렬적으로 실행된다. 멀티쓰레드 워드 프로세서는 예를 들어서, 한개의 쓰레드에 유저를 관리하게 할당하고 다른 쓰레드는 여전히 스펠 체크를 한다. 쓰레드의 도움을 받는 시스템은, PCB는 쓰레드 정보또한 포함하게 되었다. 4장에서 자세히 다루도록 하겠다.

## 3.2 프로세스 스케쥴링

멀티프로그래밍의 목적은 CPU 효율을 최대화 하기위해서 몇몇 프로세스를 모든 시간동안 실행시키는 것이다. 시공유의 목적은 프로세스 사이에서 CPU를 교체하고 유저가 각 프로그램을 실행중에 상호작용하게 한다. 이러한 목적을 달성하기 위해서, 프로세스 스케쥴러는 가용항 프로세스를 선택하고 코어에서 프로그램을 실행한다. 각 CPU 코어는 한개의 프로세스를 한번에 실행할 수 있다. 단일 CPU 코어 시스템에서, 한번에 한개 이상의 프로세스는 실행되지 않는다. 반면에, 멀티코어 시스템은 한번에 여러개의 프로세스를 실행한다. 만약 코어보다 프로세스가 많으면, 초과된 프로세스는 코어가 자유롭거나 재스케쥴 되기 전까지는 기다린다. 현재 메모리에 있는 프로세스의 수는 멀티프로그래밍의 디그리라고도 한다.

멀티 프로그래밍과 시공유의 목적을 밸런스 맞추는 것은 프로세스의 일반적인 행동을 취하는 것을 필요로한다. 일반적으로 대부분의 프로세스는 I/O 바운드 또는 CPU 바운드로 설명된다. I/O bound 프로세스는 I/O 하는 시간을 계산시간보다 더 쓴다. CPU-바운드 프로세스는 I/O는 거의 안부르고 계산하는데 시간을 더 쓴다.

### 3.2.1 스케쥴링 큐

프로세스가 시스템에 입력되면, 그들은 레디큐에 들어가는데 그들이 CPU 코어에서 레디나 실행을 대기중인 것들이다. 이 큐는 링크드 리스트로 저장되는데, 레디 큐 헤더는 리스트의 첫번쨰 PCB의 주소를 포함하고 각각의 PCB는 레디큐의 다음 PCB를 가르키고 있다.

시스템은 또한 다른 큐를 포함한다. 프로세스가 CPU 코어에 할당되면, 그것은 종료되거나, 인터럽트되거나, 특정 이벤트가 생길때 까지 실행한다. 프로세스가 I/O 요청을 디스크 같은 디바이스에 했다고 가정하자. 드라이버가 프로세서보다 느리기 때문에, 프로세스는 I/O가 가용해질 때까지 기다려야한다. 프로세스는 그러면 I/O의 완료까지 기다리고 wait queue에 위치하게 된다.

일반적인 프로세스 스케쥴링의 표현은 **queueing diagram**이다. 두가지 타입의 큐가 존재하는데 레디큐와 웨이트 큐이다. 프로세스는 생성되면 레디큐에 들어간다. 그것은 실행될때까지 대기한다. 한번 CPU 코어에 프로세스가 할당되면, 몇몇 이벤트가 생긴다.

- 프로세스는 I/O 요청을 실행하고 I/O wait 큐에 들어간다.
- 프로세스는 새로운 자식 프로세스를 만들고 자식이 종료할때까지 wait 큐에서 대기한다.
- 프로세스는 그것의 타임 지분 만료로 코어에서 강제로 제거되고 레디큐에 다시 들어간다

첫번쨰 2가지 케이스는, 프로세스는 waiting 상태에서 ready 상태로 바뀌면서 ready 큐에 들어간다. 프로세스는 종료될때까지 이 사이클을 유지하고 사이클이 끝나면, 모든 큐에서 제거되고 그것의 PCB와 리소스들은 할당이 해제된다.

### 3.2.2 CPU 스케쥴링

프로세스는 그것의 생애동안 레디큐와 다양한 wait 큐를 이동한다. CPU 스케쥴러의 역할은 레디큐에 있는 프로세스를 선택하고 그둘중 하나에 CPU 코어를 할당하는 것이다. CPU 스케쥴러는 반드시 새로운 프로세스를 위해서 CPU를 선택해야한다. I/O 바운드 프로세스는 몇 미리세컨드동안 실행하기전에 I/O 요청을 기다린다. 비록 CPU 바운드 프로세스가 긴 수명을 요구하지만, 스케쥴러는 프로세스에게 확장된 주기를 보장하지 않는다. 대신에, 그것은 프로세스를 CPU에서 강제로 제거하고 다른 프로세스를 실행한다. 그러므로, CPU 스케쥴러는 100milliseoncds 마다 실행하고, 더 많이 그런다. 

몇몇 운영체제는 스케쥴링의 중개자를 가지고 있는데, **swapping**이라고 하고 이것의 메인 아이디어는 프로세스를 메모리에서 제거하고 멀티프로그래밍의 차수를 줄이는 것이다. 그리고 프로세스는 메모리로 다시 들어오고, 그것의 실행은 떠날때까지 지속된다. 이런 기술은 스와핑이라고 하는데 왜냐하면 프로세스가 메모리에서 디스크로 스왑 아웃 당하기 때문이다. 그리고 디스크에는 현재의 상태가 저장되고, 메모리로 다시 스왑인을 하고 그것의 상태가 복구된다. 스와핑은 보통 메모리가 과용적되고 해제가 필요할때 필수적이다.

### 3.2.3 Context switch

인터럽트는 운영체제가 CPU의 현재 진행중인 일을 바꾸고 커널 루틴을 실행하게 한다. 인터럽트가 발생하면, 시스템은 현재 프로세스의 컨텍스트를 저장하고 프로세싱이 끝나면 컨텍스트를 복구한다. 즉 프로세스를 멈추고 재시작하게 한다. 컨텍스트는 프로세스의 PCB를 표현한다. 그것은 CPU 레지스터 값, 프로세스 상태, 메모리 관리 정보를 포함한다. 일반적으로 그들은 CPU 코어의 현재 상태를 저장하고, 커널이나 유저모드로 바꾸고, 그리고 상태를 복구하고 명령어를 재시작한다.

다른 프로세스로 CPU 코어 스위칭은 현재 프로세스의 상태 저장과 다른 프로세스 상태의 복구가 필요로한다. 이 일들은 컨텍스트 스위치라고한다. 컨텍스트 스위치가 일어나면, 커널은 PCB 속의 예전 프로세스의 컨텍스트를 저장하고 새롭게 스케쥴된 프로세스의 컨텍스트를 부른다. 컨텍스트 스위치 시간은 순수한 간접비인데 시스템이 스위칭 간에 유용한 일을 하지 않기 때문이다. 스위칭 속도는 기계마다 다르고, 메모리 속도에 따라서 변하고, 복사되는 레지스터의 수에 따라서 바뀌고, 특별한 명령(한번의 명령으로 모든 레지스터를 저장하거나 부르는 것)에 달려있다.

컨텍스트 스위치 시간은 하드웨어 지원에 깊게 의존한다. 예를 들어서, 몇몇 프로세서는 여러가지 종류의 레지스터 셋을 지원한다. 컨텍스트 스위치는 현재 레지스터 셋의 포인터를 바꾸는 것을 필요로 한다. 물론, 만약에 활동중인 프로세서보다 레지스터가 많으면, 시스템은 메모리로부터 레지스터 데이터를 복사한다. 또한, 운영체제가 더 복잡할수록, 컨텍스트 스위치 간에 더욱 많은 일이 필요하다.

9장에서는, 진보된 메모리 관리 기술이 각 컨텍스트마다 스위칭에 추가 데이터를 필요로 할 것이다. 예를 들어서, 현재 프로세스의 주소 공간은 반드시 새로운 일의 공간이 사용준비가 될때 보존되어야한다. 어떻게 주소공간이 보존되고 무슨 일들이 보존될지는 메모리 관리 기술에 달려있다.

## 3.3 Operation on Processes

대부분의 시스템안의 프로세스는 동시다발적으로 실행되는데, 그들은 동적으로 생성되거나 삭제된다. 그러므로, 이러한 시스템들은 반드시 프로세스 생성과 종료에 대한 메커니즘을 제공해야한다. 이 절에서는, 우리는 프로세스 생성과 리눅스와 윈도우 시스템에서의 프로세스 생성을 설명할 것이다.

### 3.3.1 Process Creation

실행 과정중에, 프로세스는 몇가지 새로운 프로세스를 생성한다. 앞서 말했듯이, 프로세스 생성하기는 부모 프로세스라고 불리고, 새로운 프로세스는 그 프로세스의 자식이라고 불린다. 각각의 새로운 프로세스는 다른 프로세스를 만들고, 프로세스의 트리를 구성한다. 대부분의 운영체제는 유일한 **process identifier(pid)**를 통해서 구별되고 일반적으로는 정수 숫자이다. pid는 시스템의 프로세스의 고유한 값을 제공하고, 커널 안에서 다양한 프로세스의 성질을 접근하기 위한 인덱스로 사용된다.

리눅스의 프로세스 시스템을 알아보겠다. 트리의 헤드에는 systemd라는 pid 1을 가진 프로세스(보통은 프로세스라고 하지만, 리눅스에서는 *task*를 선호한다.)는 보든 유저 프로세스의 루트 부보 프로세스이고 시스템이 부팅되면서 생긴 첫번째 유저 프로세스이다. 시스템이 한번 부팅되면, systemd 프로세스는 웹, 프린트서버, ssh서버같은 부가기능을 지원하는 프로세스를 생성한다. 그리고 그중에서 logind라는 프로세스는 시스템에 직접적으로 로그인하는 고객을 관리하는 책임을 가진다. 예를 들어서, bash 쉘을 사용해서 로그인 하는 클라이언트는 pid 8416을 할당받았다. bash CLI를 사용하면서, 이 유저는 ps 프로세스와 vim editor 프로세스를 생성한다. sshd 프로세스는 ssh를 통해서 접속하는 클라이언트를 관리한다. 

유닉스와 리눅스 시스템에서 우리는 ps 커맨드를 통해서 현재 실행중인 프로세스를 확인할 수 있다. ps -el이라는 명령어는 시스템에서 현재 활성화된 모든 프로세스의 정보 리스트를 제공한다. 또한 트리 모양은 pstree 명령어로 확인할 수도 있다.

보통은, 프로세스가 자식 프로세스를 만들면, 자식 프로세스는 그것의 일을 완수하기위해서 일부 자원(CPU 시간, 메모리, 파일, I/O디바이스)가 필요할 것이다. 또는 그것은 부모 프로세스의 리소스 일부분으로 제한될 수도 있다. 부모는 그것의 자원을 자식들간에 배분해야할 수도 있고, 몇몇 자식들간에 일부자원을 공유하게 해야할 수도 있다. 자식 프로세스를 제한하는 것은 많은 자식 프로세스의 생성에 따른 오버로딩을 막을수 있다.

다양한 물리적 논리적 자원을 제공하기 위해서, 부모 프로세스는 자식 데이터에게 초기화 데이터를 건내줄수도 있다. 예를 들어서, 파일의 컨텐츠를 보여주는 함수를 가진 프로세스를 고려하겠다. 프로세스가 생성되었을 때, 그것은 그것의 부모 프로세스로 부터 인풋을 받을 것이고, 파일을 열고 컨텐츠를 보여줄 것이다. 그것은 또한 출력 장치의 이름을 얻을 수도 있다. 몇몇 운영체제는 자식 프로세스에게 리소스를 넘길 수도 있다. 이런 시스템에서는, 프로세스는 두개의 오픈 파일을 가지고, hw1.c와 터미널 디바이스는 datum을 둘 사이에서 주고받을 것이다. 프로세스가 새로운 프로세스를 만들면, 실행이 존재하는 두가지 가능성이 있다.

1. 부모가 자식과 함께 실행한다.
2. 부모가 자식이 끝날때까지 기다린다.

새로운 프로세스를 위한 주소공간도 두가지 방법이 있다.

1. 자식 프로세스가 부모 프로세스의 복제본이된다.(그것은 부모와 같은 프로그램과 데이터를 가진다.)
2. 자식 프로세스가 새로운 프로그램을 불러온다.

이러한 차이를 설명하기 위해서, 유닉스 운영체제를 고려해보자. 유닉스에서는 각각의 프로세스는 그것의 pid로 구별된다. 새로운 프로세스는 fork() 시스템 콜에 의해서 생성된다. 그 새로운 프로세스는 원본 프로세스의 주소공간의 복사본을 가진다. 두 프로세스는 fork() 명령어 이후에, 한가지 차이를 가진다. : 새로운 프로세스의 fork()의 리턴 값은 0이고 pid가 0이아닌 자식들의 리턴 값은 부모이다.

fork() 시스템 콜 이후에, 프로세스는 exec() 시스템콜은 메모리에 이진 파일을 넣고 그것의 실행을 시작한다. 이런 상황에서, 두개의 프로세스는 소통이 가능해지고 그들의 분리된 길을 간다. 부모는 더욱 많은 자식을 가질수 있고, 자식이 실행중에 하는 일이 없다면, wait() 시스템콜을 발행하고 자식의 종료때까지 ready 큐밖에서 기다린다. exec() 콜은 새로운 프로그램과 함께 프로세스의 공간이 포개어지기 때문에, exec()는 에러가 발생하기 이전까지는 리턴하지 않는다.

### 3.3.2 프로세스 종료

프로세스는 마지막 절을 실행하고 운영체제에게 exit() 시스템 콜을 통해서 종료해달라고 한다. 그런 점에서, 프로세스는 기다리는 부모 프로세스에게 상태 값을 리턴할수도 있다(wait() 시스템 콜을 통해서). 프로세스의 리소스는 물리/가상 메모리, 오픈 파일들, I/O 버퍼들은 운영체제에 의해서 해제되고 재 설정딘다.

종료는 다른 상황에도 일어날 수 있다. 프로세스는 적절한 시스템 콜을 통해서 다른 프로세스를 종료시킬 수 있다.(TerminateProcess() 윈도우에서). 보통 이런 시스템 콜은 종료되려고하는 부모 프로세스에 의해서 실행된다. 다른 경우에는 유저 또는 잘못 동작하는 앱은 다른 유저의 프로세스를 죽일수 있다. 부모 프로세스는 자식 프로세스를 죽이기 위해서는 그것의 이름을 아는 것이 필요하다. 그러므로, 프로세스가 새로운 프로세스를 만들면, 새롭게 생성된 프로세스는 그것의 부모에게 넘어간다.

부모는 다양한 이유로 자식을 죽일수 있는데 다음과 같다.
- 자식이 할당된 리소스보다 많은 사용을 했을때이다.(이걸 확인하려면, 부모는 자식의 상태를 관찰할 매커니즘이 필요하다.)
- 자식에게 할당된 일이 더이상 필요가 없을떄.
- 부모가 종료되고 시스템이 부모가 종료되었을때 더이상 자식을 허용하지 않을떄.

몇몇 시스템은 부모가 종료되면 자식을 허용하지 않는다. 이러 ㄴ시스템에서는 만약 프로세스가 (정상적으로나 비정상적으로) 종료가 되면, 그것의 자식들은 반드시 종료되어야한다. 이런 현상을 **cascading termination**이라고 한다. 그리고 운영체제에 의해서 실행된다.

프로세스가 실행중인지 아닌지 설명하려면, 리눅스와 유닉스에서는 우리는 exit() 시스템콜을 통해서 프로세스를 종료할수 있는데, exit은 파라미터를 제공한다.

실제로, 정상적인 종료에서, exit()는 직/간접적으로 디폴트 값으로 exit() 콜을 포함할 것이다.

부모 프로세스는 wait()를 통해서 자식 프로세스의 종료를 기다릴 수 있다. wait() 시스템 콜은 자식의 exit 상태를 얻을수있는 파라미터를 가진다. 이 시스템 콜은 종료된 자식의 식별자를 리턴하고 부모는 어떤 자식이 종료되었다는 것을 말할 수 있다.

    
    pid_t pid;
    int status;

    pid = wait(&status);

프로세스가 종료되면, 그것의 자원들은 운영체제에 의해서 해제된다. 그러나 프로세스 테이블의 엔트리는 부모가 wait()를 부를떄까지 유지하는데, 프로세스 테이블은 프로세스의 exit 상태를 포함하기 때문이다. 종료된 프로세스는, 하지만 부모에 의해서 wait()로 불리지 않은 것은 좀비 프로세스라고 불린다. 모든 프로세스가 이 상태로 이동하면, 좀비로 간편하게 존재한다. 한번 부모가 wait()를 콜하면, 좀비 프로세스의 pid와 프로세스 테이블의 엔트리는 풀려난다.

이제 만약 부모가 wait를 부르지 않으면 어떤 일이 일어나는지 알아보자. 대신에 그것의 자식을 고아로 만드는 상황을 생각해보겠다. 전통적인 유닉스 시스템은 init 프로세스를 새로운 부모 부터 고아 프로세스로 할당한다. init 프로세스는 주기적으로 wait() 콜을 생성하고, 따라서 어떤 고아가된 프로세스든 모이고 고아의 pid와 프로세스 테이블 엔트리를 해제한다.

비록 리눅스 시스템이 init을 systemd로 바꾸었어도 여전히 같은 동작을 취한다. 그리고 고아 프로세스의 관리를 systemd이외의 프로세스를 허용한다.

### 3.3.2.1 안드로이드 프로세스 계보

제한된 메모리같은 리소스 제한때문에, 모바일 운영체제는 제한된 시스템 리소스를 재설정하기위해서 존재하는 프로세스를 종료한다. 제멋대로인 프로세스를 종료하는 것보다, 안드로이드는 시스템이 새로운, 더 중요한 프로세스를 위해서 존재하는 것을 종료해야할때를 위한 프로세스의 중요성 계보를 가지고 있다. 그것은 중요도가 증가하는 순서대로 프로세스를 종료한다. 최대부터 최소 중요성까지, 프로세스 분류 계보는 다음을 따른다.

- Foreground process - 스크린에서 현재 보이는 프로세스, 현재 유저가 상호작용하는 앱이다.
- Visible process - 프로세스가 보이지는 않지만, foreground 프로세스가 언급하는 현재 활동중인 앱이다.
- Service process - 백그라운드 프로세서와 비슷하지만, 유저에게 분명한 활동을 하는 프로세스이다.(음악 스트리밍)
- Background process - 활동중이지만 유저에게 분명하지 않은 프로세스
- Empty process - 아무런 활동적인 활동없는 프로세스

만약 시스템 리소스가 재정의되면, 안드로이드는 먼저 empty를 지우고 background를 멈추고 더 나아간다. 프로세스는 중요도 랭킹으로 할당되고, 안드로이드는 최대한 높은 등수를 프로세스에 할당하려고 한다. 예를 들어서, 만약 프로세스가 서비스를 제공하고 눈에 보이면, 그것은 visible 프로세스 분류에서 가장 중요하다고 한다.

더 나아가서, 안드로이드 개발 실습은 프로세스 라이프 사이클의 가이드라인을 제시한다. 이 가이드라인이 따라오면, 프로세스의 상태는 종료전까지 우선을 가지고 만약 유저가 다시 앱으로 돌아가면 그것의 저장된 상태를 재시작한다.

## 3.4 IPC

운영체제에서 동시에 실행중인 프로세스는 독립적이거나 협력하는 프로세스일 것이다. 프로세스는 만약에 시스템 속에서 실행중인 다른 프로세스와 데이터를 공유하지 않으면 독립적이라고 한다. 협력하는 프로세스는 만약에 시스템의 다른 프로세스에게 영향을 받거나 주면 협력적이라고 한다. 분명하게, 데이터를 공유하는 프로세스는 협력 프로세스라고 한다. 프로세스끼리 협력하는 환경을 제공하는 이유는 다음과 같다.

- 정보 공유 - 앱들이 같은 정보의 조각들에 관심이 있다면, 우리는 반드시 이런 정보에 동시에 접근하도록 허용해야한다.
- 컴퓨테이션 가속 - 만약 몇몇 작업이 빠르길 원하면, 우리는 그것을 분할해서 다른 것들과 병행으로 실행하게 해야한다. 이런 스피드업은 오직 컴퓨터가 다중 프로세싱 코어를 가질때 가능하다.
- modularity - 우리는 시스템을 모듈러 상태로 건설하기를 원하고 시스템을 분리된 프로세스나 쓰레드로 가지길 원한다.

협력 프로세스는 **Iterprocess communication(IPC)**를 필요로하는데 이것은 데이터를 교환하게한다. 즉, 데이터를 서로에게 보내고 받는다. 두가지 기본적인 통신 방식이 있다. 메모리 공유와 메시지 패싱이다. 공유 메모리 모델에서는, 메모리의 영역은 프로세스가 만들어지면서 생긴다. 프로세스는 공유된 영역을 읽고 씀으로서 정보를 교환한다. 메시지 패싱 모델에서, 협력 프로세스들 사이에서 메시지 교환의 목적으로 통신이 자리잡는다.

두 모델은 다양한 시스템에서 일반적으로 언급된다. 메시지 패싱은 작은 양의 데이터를 교환하는데 도움이되는데, 충돌을 피할필요가 없기 때문이다. 메시지 패싱은 공유메모리보다 분산 시스템에서 더욱 쉽게 실행된다. 공유 메모리는 메시지 패싱보다 빠른데, 메시지 패싱은 커널의 시스템 콜을 필요로하기 때문이다. 공유메모리에서, 시스템 콜은 오직 공유 메모리 영역을 건설할때 필요로한다. 한번 공유메모리가 생기면 모든 접근은 일반적인 메모리 접근으로 여겨지고 커널의 도움은 전혀 필요없다.

## 3.5 IPC in shared memory system

공유 메모리 IPC를 통해 통신하는 프로세스는 공유메모리의 영역을 건설할 필요가 있다. 보통, 공유 메모리 영역은 공유 메모리를 만드는 프로세스의 주소 공간에 거주한다. 통신을 원하는 다른 프로세스는 그들의 주소공간에 반드시 공유메모리 세그먼트를 부착해야한다. 보통 운영체제는 한 프로세스가 다른 프로세스의 메모리를 접근하는 것을 방지하려고 한다. 공유 메모리는 이런 제한을 없애는 것을 허용해야한다. 그들은 그러면 공유된 영역에서 공통 영역에서 데이터를 읽고 쓸수 있다. 데이터의 모양과 위치는 프로세스에 의해서 결정되고 운영체제의 영향을 받지 않는다. 프로세스는 그들이 같은 위치에 동시에 쓰지 않도록 하기도 해야한다. 협력 프로세스의 개념을 설명하기 위해서 생산자-컨슈머 문제를 고려해보겠다. 생산자 프로세스는 소비자 프로세스에 의해서 소비되는 정보를 생산한다. 예를 들어서, 컴파일러는 어셈블러에 의해서 소비되는 어셈블리 코드를 생산한다. 에섬블러의 입장에서는 로더가 소비하는 오브젝트 모듈을 생산할 수도 있다. 생산자-소비자 문제는 제공자로 생산자, 고객으로 소비자를 생각한다. 예를 들어 웹서버가 HTML같은 웹 컨텐츠를 제공하고 웹 브라우저에 요청된 자원은 소비된다.

한가지 생산자-소비자 문제를 해결하는 방법은 공유메모리이다. 두 프로세스가 동시에 작동하기 위해서 우리는 반드시 생산자에 의해서 채워지고 소비자에 의해서 비워지는 아이템의 버퍼가 필요하다. 이 버퍼는 생산자와 소비자 프로세스가 공유하는 메모리의 영역에 상주한다. 생산자는 소비자가 다른 아이템을 소비하는 동안 다른 아이템을 생산할 수 있다. 생산자와 소비자는 반드시 동기화되어야하고, 소비자는 생산되지 않은 상품을 소비하려고 하지 않아야한다.

두가지 타입의 버퍼가 사용가능하다. **Unbounded buffer**은 버퍼의 크기를 가지지 않는다. 그 소비자는 새로운 아이템을 기다리지만, 생산자는 항상 새로운 아이템을 생산한다. **Bounded buffer**는 고정된 버퍼 크기를 가진다. 이 경우에는, 소비자는 버퍼가 비게되면 기다리고 생산자는 버퍼가 차게되면 기다린다.

bounded buffer가 어떻게 사용되는지 보겠다. 다음과 같은 변수가 생산자-소비자 프로세스의 공유 영역에 머문다.


    #define BUFFER_SIZE 10

    typedef struct {
        . . .
    }item;

    item buffer[BUFFER_SIZE];
    int in = 0;
    int out = 0;

공유된 버퍼는 두가지 논리 포인터로 환형 배열로 실행된다. in 포인트는 버퍼에서 다음 빈 공간을 가르키고, out 포인트는 버퍼의 첫번째 가득찬 위치를 가르킨다. 버퍼는 in==out일때 비어있고 (in+1)%BUFFER_SIZE == out일때 가득 찼음을 가르킨다. 생산자 프로세스는 next_produced 지역변수를 통해서 생산된 새로운 아이템이 저장될 곳을 가르킨다. 마찬가지로 소비자 프로세스는 소비될 아이템이 있는 위치를 알린다. 3.7.1에서 POSIX 공유메모리 API를 알려주겠다.

한가지 걱정은 공유된 버퍼에 동시에 두 프로세스가 접근하는 것이다. 이것은 6장과 7장에서 동기화를 배우고 효과적으로 공유 메모리 환경을 실행하는 법을 배우겠다.

## 3.6 IPC in Message-Passing Systems.

3.5절에서, 우리는 공유 메모리 환경에서 협력프로세스가 어떻게 통신하는지 보여줬다. 이 기술은 메모리의 영역을 공유해서 코드가 앱 프로그래머에 의해서 공유된 메모리에 쓰여지고 접근된다. 다른 방법은 운영체제가 지원하는 메시지 패싱 기술을 이용해서 통신하는 것이다.

메시지 패싱은 프로세스가 통신하는 것을 허용하는 메커니즘을 제공하고 공유된 주소 공간 없이 그들의 행동을 동기화한다. 그것은 특히 분산 환경에서 유용한데, 통신 프로세스는 네트워크로 연결된 다른 컴퓨터에 있을 수 있기 때문이다. 예를 들어서, 인터넷 챗 프로그램은 챗 참가자들이 메시지 교환을 통해서 소통하게끔 디자인된다.

메시지 패싱 기능은 2가지 명령어를 제공한다. send(message)와 recieve(message)이다.

메시지는 사이즈에 상관없이 프로세스에 의해서 보내진다. 만약 고정된 사이즈 메시지가 보내지면, 시스템 레벨 실행은 꽤나 직관적이다. 이 제한은, 그러나, 프로그래미의 일을 더욱 힘들게 만든다. 반대로, 다양한 사이즈의 메시지는 복잡한 시스템 레벨 실행을 요구하지만, 프로그래밍 업무는 간단하다. 이것은 운영체제 디자인에서 흔히 보이는 트레이드오프이다. 만약 프로세스 P와 Q가 통신을 원하면, 그들은 반드시 서로에게 메시지를 보내고 받아야한다. 통신 링크는 그들 사이에 반드시 존재한다. 이 링크는 다양한 방법으로 추가된다. 우리는 링크의 물리적 설치는 보지 않겠다.(예를 들어서, 공유메모리, 하드웨어 버스, 네트워크는 19장에서 나온다.) 오히려 논리적 설치를 보겠다. 여기에 논리적 링크 설치를 위한 몇가지 방법과 send()/receive() 명령어가 있다.

- Direct or indirect 통신
- 동기화 또는 비동기화 통신
- 자동 또는 노골적인 버퍼링

### 3.6.1 네이밍

통신을 원하는 프로세스는 서로를 언급할 방법이 있어야한다. 그들은 직접 또는 간접 통신을 사용한다. 직접 통신에서는 각각의 프로세스는 통신의 수신자와 발신자를 명백하게 이름지어서 통신하기를 원한다. 이 기술에서, send()와 receive() 원조는 다음과 같다.

- send(P, message) - Send a message to process P.
- receive(Q, message) -Receive a message from process Q.

이 기술속의 통신 기술은 다음과 같은 재산을 가진다.

- 링크는 통신을 원하는 모든 프로세스의 쌍으로 자동적으로 생긴다. 프로세스는 통신하기위해서 각자의 이름을 안다.
- 링크는 오직 2개의 프로세스에만 있다.
- 두 프로세스의 사이에, 오직 하나의 선만이 있다.

이 기술은 어드레싱에서 대칭적이다. 전송자 프로세스와 수신자 프로세스는 각자의 이름을 반드시 사용해야한다. 이 기술의 다른 방법은 어드레싱이 비대칭적이다. 여기서는 오직 발신자만 수신자를 정하고, 수신자는 발신자의 이름을 필요로 하지 않는다. 이런 경우에는 명령어는 다음과 같다.

- send(P, message) - Send a message to process P
- receive(id, message) - Receive a message from any process. id는 통신가능한 프로세스의 이름 집합이 차지하고 있다.

두가지 방법의 단점은 프로세스 정의가 만드는 결말의 제한된 모듈성이다. 프로세스의 id를 바꾸는 것은 모든 프로세스 정의를 재검사하는 것을 필요로한다. 오래된 식별자로의 레퍼런스는 반드시 찾아지고 새로운 식별자로 바뀌어야한다. 보통, 하드 코딩 기술에서, 식별자가 명확하게 언급된, 다음에 언급될 비간접 방법보다 덜 효과적이다.

*indirect communication*에서 메시지는 메일박스나 포트를 통해서 보내지거나 받아진다. 메일 박스는 추상적인 객체로 보여지고 메시지는 프로세스에 의해서 위치하거나 제거될수 있다. 각각의 메일 박스는 유일한 식별자가 있다. 예를 들어 POSIX 메시지 큐는 메일 박스를 구별한 정수 값이 있다. 프로세스는 다른 프로세스와 다양한 메일 박스를 통해서 통신할수 있다. 하지만, 두개의 프로세스는 오직 공유된 메일 박스가 있을떄만 통신할 수 있다. 명령어는 다음과 같다.

- send(A, message) - Send a message to mailbox A.
- receive(A, message) - Receive a message from mailbox A.

이런 기술에서, 통신 링크는 다음과 같은 재산을 가진다.

- 링크는 멤버 쌍이 공유된 메일 박스를 가질떄 생긴다.
- 링크는 2개 이상의 프로세스와 관련되어있다.
- 통신하는 프로세스의 쌍들 사이에, 다양한 링크가 존재하고, 각 링크는 메일박스와 관련되어있다.

이제 P1, P2, P3가 공유 메일박스 A를 가졌다고 가정하겠다. P1은 A에 메시지를 보내고 P2, P3는 A로 부터 receive()를 실행한다. 어떤 프로세스가 P1에 의해서 받아졌을까? 다음과 같은 대답은 우리가 고르게 될 방법에 따라 달라진다.

- 링크를 최대 두개의 프로세스만 가지도록 허용한다.
- 오직 하나의 프로세스만 receive 명령어를 동시에 실행하도록 한다.
- 시스템이 어떤 프로세스가 메시지를 받을지 무자구이로 정하도록 한다. 그 시스템은 어떤 프로세스가 메시지를 받을지를 선택하는 알고리즘을 정의한다(예를 들어 round robin, 프로세스가 메시지를 받는 시간을 가진다.). 시스템은 송신자에게 수신자르 알린다.

메일박스는 프로세스에 의해서 소유되거나 운영체제에 의해서 소유된다. 만약에, 메일박스가 프로세스에 의해서 소유되면(메일 박스가 프로세스의 주소공간에 존재한다.), 우리는 주인(오직 메일 박스를 통해서 메시지를 받는 것만 가능하다.)와 유저(메일박스로 메시지를 보내는 것만 가능하다.)를 구별한다. 각 메일 박스가 특별한 주인을 가지면, 프로세스는 보낸 메시지를 누가 받았는지를 헷갈릴 필요가 없다. 그리고 만약에 메일박스를 가진 프로세스가 종료되면, 메일박스는 사라진다. 그리고 메시지를 보내는 프로세스들은 반드시 이 메일박스가 더이상 존재하지 않은 것을 통지받아야한다.

반대로, 메일박스가 운영체제에 의해서 소유된다. 그것은 독립적이고 어떤 프로세스에도 부착되어 있지 않다. 운영체제 시스템은 다음과 같은 메커니즘을 프로세스에게 제공한다.

- 새로운 메일박스 생성
- 메일박스를 통한 송신과 수신
- 메일박스 삭제

새로운 메일 박스를 생성하는 프로세스는 기본으로 메일박스의 주인이다. 초기에, 주인은 이 메일박스를 통해서 메시지를 받는것만 가능했다. 그러나, 주인권한과 우선권 받기는 적절한 시스템 콜을 통해서 다른 프로세스에 옮겨질 수 있다. 물론, 이 영역은 각 메일 박스의 다중 수신자를 만들 수 있다.

### 3.6.2 동기화

프로세스간의 통신은 send와 receive 콜을 통해서 실행될 수 있다. 각각의 원조를 실행하는 것에는 다양한 디자인 옵션이 있다. 메시지 패싱은 블록킹또는 논블록킹이라는 동기화와 비동기화 방식이다.

- Blocking send - 보내는 프로세스는 메일 박스 또는 받는 프로세스에 의해서 받아지는 동안 멈춰진다.
- Nonblocking send - 보내는 프로세스는 메시지를 보내고 다시 명령을 실행한다.
- Blocking receive - 메시지가 존재할때까지 수신을 멈춘다.
- Nonblocking receive - 있던 없던 계속 수신한다.

다른 종류의 send 와 rececive 조합은 가능하다. 만약 두개의 명령이 blocking이면 우리는 수신자와 송신자의 만남을 가진다. 생산자 소비자 문제의 해결은 blocking send와 receive 상태에서는 사소하다. 생산자는 고작 blocking send 콜을 생성하고 메일박스나 수신자에게 메시지가 전해질때까지 기다린다. 비슷하게 소비자는 오직 메시지가 도착할떄만, receive를 생성한다. 

### 3.6.3 버퍼링.

통신이 직접적이든 간접적이든, 통신하는 프로세스의 메시지 교환은 임시 큐에 상주한다. 기본적으로, 이런 큐들은 3가지 방법으로 만들어진다.

- Zero capacity - 큐는 0의 최대길이를 가지고, 링크는 어떠한 메시지도 가질수 없다. 이런 경우에는 sender는 반드시 수신자가 메시지를 받을떄까지 기다려야한다.

- Bounded capacity - 큐는 제한된 길이 n을 가진다. 최대한 n의 메시지가 안에 존재한다. 만약 메시지가 보내졌을떄 가득차지 않으면, 메시지는 큐에 존재하고 송신자는 기다림 없이 계속 보낼수 있다. 링크의 크기가 제한되어있다. 만약 링크가 풀이면, 송신자는 반드시 큐의 공간이 빌떄까지 기다려야한다.

- Unbounded capacity - 큐의 길이는 무한이다. 그러므로 어떤 메시지도 들어가는 것을 기다린다. 송신자는 절대로 block 하지 않는다.

## 3.7 IPC 시스템 예제

이 절에서, 우리는 4가지 IPC 시스템을 보겠다. 우리는 우선 공유 메모리를 쓰는 POSIX API와 매크 운영체제에서의 메시지 패싱을 보겠다. 다음으로는 윈도우에서의 일부 메시지 패싱방식을 제공하는 메커니즘과 공유메모리를 보겠다. 우리는 유닉스 시스템의 IPC 메커니즘으로 마무리 짓겠다.

### 3.7.1 포식스 공유 메모리(http://logan.tw/posts/2018/01/07/posix-shared-memory/)

공유메모리와 메시지 패싱 IPC 메커니즘은 POSIX 시스템에서 존재한다. 여기서, 우리는 공유 메모리를 위한 POSIX API를 보겠다. 

POSIX 공유 메모리는 메모리 매핑으로 이루어져있고, 파일을 통해서 공유된 메모리를 관련짓는다. 프로세스는 반드시 shm_open() 시스템 콜을 이용해서 공유 메모리 객체를 만들어야한다.

`fd = shm_open(name, 0_CREAT | O_RDWR, 6666);`

첫번째 파라미터는 공유메모리 객체의 이름을 의미한다. 이 공유메모리에 접근하려는 프로세스는 반드시 이 이름으로 객체를 언급해야한다. 다음 파라미터는 공유메모리가 만약 없다면(O_CREAT) 만들도록하고 객체가 읽기와 쓰기(O_RDWR)을 의미한다. 마지막 파라미터는 공유 메모리 객체의 파일 엑세스 허용을 의미한다. 성공적인 shm_open() 시스템 콜은 공유 객체를 위한 정수형 파일 세부사항을 반환한다.

객체가 한번 만들어지면, ftruncate() 함수가 객체의 크기를 설정한다. 

`ftruncate(fd, 4096);`

마지막으로 mmap() 함수는 공유 메모리 객체를 포함한 memory-mapped file을 만든다. 이것은 공유 메모리 객체의 접근을 목적으로 하는 memory-mapped file의 포인터를 리턴한다.

### 3.7.2 mach message passing

메시지 패싱방법의 예시로는, 매크 운영체제이다. 매크는 분산 시스템을 위해서 디자인되었으나, 모바일과 데스크탑 시스템에 적합하다. 매크 커널은 프로세스와 비슷하지만 여러개의 쓰레드 제어와 적은 리소스를 가진 다양한 업무의 생성과 파괴를 지원한다. 매크의 IPC 통신 대부분은 메시지를 통해서 옮겨진다. 메시지들은 매크에서 포트라고 불리는 메일 박스로 받아지고 메시지로 보내진다. 포트들은 한정된 사이즈를 가지고 방향성이 없다. 두가지 통신 방식이 있는데, 메시지는 한개의 포트로 보내지고 반응은 분리된 reply 포트로 보내진다. 각각의 포트는 많은 송신자를 가지지만, 하나의 수신자를 가진다. 매크는 태스크, 스레드, 메모리, 프로세스같은 리소르를 대표하기 위해서 포트를 사용한다. 메시지 패싱은 객체 지향적인 접근을 각각의 시스템 리소스와 서비스가 통신하기위해서 제공한다. 메시지 패싱은 두개의 같은 호스트 또는 분산 시스템 속의 분리된 호스트의 포트 사이에서 일어난다.

각각의 포트들은 포트와 상호작용하는 태스크에 필요한 역량을 구분하기위한 **port rights**의 모음이다. 예를 들어서, 포트로부터 메시지를 받는 태스크는, 반드시 그 포트에 대해서 MACH_PORT_RIGHT_RECEIVE를 가져야한다. 그 포트를 만든 태스크는 포트의 주인이고, 그 주인은 그 포트를 통해서 메시지를 받도록 허용된 유일한 태스크이다. 포트의 주인은 포트의 능력을 조정할 수도 있다. 보통 이것은 reply 포트를 만들때 사용된다. 예를 들어서 태스크 T1이 포트 P1을 가졌고, 그것은 포트 P2로 메시지를 보냈다. 만약에 T1이 T2로부터 답장을 기대하면, 그것은 반드시 P1에 대해서 MACH_PORT_RIGHT_SEND 권한을 T2에게 주어야한다. port right의 소유권은 태스크 레벨이고, 태스크에 소유된 쓰레드들은 반드시 같은 port right를 가진다. 그러므로, 같은 태스크에 속한 두개의 스레드는 각 스레드별로 가진 스레드 포트를 통해서 메시지를 교환할수 있다.

태스크가 생성되면, 두개의 특별한 포트인 *Task Self* 포트와 *Notify* 포트또한 생성된다. 커널은 Task Self 포트의 권한을 가지고 태스크가 커널로 메시지를 보내는 것을 허용한다. 커널은 태스크의 Notify 포트를 통해서 이벤트 발생을 알릴수도 있다.

mach_port_allocate() 함수 콜은 새로운 포트를 생성하고 메시지의 큐를 위한 공간을 할당한다. 그것은 포트를 위한 권한을 구별한다. 각각의 포트 권한은 포트를 위한 이름으로 불리고, 포트는 권한을 통해서만 접근 가능하다. 포트 이름은 간단한 정수 값이고 유닉스 파일 기술자 처럼 행동한다. 다음 예시는 이 API를 통해서 포트를 만드는 것이다.

```c
mach_port_t port; //The name of the port right

mach_port_allocate(
    mach_task_self(), //a task referring to itself
    MACH_PORT_RIGHT_RECEIVE, // The right for this port
    &port); //the namme of the port right
```

각각의 태스크는 또한 부트스트랩 포트에 접근하고, 태스크가 시스템 전역 부트스트랩 서버에 만든 포트를 등록하게 허용한다. 한번 포트가 부트스트랩 서버에 등록되면, 다른 태스크들은 이 레지스트리안의 포트를 볼 수 있고 포트로 메시지를 보내는 권한을 얻을 수 있다.

각각의 포트와 연관된 큐는 사이즈가 제한되있고 처음에는 비어있다. 메시지들이 포트로 보내지면, 메시지들은 큐안으로 복사된다. 모든 메시지들은 믿음직하게 보내지고 같은  우선권을 가진다. 매크는 같은 송신자로부터 FIFO 구조를 보장하지만 무조건적인 순서는 아니다. 예를 들어서, 두명의 송신자가 있다면 어떤 순서로든지 큐될것이다.

매크 메시지는 다음과 같은 두개의 영역이 있다.

- 고정된 사이즈 메시지 헤더는 메시지에 대한 메타데이터를 포함하는데, 메시지의 사이즈와 소스와 목적지 포트를 포함한다. 보통, 보내는 스레드는 답장을 기대하므로, 소스의 포트 이름이 받는 태스크에게 건내지고 'return address'가 될 것이다.

- 데이터를 포함한 가변 사이즈 바디

메시지는 간편하거나 복접할 것이다. 간단한 메시지는 커널이 해석하지 못하는 보편적인, 구조화되지 않은 유저 데이터를 가진다. 복잡한 메시지는 데이터를 포함하는 메모리 위치 포인터를 포함하거나 포트 권한을 다른 태스크로 옮기도록 사용될 수 있다. Out of line 데이터 포인터는 특히 메시지가 대용량의 데이터를 건낼때 도움이 된다. 간단한 메시지는 메시지 안의 데이터를 복사하고 패키징하는 것이 필요하다. out-of-line 데이터 통신은 데이터가 저장된 메모리 공간의 위치만을 필요로 한다.

함수 mach_msg()는 메시지 송신과 수신을 위한 표준 API이다. 함수의 한 파라미터 값은 MACH_SEND_MSG or MACH_RCV_MSG 인데 그것이 보내는 명령어인지, 받는 명령어인지 구분한다. 우리는 클라이언트 태스크가 서버 태스크에게 간단한 메시지를 보내는지 볼것이다. 두개의 포트가 있고 -클라이언트와 서버-라고 하겠다. 클라이언트 태스크는 헤더를 건설하고 서버에 메시지를 보내고 서버는 메시지를 클라이언트로부터 받는다.

mach_msg() 함수는 메시지 패싱을 수행하기 위해서 생기는 함수 콜이다. mach_msg()는 매크 커널에 시스템 콜인 mach_msg_trap()를 생성한다. 커널 안에서, mach_msg_trap()은 mach_msg_overwrite_trap() 함수를 다음으로 부르고 실제 메시지의 패싱을 조절한다.

보내고 받는 명령어는 그들자체로 유연하다. 예를 들어서, 메시지가 포트로 보내질때, 그것의 큐는 가득찰 수가 있다. 만약 큐가 가득차지 않으면, 메시지는 큐로 복사되고, 보내는 태스크는 지속된다. 만약에 포트의 큐가 가득차면, 송신자는 몇가지 선택지 가 있다.

1. 큐의 공간이 있을때까지 무제한적으로 기다린다.
2. 최대 n 밀리세컨드를 기다린다.
3. 기다리지 않고 즉시 리턴한다.
4. 메시지를 임시로 캐시한다. 여기서 메시지는 메시지를 보내어야할 큐가 가득찼다고 하더라도 운영체제가 가지도록 한다. 메시지가 큐에 놓아지면, notification 메시지가 센더에게 다시 보내지고 오직 가득찬 큐로 한개의 메시지만 기다리도록 한다.

마지막 옵션은 서버 태스크를 의미한다. 리퀘스트를 마치고, 서버 태스크는 서비스를 요청한 태스크에 한번의 답장을 할 필요가 있고, 그러나 그것이 계속 다른 서비스 리퀘스트를 지속해야는데, 비록 클라이언트의 reply 포트가 가득차도이다.

메시지 시스템의 주요한 문제는 메시지의 보내는 사람 포트부터 받는 사람 포트의 복사 때문에 낮은 성능을 가진다. 매크 메시지 시스템은 이런 카피 명령어를 피하려고 노력했고 virtual-memory-management technique로 극복했다. 근본적으로 매크는 센더의 메시지를 포함한 주소공간을 수신자의 주소공간에 매핑하는 것이다. 그러므로, 메시지 자체는 실제로 복사되지 않고, 같은 메모리에 접근하는 것이다. 메시지 관리 기술은 메시지에 큰 성능향상을 주었지만 오직 인트라 메시지 시스템에만 적용된다.

### 3.7.3 윈도우

윈도우 운영체제는 기능성을 늘리고 새로운 기능의 추가를 위한 시간을 줄인 모듈성을 실행하는 현대 디자인의 예시이다. 윈도우즈는 다양한 운영체제 한경 또는 서브시스템 지원을 제공한다. 앱 프로그램은 이러한 서브 시스템을 메시지 패싱 메커니즘을 통해서 통신한다. 그러므로, 앱 프로그램은 서브시스템 서버의 고객으로 고려된다.

윈도우의 메시지 패싱 기능은 **advanced local procedure call(ALPC)**라고 불린다. 그것은 한 장치에서 두개의 프로세스가 통신하도록 사용된다. 그것은 표준 remote procedure call 메커니즘과 비슷하다. 매크와 비슷하게, 윈도우는 두 프로세스간에 통신을 유지하기 위해서 포트 객체를 사용한다. 윈도우는 두가지 포트를 사용한다. 커넥션 포트와 통신 포트이다.

서버 프로세스는 연결 포트 객체를 발행하고 모든 프로세스들이 볼수 있다. 클라이언트가 서브시스템으로부터 서비스를 원하면, 그것은 서버의 연결 포트 객체를 열고 그 포트로 연결 요청을 보낸다. 채널은 사적 통신 포트의 쌍으로 구성된다. 하나는 클라이언트 서버 메시지, 다른 것은 서버 클라이언트 메시지이다. 덧붙여서, 통신 채널은 클라이언트와 서버가 그들이 답장을 원할때 요청을 허용하는 콜백 메커니즘을 지원한다.

ALPC 채널이 생성되면, 3가지 방법중 하나가 선택된다.

1. 작은 메시지(256바이트 이하)는, 포트의 메시지 큐가 중간 저장소로 사용되고 메시지는 한 프로세스에서 다른 프로세스로 복사된다.
2. 큰 메시지는 반드시 채널과 관련된 공유메모리의 영역인 section object를 통해서 전달된다.
3. 데이터의 크기가 section object보다 크다면, API는 서버 프로세스가 클라이언트의 주소공간을 직접 읽고 쓰게 해준다.

클라이언트는 채널을 세팅할때 큰 메시지를 보내는지를 통해서 결정한다. 만약 클라이언트가 큰 메시지를 원하면, 그것은 section object가 생성되도록 결정한다. 비슷하게 서버가 답변이 크다면, 그것은 section object를 만든다. 그래서 section object는 사용되는데, 작은 메시지는 section objec에 대한 포인터와 정보 크기가 포함된 것을 보낸다. 이 방법은 첫번째 말한 방법보다는 복잡하지만, 데이터 복사는 피할수 있다.

윈도우의 ALPC 기능은 윈도우 API의 기능이 아니고 앱 프로그래머에게 보이지 않는다는 것이 중요하다. 오히려, 윈도우 API를 사용하는 앱들은 표준 remote procedure calls를 사용한다. RPC가 프로세스에서 생기면, RPC는 ALPC를 통해서 비간접적으로 다루어진다. 추가적으로, 많은 커널 서비스는 ALPC가 클라이언트 프로세스와 통신하게 해준다.

### 3.7.4 Pipes

파이프는 두개의 프로세스가 통신하도록 하는 전달자 역할을 한다. 파이프 들은 유닉스 시스템의 첫번째 IPC 메커니즘이다. 그들은 대개 다른 것들과 통신하기 위해서 간단한 방법을 프로세스에게 제공하는데, 물론 제한점이 존재한다. 파이프를 만들려면, 4가지 이슈가 고려되어야한다.

1. 파이프가 양방향 통신인지 아니면 단방향 통신인가?
2. 만약에 양방향이 허용되면, half duplex(데이터가 한번에 한길만 쓴다) or full duplex(데이터가 동시에 양방향을 지난다.)인가?
3. 통신 프로세스 간에 관계(부모-자식)이 존재하는가?
4. 파이프가 네트워크를 넘어서 통신할수 있는가? 또는 같은 머신에 프로세스가 존재해야하는가?

다음 절에서 우리는 유닉스와 윈도우 시스템에서 사용하는 두가지 타입의 파이프를 보겠다.

#### 3.7.4.1 Ordinary Pipes

파이프는 두 프로세스가 표준 생산자-소비자 상태에서 소통하게한다. 생산자는 pipe의 끝(**write end**)에 쓰고, 소비자는 다른 끝(**read end**)에서 읽는다. 결과적으로 파이프는 단방향이고, 한길 통신만을 지원한다. 만약 양방향 통신이 필요하면, 2개의 파이프가 사용되어야하고, 각 파이프는 데이터를 다른 방향으로 보내어야한다. 한 프로세스는 "Greetings"라는 메시지를 파이프에 쓰고, 다른 프로세스는 파이프로부터 메시지를 읽는다. 유닉스 시스템에서, 파이프들은 다음과 같은 함수로 생성된다.
`pipe(int fd[]) `
이 함수는 파이프를 int fd[] 파일 기술자를 통해서 접근하게한다. fd[0]는 파이프의 read end이고 fd[1]은 write end이다. 그러므로 파이프는 ordinary한 read()와 write() 시스템콜을 통해서 접근이 가능해진다.

ordinary 파이프는 만들어진 프로세스의 밖에서 접근이 불가능하다. 일반적으로는, 부모 프로세스는 파이프를 만들고 자식 프로세스와 통신하기 위해서 사용된다. 3.3.1을 회상하면, 자식 프로세스는 부모가 오픈한 파일을 상속받는다. 파이프가 특별한 타입의 파일이기에, 자식은 부모 프로세스로부터 파이프를 상속받는다. 부모에 의한 파이프의 write엔드 쓰기fd[1]은 파이프의 read end로부터 자식의 읽기fd[0]로 읽힐수 있다.

유닉스 프로그램은, 부모 프로세스가 파이프를 만들고 fork()콜을 실행한다. fork() 콜 이후에 일어나는 것은 파이프를 통해서 데이터가 어떻게 흐르느냐에 따라 달려있다. 이 예시에서, 부모는 파이프에 쓰고, 자식은 그것으로부터 읽는다. 부모와 자식 프로세스가 그들의 사용되지 않은 파이프를 알리는 것은 중요하다. 그것은 writer가 파이프의 끝을 닫았을때 파이프의 eof를 찾는 것을 확실하게 해주는 중요한 단계이다.

윈도우 시스템에서는, **anonymous pipes**라고 하는데, 그들은 유닉스와 비슷하다. 그들은 단방향이고 부모-자식 관계에서 작동한다. 덧붙여서, 파이프에 읽고 쓰는 것은 ReadFile()와 WriteFile() 함수로 작동한다. 파이프를 생성하는 윈도우 API는 CreatePipe() 함수인데, 4개지 파라미터가 있다. 

(1) 읽기 

(2) 쓰기 

(3) STARTUPINFO 구조의 예시(자식 프로세스가 파이프를 상속받았는지) 

(4) 파이프의 크기

유닉스는 자식 프로세스는 자동으로 상속되는데, 윈도우는 프로그래머가 어떤 특징을 상속받을지 명세해줘야한다. 이것은 첫번째 상속하는 핸들을 허용하고 파이프의 햄들을 읽고 쓰는 표준 입력과 표준 출력을 다시보내는 SECURITY_ATTRIBUTES 구조를 통해서 수행된다. 더 나아가, 파이프가 half duplex이면, 그것은 자식이 write end를 상속받는 것을 막아야한다. 프로세스는 이전 예시와는 오직 5번째 파라미터만 다르게 할 것인데, 이것은 자식 프로세스가 지정된 핸들을 상속받을지를 설정하는 것이다. 파이프로 쓰기전에, 부모는 먼저 쓰지 않는 파이프의 read end를 닫아야한다. 자식프로세스는 읽는다. 읽기전에 이 프로그램은 GetStdHandle()을 발생시켜서 읽기 핸들을 얻는다.

Ordinay pipe는 부모-자식 관계가 필요로한다. 이것은 이런 파이프는 오직 같은 머신에서만 가능하다는 의미이기도 하다.

#### 3.7.4.2 네임드 파이프

ordinary 파이프가 두쌍의 프로세스가 통신하도록 허용하는 간단한 메커니즘을 제공한다. 그러나, ordinary 파이프는 오직 통신할때만 존재한다. 유닉스와 윈도우 시스템에서, 프로세스가 종료되면, ordinary 파이프는 존재하지 않는다.

네임드 파이프는 더 강력한 통신 도구를 제공한다. 통신은 양방향일수는 있지만, 부모-자식 같은 관계는 필요로 하지 않는다. 한번 네임드 파이프가 생기면, 몇가지 프로세스들은 그것을 통신에 사용할 수 있다. 실제로, 몇가지 시나리오에서, 네임드 파이프는 몇가지 라이터를 가진다. 추가적으로, 네임드 파이프는 통신 프로세스가 끝난후에도 계속 존재한다. 유닉스와 윈도우 시스템은 파이프를 지원하지만, 실행 방식은 크게 다르다. 다음에 우리는 각 시스템에서의 네임드 파이프를 보겠다.

네임드 파이프는 유닉스에서 FIFOs라고 불린다. 한번 생성되면, 그들은 파일시스템의 특정 파일로 나타난다. FIFO는 mkfifo() 시스템 콜로 생기고 open() read() write() close() 시스템 콜로 제어된다. 그것은 확실하게 제거되기 전까지 존재한다. 비록 FIFOs가 양방향 통신을 지원하지만, half duplex 통신만이 허용된다. 추가적으로 통신 프로세스는 반드시 같은 컴퓨터에 있어야한다. 만약에 머신간 통신이 필요하면, 소켓이 반드시 사용된다.

윈도우의 네임드 파이프는 유닉스보다 더욱 다양한 통신 메커니즘을 제공한다. Full duplex 통신이 허용되고, 통신 프로세스는 같은 혹은 다른 머신에서 사용된다. 추가적으로, 오직 바이트 기반 데이터가 유닉스 FIFO를 통해 전송되는데 비해서, 윈도우 시스템은 바이트 또는 메시지 기반 데이터를 통신한다. 네임드 파이프는 CreateNamedPipe()를 사용한다. 통신은 네임드 파이프를 넘어서 수행되고 ReadFile()과 WriteFile() 함수로 실행된다.

## 3.8 클라이언트-서버 시스템 통신

3.4절에서, 우리는 프로세스가 공유메모리와 메시지 패싱으로 어떻게 통신하는지 말했다. 이런 기술은 클라이언트-서버 시스템에서도 사용될수 있다. 이 절에서는, 우리는 소켓과 RPC라는 두가지 전략을 살펴보겠다.

### 3.8.1 소켓

소켓은 통신을 위한 엔드포인트로 정의된다. 네트워크를 통해서 작동하는 소켓의 쌍은 프로세스마다 존재한다. 소켓은 포트넘버와 IP 주소와 포트 이름으로 연결된 것으로 구분된다. 보통, 소켓들은 클라이언트-서버 구조이다. 서버는 특정화된 포트를 들음으로서 들어오는 클라이언트들을 기다린다. 한번 요청이 들어오면, 서버는 클라이언트 소켓으로부터의 연결을 수락한다. 서버는 특정한 서비스(ssh, ftp, http)를 실행하고 알려진 포트(ssh는 22번 포트, http는 80번, ftp는 21번)을 듣는다. 1024이하의 모든 포트는 알려져있고 표준 서비스를 제공하는데 쓰인다.

클라이언트 프로세스가 연결 요청을 시작하면, 그것은 호스트 컴퓨터의 포트로 할당이 된다. 이 포트는 1024보다 높은 번호가 무작위로 할당된다. 예를 들어서, 만약 hosx X(146.86.5.20)이라는 클라이언트가 웹 서버(80번포트)의 연결을 원하면 host X는 1625를 할당 받는다. 연결은 소켓의 페어로 구성되어있다. (146.86.5.20:1625) host x와 (161.25.19.8:80) 웹서버이다. 호스트사이에서 움직이는 패킷은 목적지 포트 넘버에 기반해서 적절한 프로세스로 배달된다.

모든 연결은 반드시 유니크하다. 그러므로, 만약에 host x위의 다른 프로세스가 웹서버와 연결을 원하면 그것은 1024보다 크지만, 1625와는 다른 포트를 할당받아야한다. 이것은 모든 연결이 유니크한 소켓의 페어를 만들게 한다.

비록 대부분의 프로그램은 C에서 쓰이지만, 여기서는 자바를 사용하겠다. 자바는 더욱 풍부한 네트워킹 기능을 쉽게 지원하기 떄문이다. C기반의 소켓 프로그래밍은 챕터의 끝 bibliographical notes에 있다. 

자바는 3가지 다른 방식의 소켓을 제공한다. Connection-oriented(TCP)라는 자바의 Socket 클래스로 작동하는 소켓이다. Connectionless(UDP) 소켓은 DatagramSocket 클래스를 사용한다. 마지막으로 MulticastSocket 클래스는 DatagramSocket 클래스의 하위 클래스이다. 멀티캐스트 소켓은 데이터가 여러명의 수신자를 가지게 한다.

우리의 예제는 연결-기반 TCP 소켓을 사용한 날짜 서버이다. 그 명령어는 클라이언트가 현재의 시간과 날짜를 서버를 통해서 받는 것이다. 서버는 6013포트로 부터 듣고, 포트는 1024보다 더큰 아무 수를 가질수도 있다. 연결이 받아지면, 서버는 클라이언트에게 날짜와 시간을 리턴한다.

날짜 서버는 ServerSocket을 6013포트로 듣는다. 서버는 accept() 메서드로 포트로부터 듣는다. 서버는 accept() 메소드를 클라이언트가 요청하기전까지는 블럭한다. 연결이 받아지면, accept()는 소켓을 리턴하고 서버는 클라이언트와 통신할 수 있다.

서버가 어떻게 소켓과 통신하는지는 다음과 같다. 서버는 먼저 PrintWriter 객체를 만들어서 클라이언트와 통신하는데 쓴다. PrinterWriter 객체는 print()와 println() 메서드를 통해 소켓에 아웃풋으로 쓰도록 허용한다. 서버 프로세스는 클라이언트에 날짜를 보내는데, println 메서드를 부른다. 한번 소켓에 날짜가 쓰이면, 서버는 소켓을 닫고 다른 리퀘스트를 듣는다.

클라이언트는 서버와 소켓을 만드는 것과 서버가 듣는 포트를 듣는것으로 연결한다. 우리는 자바프로그램에 보이는 다음과 같은 연결을 만든다. 클라이언트는 소켓을 만들고 127.0.0.1:6013의 위치 서버에 연결을 요청한다. 날짜를 서버로부터 받으면, 클라이언트는 소켓을 닫고 나간다. IP 주소는 loopback으로 알려져있다. 컴퓨터가 127.0.0.1을 부르면 그것은 그것을 의미한다. 이 메커니즘은 클라이언트와 서버가 같은 호스트에서 TCP/IP 프로토콜로 통신하는 것을 허용해준다. 이 IP 주소는 주소 서버를 운영하는 다른 IP주소로 바뀔수 있다. 예를 들어서 www.west~~등이 있을 것이다.

소켓을 사용하는 통신은 일반적이고 효율적이지만, 분산 프로세스 간의 낮은 레벨 형태를 취한다. 소켓이 구조화되지 않은 바이트가 통신하는 스레드간에 교환하게끔 허용한다. 클라이언트나 서버 앱이 데이터 구조위에 있는 것이 안전하다. 다음 서브 섹션에서는 높은 레벨의 통신 방법인 RPC를 살펴보겠다.

### 3.8.2 Remote Procedure Calls

원거리 서비스의 가장 일반적인 형태는 RPC 패더다임이고, 네트워크 연결로된 시스템인데 추상상화된 디자인 방법이다. 그것은 IPC 메커니즘과 많이 비슷하고, 보통 시스템의 최상단에 만들어진다. 여기서, 우리는  분리된 시스템위에서 환경과 교환하기 때문에, 우리는 반드시 원거리 서비스를 제공하는 메시지 기반 통신 기술이다.

IPC 메시지와는 다르게, RPC 통신으로 교환되는 메시지는 잘 구조화되어있고 데이터 패킷에 불과하지 않다. 각각의 메시지는 리모트 시스템의 포트를 듣는 RPC 데몬을 가르키고 각각은 실행을 특정하는 함수 식별자를 가지고 함수에 전달할 파라미터를 가진다. 함수가 요청되면, 어떤 형태의 아웃풋이 분리된 메시지로 리퀘스터에게 보내진다.

여기서의 **포트**는 메시지 패킷의 시작을 포함한 숫자이다. 반면에, 시스템은 보통 한개의 네트워크 주소를 가지는데, 그것은 다양한 네트워크 서비스를 지원하는 다른 주소포트를 가진다. 만약 리모트 프로세스가 서비스를 필요로 하면, 그것은 적절한 포트에 메시지를 지시해야한다. 예를 들어서, 만약 시스템이 다른 시스템이 현재의 유저에게 접근을 가능하게 하려면, RPC를 지원하는 데몬을 포트에 붙여야한다. 어떤 리모트 시스템도 필요한 정보(현재 유저이 리스트)를 서버위의 포트에 요청함으로서 얻을 수 있다. 데이터는 받아진 메시지를 받을 수 있다.

RPC의 의미는 클라이언트가 멀리 있는 호스트가 로컬에서 프로시저를 실행하듯이 프로시저를 실행하는 것에 있다. RPC 시스템은 클라이언트 단에서 **stub**를 제공함으로서 통신을 허용하는 자리를 숨길 수 있다. 분리된 stub은 각각의 원거리 프로시저에 존재한다. 클라이언트가 원거리 프로시저를 실행하면, RPC 시스템은 적절한 stub를 부르고, 원격 프로시저에 파라미터를 전한다. 이 stub는 서버의 포트에 상주하고 파라미터를 모은다(**marshal**). 스텁은 서버로 메시지 패싱을 통해서 메시지를 보낸다. 서버의 비슷한 스텁은 이 메시지를 받고 서버에서 프로시저를 실행한다. 만약 필요하다면, 리턴 값들은 같은 기술을 이용해서 클라이언트에게 다시 주어진다. 윈도우 시스템에서, stub 코드는 **Microsoft Interface Definition Language(MIDL)**으로 특별히 쓰인 것으로 컴파일되고, 클라이언트와 서버 프로그램 간의 인터페이스를 정의한다.

클라이언트와 서버 기계간의 데이터가 다른 점은 주소이다. 32비트 정수를 생각해보겠다. 몇몇 시스템(빅엔디안)은 가장 큰 바이트를 먼저 저정하는데 비해서 다른 시스템(리틀엔디안)은 작은 바이트를 먼저 저장한다. 어떤 순서가 그 자체로는 나은지는 없다. 오히려, 선택은 컴퓨터 구조에 따라서 임의적이다. 이런 다름을 해결하기 위해서, 많은 RPC시스템들은 데이터의 머신 독립 대표를 정의했다. 이런 대표중 하나는 **external data representation(XDR)**가 있다. 클라이언트 단에서는, XDR을 통해서 머신 의존 데이터가 서버에 들어가기전에 변환된다. 서버에서는 XDR 데이터들은 unmarshalled되고 서버 machine-dependent로 다시 변환된다.

다른 중요한 이슈는 sementics of a call이다. 반면에, 로컬 프로시저가 극적인 상황에서만 실패하는데 비해서, RPC는 실패되거나 하나보다 더 복제되거나 실행되고 네트워크의 에러결과로 나타난다. 이 문제를 어드레스하는 한가지 방법은 메시지가 단한번 작동하도록 하는 것을 하는 것이다. 대부분의 프로시저 콜들은 정확히 단한번만 작동하지만, 그것은 실행하기가 힘들다.

