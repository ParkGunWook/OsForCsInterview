# what we gonna study

챕터3에서 프로세스 모델은 한개의 스레드가 작동하는 프로그램이다. 가상적으로 모든 운영체제 시스템에서는 프로세스가 다중의 스레드를 작동하는 기능을 제공한다. 스레드의 사용을 통한 병렬처리 식별은 멀티 CPU를 제공하는 멀티코어 시스템에서 점점 중요해지고 있다. 

이 장에서는, 우리는 많은 개념을 소개하는데, Pthreads, Windows, Java Thread API의 토론을 멀티스레드 컴퓨터 시스템과 연관지어서 공부한다. 덧붙여서, 우리는 스레드 생성 추상화, 병렬처리를 지원하는 개발자 허용, 언어 기능과 API 프레임워크을 실행, 스레드 관리의 명세를 보이겠다. 우리는 멀티스레드 프로그래밍과 관련된 이슈와 그것이 운영체제에 미치는 영향을 공부한다. 마지막으로, 우리는 윈도우와 리눅스 운영체제가 커널레벨에서 지원하는 스레드 기능을 보겠다.

# Chapter Objectives

- 스레드의 기본 구성요소를 보고, 스레드와 프로세스의 차이를 알아본다.
- 멀티스레드 프로세스를 디자인하고 주요한 장점을 보겠다.
- 내재적인 스레드 풀, 포크-조인, Grand Central Disaptch을 포함한 내재적인 스레딩 접근을 설명하겠다.
- 윈도우와 리눅스 운영체제를 대표하는 스레드를 구현한다.
- Pthreads, Java, 윈도우 스레딩 API를 사용하는 멀티스레드를 디자인한다.

## 4.1 Overview

스레드는 CPU 효율성의 기초 단위이다. 그것은 스레드 ID, PC, 레지스터 셋과 스택으로 구성되어있다. 그것은 다른 스레드와 코드, 데이터, 운영체제 리소스(파일, 신호)를 공유한다. 전통적인 프로세스는 싱글 스레드 컨트롤이었다. 만약 프로세스가 다중 스레드라면, 그것은 같은 시간동안 한개보다 많은 일을 할 수 있다.

### 4.1.1 동기

대부분의 소프트웨어 앱들은 멀티스레드이다. 앱들은 여러개의 스레드를 가진 분리된 프로세스로 구현된다. 우리는 몇개의 멀티스레드 앱을 보겠다.

- 이미지 컬렉션으로부터 각각의 이미지로 섬네일을 만드는 것은 분리된 스레드를 사용할 수도 있다.

- 웹 브라우저는 이미지나 텍스트를 띄우는 다른 스레드는 동안 네트워크로부터 데이터를 순회하고 있다.

- 워드 프로세스는 그래픽을 띄우면서, 다른 스레드는 유저로부터 키입력을 반응하고, 3번째 스레드는 스펠링과 문법체크를 백그라운드에서 수행한다.

앱들은 멀티시스템에서 'leverage(영향력) processing capablilities'로 디자인된다. 이런 앱들은 멀티 컴퓨팅 코어에서 CPU 집중 태스크를 실행할 수 있다.

어떤 상황에서는, 단일 앱은 비슷한 태스크를 실행하는 것을 필요로 할 수 있다. 예를 들어서, 웹 서버는 웹페이지, 이미지, 사운드 등을 클라이언트 요청으로 수락할 수 있다. 바쁜 웹 서버는 병렬적으로 접근하는 클라이언트를 가질 수 있다. 만약 웹서버가 단일 스레드에서 작동하면, 그것은 오직 한명의 클라이언트만 가능할 것이고, 클라이언트는 서비스가 실행되도록 긴 시간을 기다려야 한다.

한가지 해결책은 한개의 프로세스로만 요청을 받아들이는 서버를 가지는 것이다. 서버가 요청을 받아들이면, 그것은 요청을 서비스하도록 분리된 프로세스를 생성한다. 실제로, 이런 프로세스 생성 메소드는 스레드가 유명해지기 전에 일반적인 방법이었다. 프로세스 생성은 시간을 많이 소요하고 리소스를 많이 먹는다. 만약 새로운 프로세스가 존재하는 프로세스와 같은 일을 하면 뭐하러 간접비를 또 지불하는가?? 한개의 프로세스가 다중 스레드를 가지는 것이 훨씬 효율적이다. 만약 웹-서버 플세스가 멀티 스레드이면, 서버는 클라이언트 요청을 들을 분리된 스레드를 만들면 된다. 요청이 만들어지면, 프로세스를 새로 만드는 것보다는, 서버가 새로운 스레드를 만들어서 요청을 처리하고 추가 요청을 듣는 것을 재시작한다.

대부분의 운영체제 커널들은 보통 멀티스레드이다. 예를 들어서, 리눅스의 시스템 부트동안에, 몇몇 커널 스레드는 생성된다. 각각의 스레드는 특정한 업무(디바이스 관리, 메모리 관리, 인터럽트 관리)를 실행한다. 커맨드 ps -ef는 리눅스에서 실행중인 커널스레드를 보인다. 이 커밴드의 결과물은 모든 커널 스레드의 부모를 제공하는 커널 스레드 *ktreadd*를 보여준다. 

많은 앱들은 다중 스레드의 장점을 가지는데, 소팅, 트리, 그래프 알고리즘이 포함되어있다. 덧붙여서, 데이터 마이닝, 그래픽스, AI 같은 현대의 CPU 집중 문제들을 해결해야하는 프로그래머들은 병렬적으로 수행하도록 멀티코어 시스템을 디자인 함으로서 기능을 올릴 수 있다.

### 4.1.2 장점

멀티 스레드 프로그래밍의 장점은 4가지로 나뉜다.

1. Responsiveness(반응성) : 상호작용하는 앱들을 멀티스레딩하는 것은 프로그램이 일부분이 막히거나, 긴 명령어를 실행해서 유저의 responsiveness를 증가시킬때에도 계속 실행하도록 허용한다. 퀄리티는 유저 인터페이스를 디자인할 때 특히 유용해진다. 예를 들어서, 유저가 시간을 많이 잡아먹는 명령어 실행 버튼을 클릭할때를 고려해보자. 싱클 스레드 앱들은 명령어가 완료될떄까지 반응을 하지 않을 것이다. 반면에, 만약 시간을 잡아먹는 명령어가 분리된, 비동기화된 스레드에서 작동하면, 앱은 유저에게 반응성을 유지한다.

2. Resource sharing : 프로세스는 공유 메모리와 메시지 패싱을 통해서 리소르를 공유한다. 그런 기술들은 프로그래머에 의해서 확실히 생성되어야한다. 그러나, 스레드들은 메모리를 공유하고 그들이 가진 프로세스의 리소스를 디폴트로 가진다. 코드와 데이터를 공유하는 장점은 앱들이 같은 주소영역안에서 활동의 여러가지 다른 스레드를 가지도록한다.

3. Economy : 프로세스 생성을 위한 메모리와 리소스 할당은 비용이 크다. 스레드들이 그들이 속한 리소스를 공유하기에, 스레드를 만들고 컨텍스트-스위치하는 것은 훨씬 경제적이다. 경험적으로 간접비를 검량하는 것은 힘들지만, 일반적으로 스레드 생성은 프로세스 생성보다 시간과 메모리를 덜 차지한다. 추가적으로, 컨텍스트 스위칭은 프로세스간보다는 스레드에서 훨씬 빠르다.

4. Scalability(확장성) : 멀티 스레딩의 장점은 스레드가 다른 프로세싱 코어에서 병렬적으로 작동하는 멀티 프로세서 아키텍처보다 훨씬 클수도 있다. 싱글 스레드 프로세스는 여러개가 있어도 오직 한개의 프로세서에서 작동한다. 우리는 다음 절에서 이것을 보겠다.

## 4.2 Multicore Programming

컴퓨터 디자인의 초기 역사에서, 더 좋은 컴퓨팅 성능을 위해서, 싱글 CPU 시스템은 멀티 CPU 시스템으로 진화했다. 후에, 시스템 디자인의 트렌드는 여러개의 코어를 가진 단독 칩으로 멀티 컴퓨팅 코어를 가지도록 되었다. 우리는 이런 시스템을 **multicore**라고 했고, 멀티 스레드 프로그래밍은 멀티 프로그래밍 컴퓨팅 코어와 향상된 병렬성을 더욱 효율적인 메커니즘에서 제공하도록 했다. 4개의 스레드를 가진 앱을 생각해보겠다. 단독 컴퓨팅 코어를 가진 시스템에서, 컨커런시는 스레드의 실행을 끼우는 것을 의미할 수도 있는데, 왜냐하면 프로세싱 코어는 오직 하나의 스레드를 한번에 작동하기에 적합하다. 멀티 코어 시스템을 가진 시스템에서는, 컨커런시는 여러개의 스레드가 병렬적으로 처리되는 것을 의미하는데, 왜냐하면 시스템은 각각의 코어에서 분산된 스레드이기 때문이다.

*concurrency*와 *parallelism*은 여거시 확실한 차이를 배우겠다. concurrent 시스템은 모든 태스크를 단계적으로 실행함으로서 한개보다 많은 태스크를 지원한다. 반대로, 병렬 시스템은 동시에 한개보다 많은 일을 실행하게 한다. 그러므로, parallelsm 없는 concurrency는 존재한다. 멀티 프로세서와 멀티코어 아키텍처의 급발전 전에는, 대부분의 컴퓨터는 오직 싱글 프로세서만 가졌기에, CPU 스케쥴러는 고속으로 프로세스간에 스위칭함으로서 parallelism의 환상을 제공했고, 각 프로세스가 단계적으로 실행하게 만들었다. 이런 프로세스들은 Concurrently이지 parallel은 아니다.

### 4.2.1 프로그래밍 챌린지

멀티코어 시스템의 트렌드는 시스템 디자이너와 앱 프로그래머들이 더욱 나은 멀티 컴퓨팅 코어를 더 좋게 사용하게끔 압박을 주었다. 운영체제의 디자이너들은 멀티 프로세싱 코어가 parallel 실행을 하게끔 스케쥴링 알고리즘을 썼다. 앱 프로그래머들은, 현존하는 프로그램을 새로운 프로그램이 멀티스레드하게 수정하는 챌린지를 받았다.

일반적으로 멀티코어 시스템에는 5가지 챌린지가 존재한다.

1. Identifying tasks : 이것은 분리된, concurrent한 태스크를 나누는 영역을 앱을 통해서 찾는 것이다. 이상적으로는, 태스크들은 다른 것과 독립적이므로 각각의 코어들은 병렬적으로 개인 코어를 가진다.

2. balance : 병렬적으로 실행할 태스크를 구분하는 동안, 프로그래머들은 같은 가치의 같은 일을 태스크가 수행하는 것을 확신해야한다. 몇가지 예시로, 어떤 일은 다른 태스크보다 전체의 프로세스에 큰 결과를 공헌하지 않을 수 있다. 분리된 코어 실행을 사용하는 태스크는 사실 코스트의 가치를 없는 것이다. 

3. Data splitting : 분리된 태스크로 앱들이 구별되있는 것처럼, 데이터 접근과 조작은 반드시 분리된 코어에서 쪼개져야한다.

4. Data dependency : 태스크에 데이터 접근은 두개 또는 더 많은 태스크는 반드시 의존성을 가져야한다. 하나의 태스크가 다른 데이터로 의존하면, 프로그래머들은 반드시 데이터 의존성을 가지는 동기화 태스크 실해을 해야만 한다. 이 전략은 6장에서 공부한다.

5. Testing and debugging : 프로그램이 병렬 코어에서 실행될때에, 많은 실행 경로가 가능하다. 이런 concurrent 프로그램의 테스팅과 디버깅은 싱글 스레드 앱보다 훨씬 힘들다.

이런 챌린지 때문에, 많은 소프트웨어 개발자들은 멀티코어 시스템의 급발전이 소프트웨어 미래에 새로운 접근을 만들어냈다고 주장한다.(비슷하게 많은 컴퓨터 공학 교육자들은 병렬 프로그래밍의 강조를 많이 해야하다고 한다.)

### 4.2.2 병렬의 종류

보통, 두가지의 병렬이 있다. 데이터 병렬과 태스크 병렬이다. **Data parallelism**은 다중 컴퓨팅 코어사이의 같은 데이터 분산과 각 코어의 같은 명령어 수행에 집중한다. 예를 들어서, N 사이즈의 행렬을 더하는 것을 생각하겠다. 한개의 스레드는 0~N-1까지를 간단하게 더하는 것이다. 그러나 듀얼 코어 시스템에서는 A가 0~N/2, B가 N/2+1~N-1까지를 더한다. 두개의 스레드는 분리된 컴퓨팅 코어에서 병렬적으로 수행된다.

태스크 병렬은 데이터 분산이 아니라 멀티 컴퓨팅 코어에서의 태스크 분산이다. 각 스레드는 고유한 명령어를 실행한다. 다른 스레드들은 같은 데이터에서 작동하거나, 그들은 다른 데이터에서 실행된다. 위의 예시를 다시하겠다. 그 상황과 다르게, 태스크 병렬은 두개의 예시는 각각은 행렬의 원소에 특별한 통계적인 명령어를 실행한다. 스레드는 분리된 코어에서 병렬적인 명령을하지만, 각각은 특별한 명령을 실행한다.

기초적으로, 데이터 병렬은 멀티 코어의 분산된 데이터를 포함하고, 태스크 병렬은 멀티 코어의 분산된 태스크를 포함한다. 그러나, 데이터와 태스크 병렬은 상호적으로 배제하지 않고, 앱들은 두 전략의 하이브리드를 가진다.

## 4.3 멀티스레딩 모델

우리의 논의는 일반적인 사오항의 스레드 관리이다. 그러나, 스레드 지원은 유저레벨에서 제공되고, 유저 스레드, 커널 스레드가 있다. 유저 스레드는 커널 위에서 지원하고 커널의 지원없이 관리된다. 반면에 커널 스레드는 운영체제에 의해서 직접 지원/관리된다. 가상적으로 모든 현대 운영체제는 커널 스레드를 지원한다.

최종적으로, 유저스레드와 커널스레드는 관계를 가진다. 이 절에서는, 우리는 이런 관계를 확립하는 3가지 방법을 보겠다. many-to-one model, one-to-one model, many-to-many model이다.

### 4.3.1 Many-to-One Model

이 모델은 많은 유저레벨 스레드를 하나의 커널 스레드에 맵핑한다. 스레드 관리는 유저 공간의 스레드 라이브러리에서 실행되는데, 효율적이다.(스레드 라이브러리는 4.4에서 알아본다.) 그러나, 전체 프로세스는 만약 스레드가 블럭킹 시스템 콜을 만들면 블락한다. 또한, 오직 한개의 스레드가 동시에 커널에 접근하기에, 다중 스레드들은 멀티코어 시스템에서 병렬적으로 수행불가능하다. **Green threads**는 솔라리스 시스템에 적용되고 자바의 초기 버전에 채택되어서, many-to-one 모델을 사용한다. 그러나 소수의 시스템이 이제는 대부분의 컴퓨터 시스템에서 사용되는 멀티 프로세싱 코어 장점을 못받아드려도 사용중이다.

### 4.3.2 One-to-One Model

이 모델은 각각의 유저 스레드를 커널 스레드에 연결한다. 그것은 다른 스레드가 스레드가 블럭킹 시스템콜을 만들때도 실행함으로서 many-to-one 모델보다 concurrency를 제공한다. 그것은 또한 멀티 프로세서에서 멀티 스레드가 작동하도록 허용한다. 이 모델의 유일한 단점은 유저 스레드를 만드는 것은 커널 스레드를 만드는 것을 필요로하고 많은 커널 스레드는 시스템에 큰 부담을 주게된다. 리눅스, 윈도우는 One-to-One 모델을 사용한다.

### 4.3.3. Many-to-Many Model

many-to-many 모델은 많은 유저레벨 스레드를 작거나 같은 수의 커널 스레드로 연결하는 것이다. 커널 스레드는 특정 앱이나 특정 기계에 따라서 달라진다.(앱은 4개의 코어보다 8개의 코어 시스템에서 더 많은 커널 스레드를 할당할 수 있다.)

concurrency의 디자인 효과를 고려해보자. many-to-one 모델이 개발자가 많은 유저 스레드를 원하는 만큼 만들도록 허용했지만, 그것은 parallelism을 얻어내지 못했는데 왜냐하면 커널이 오직 한개의 커널 스레드를 가졌기 때문이다. one-to-one 모델은 큰 concurrency를 가져왔지만, 개발자들은 앱에서 너무 많은 커널을 만들지 않도록 조심해야한다. many-to-many 모델은 이런 결점을 겪지는 않았다. 개발자는 많은 유저 스레드를 필요한만큼 생성하고 관련있는 커널 스레드는 멀티 프로세서에서 parallel하게 돌아갔다. 또한, 스레드가 blocking 시스템 콜을 실행해도, 커널은 다른 스레드를 실행을 위해서 스케쥴했다.

한가지 many-to-many의 버라이에이션은 많은 유저 레벨 스레드를 적거나 같은 수의 커널 스레드로 멀티플렉스하지만, 유저 스레드가 커널 스레드에 바인드되게 하는 것이다. 이것은 **two-level mode**이라고 한다.

비록 many-to-many 모델이 모델중에서 가장 유연하지만, 실전에서는 구현이 어렵다. 덧붙여서, 대부분의 시스템에서 프로세싱 코어가 늘어감에 따라서, 커널 스레드를 제한하는 것은 덜 중요해졌다. 결과적으로, 대부분의 운영체제느느 one-to-one 모델을 사용한다. 그러나 우리가 4.5절에서는, 몇가지 현대 concurrency 라이브러리는 개발자가 many-to-many 모델을 사용해서 매핑된 스레드에서 태스크를 구별하는 것을 가진다.

## 4.4 스레드 라이브러리

스레드 라이브러리는 프로그래머에게 스레드 관리와 생성을 위한 API를 제공한다. 두가지 방법의 주요한 스레드 라이브러리가 존재한다. 첫번째 방법은 커널의 도움없이 유저 스페이스 전체에서 제공하는 것이다. 모든 코드와 데이터 구조는 유저 공간에 존재한다. 이것은 유저 공간에서의 로컬 함수 호출을 통해서 함수를 호출하고 시스템 콜은 이용하지 않는 것이다.

두번째 방법은 커널 레벨 라이브러리에서 제공하는 방법이다. 이런 경우에는 라이브러리의 코드와 데이터 구조는 커널 공간에 존재한다. 이런 라이브러리 API는 커널의 시스템콜을 이용한다.

현재 쓰이는 3가지 주요한 스레드 라이브러리는 포식스 Pthread, 윈도우, 자바가 있다. 3가지 라이브러리는 모두 POSIX 표준의 확장이고, 유저/커널 레벨을 지원한다. 윈도우 스레드 라이브러리는 윈도우 시스템에 있는 커널 레벨의 라이브러리이다. 자바 스레드 API는 자바 프로그램에서 직접 관리하고 생성된다. 그러나, 대부분의 JVM 인스턴스는 호스트 운영체제의 위에서 작동되므로, 자바 스레드 API는 운영체제에 있는 스레드라이브러리를 보통 이용한다. 이것은 윈도우 시스템에서, 자바 스레드는 윈도우 API를 이용한다는 것이다. 유닉스, 리눅스, macOS는 보통 Pthreads를 이용한다.

포식스와 윈도우 스레딩은 데이터가 전역으로 선언되는데, 즉, 함수의 바깥에서 선언되고 같은 프로세스내에서 모든 스레드가 공유된다는 것이다. 자바는 전역 데이터에 대한 개념이 없기 때문에 스레드사이에 공유 데이터 접근이 반드시 정렬되어야한다.

이 절의 나머지 부분에서, 우리는 3가지 스레드 라이브러리를 이용한 스레드 생성을 설명하겠다. 표현된 예시는, 우리는 양수 정수를 분리된 스레드에서 모두 더하는 것이다. 예를 들어서, 5까지의 숫자를 더하면 1~5의 숫자를 더하고 답은 15일 것이다. 각각의 3개의 프로그램은 커맨드 라인에 입력된 수까지의 합을 ㅍ현한다. 

예시를 시작하기전에, 우리는 두가지 전형적인 전략을 보이겠다. **asynchronous threading**과 **synchronous threading**이다. 비동기화 스레딩은, 한번 부모가 자식 스레드를 만들면, 부모는 그것의 실행을 재시작하고, 부모와 자식은 같이 동작하고 각자가 독립적으로 작동한다. 스레드들은 독립적이기 때문에, 그들 사이에 공유하는 데이터는 보통 적다. 비동기화 스레딩은 멀티 스레드 서버에서 쓰인다. 그리고 반응형 유저 인터페이스에서 주로 쓰인다.

동기화 스레딩은 부모 스레드가 1개 또는 그 이상의 자식을 만들면, 그들은 반드시 자식의 종료후에 시작한다. 여기서, 부모에 의해서 생성된 스레드는 동시에 작동하는데, 부모는 이 일들이 끝나기 전까지 일을 실행할 수 없다. 한번 스레드가 그들의 일을 종료하면, 그것은 종료되고 그것의 부모에 참여한다. 모든 자식이 참여한 후에야 부모는 일을 다시 시작한다. 일반적으로, 동기화 스레딩은 스레드 사이에 큰 데이터 공유를 포함한다. 예를 들어서, 부모 스레드가 다양한 자식들이 계산한 결과를 합치는 것이다. 뒤에 나오는 모든 예시는 동기화 스레딩이다.

### 4.4.1 Pthread

Pthreads는 POSIX 표준에서 정의하는 스레드 생성과 동기화를 의미한다. 이것은 스레드 행동에 특화되있지, 구현에는 아니다. 운영체제 디자이너는 그들이 원하는 되로 특화할수있다. 많은 시스템들이 Pthread specification으로 구현한다. 대부분은 유닉스 타입 시스템이다. 비록 윈도우가 Pthreads를 지원하지 않지만, 몇몇 서드파티 구현이 존재하긴한다.

예시 코드는 분리된 스레드에서 양수합을 계산하는 멀티 스레드 프로그램이다. Pthreads 프로그램에서, 분리된 스레드들은 정의된 함수를 실행한다. runner 함수가 즉 스레드이다. 프로그램이 시작되면 싱글 스레드가 메인문을 시작한다. 몇가지 초기화 후에, 메인문은 2번째 스레드인 러너 함수를 시작한다. 두가지 스레드는 전역 데이터 sum을 공유할 것이다.

프로그램을 자세히 살펴보겠다. 모든 Pthreads 프로그램은 반드시 pthread.h를 include해야 한다. pthread_t tid는 스레드의 식별자로서 선언한다. 각각의 스레드는 그것의 특성 정보를 가지고 있고, 스택사이즈와 스케쥴링 정보일 것이다. pthread_attr_t attr이 스레드의 특성을 표현한다. 우리는 함수콜 pthread_attr_init(&attr)로 특성을 세팅한다. 우리가 어떠한 특성도 explicitly 정의하지 앟ㄴ았기 때문에, 우리는 디폴트 특성을 사용한다. 분리된 스레드는 pthread_create() 함수콜로 생성된다. 추가적으로 스레드를 위해서 스레드 식별자와 특성을 전달하기 위해서, 우리는 새로운 스레드가 시작하는 곳에서 함수의 이름을 전달한다.(여기서는 runner() 함수이다.) 마지막으로 우리는 정수 파라미터 argv[1]을 전한다.

여기서, 프로그램은 두개의 스레드를 가진다. 첫번째(부모) 스레드는 메인에 있고 합하는 스레드 runner() 스레드이다. 프로그램은 스레드 create/join 전략을 따르고, 합하는 스레드 생성후에 부모 스레드는 pthread_join() 함수가 끝날때까지 대기한다. 합하는 스레드가 종료하면 우리는 pthread_exit()를 부른다. 한번 합하는 스레드가 리턴되면 부모 스레드는 sum을 아웃풋으로 출력한다.

이 예제는 오직 한개의 스레드를 만들었다. 증가하는 멀티코어 시스템에 따라서, 프로그램은 여러가지 스레드를 사용하는 것이 일반적으로 되고있다. 루프문을 통해서 여러개의 스레드를 만드는 것고 가능하다.

### 4.4.2 윈도우 스레드

윈도우 스레드 라이브러리로 스레드를 만드는 방식은 Pthread와 비슷하다. 우리는 반드시 윈도우 API 이용을 위해서 windows.h 헤더를 추가해야는 것을 생각하자.

Phtread와 비슷하게 데이터는 전역으로 선언된 스레드를 통해서 공유된다.(DWORD 데이터는 32비트 정수이다.) 우리는 Summation() 함수를 분리된 스레드로 작동한다. 이 함수는 보이트 포인터를 넘겨주고, LPVOID로 정의된다. 스레드는 0부터 전해진 파라미터로 합을 실행한다.

스레드는 윈도우 API에서 생성되었고 CreateThread() 함수를 이요한다. 그리고 이 함수에서 스레드로 특성을 보낸다. 이런 특성은 보안 정보, 스택 사이즈, 스레드가 정지된 상태에서 시작했는지 확인하는 플래그이다. 한번 서메이션 스레드가 생성되면 부모는 Sum의 결과가 나오기까지 기다린다. Pthread 프로그램처럼 pthread_join()을 이용해서 부모 스레드가 기다렸다. 우리는 윈도우 API에서 비슷하게 WaitForSingleObject() 함수를 사용한다. 이것은 스레드가 서메이션 스레드가 끝날때까지 기다리게한다.

다양한 스레드가 종료되길 기다리는 상황에서, WaitForMultipleObjects() 함수는 사용된다. 함수는 4가지 파라미터를 전달한다.

1. 기다리는 오브젝트 수
2. 오브젝트의 포인터 행렬
3. 모든 오브젝트가 신호보냈는지 확인하는 플래그
4. 타임아웃 시간(무한도 가능)

예를 들어서, THandles는 스레드 Handle 오브젝트의 사이즈 N이다. 부모 스레드는 자식이 끝날때까지 기다리는 것을 다음과 같이 정의 가능하다.

`WaitForMultipleObjects(N, THandles, TRUE, INFINITE);`

### 4.4.3 JAVA 스레드

스레드들은 자바프로그램에서 프로그램 실행의 기초 모델이다. 자바와 그것의 API는 스레드의 관리와 생성에 대해서 풍부한 기능을 제공한다. 모든 자바 프로그램들은 스레드 하나하나의 통제로 이루어져있고 심지어 JVM에서의 메인도 하나의 스레드이다. 자바 스레드들은 윈도우, 리눅스 macOS를 포함하는 JVM에서 어떤 시스템에서도 실행된다. 자바 스레드 API는 안드로이드 앱에서도 가능하다.

자바 프로그램에서 스레드를 만드는 두가지 기술이 있다. 한가지는 Thread 클래스로부터 새로운 클래스를 만들고 그것의 run() 메서드를 오버라이드하는 것이다. 다른 방법은 Runnable 인터페이스를 정의하는 것이다. 이 인터페이스는 한가지 추상 메서드를 public void run()으로 정의하는 것이다. run() 메서드의 코드는 Runnalble을 구현했고 분리된 스레드로 작동한다. 예시는 다음과 같다.

```java
class Task implements Runnable
{
    public void run() {
        System.out.println("I am a thread.");
    }
}
```

자바에서의 스레드 생성은 스레드 오브젝트 만드는 것과 그것을 Runnable을 구현하는 클래스의 인스턴스에게 넘기는 것을 포함하는데, start() 메소드를 실행하는 것부터 시작한다. 다음과 같다.
```java
Thread worker = new Thread(new Task());
worker.start();
```

새로운 스레드 오브젝트를 위해서 start() 메소드 호출은 2가지 일을 한다.

1. 그것은 JVM에 새로운 스레드를 초기화하고 메모리를 할당한다.
2. run() 메서드를 호출하고, JVM에 의해서 돌아가는 스레드를 만든다.(우리는 run() 메서드를 직접 부르지 않는다. 대신에, 우리는 start() 메서드를 부르고 그것이 run() 메서드를 실행한다.)

Pthreads와 윈도우 라이브러에서의 부모 스레드는 pthread_join()과 waitForSingleObject()를 스레드가 서메이션을 끝날때까지 기다리게한다. join() 메서드가 자바에서는 비슷하게 제공된다.(join(0)은 InterruptedException을 throw하고 우리는 무시하도록 선택가능하다.)

```java
try {
    worker.join();
}
catch(InterruptedExcption ie) { }
```

만약 부모가 반드시 스레드의 종료까지 기다려야하면 우리는 for 루프를 비슷하게 이용할 수 있다.

### 4.4.3 자바 Excutor Framework

자바는 스레드를 우리가 앞서 말한것으로 구현가능했다. 그러나 1.5버전과 API가 소개되면서 새로운 방법이 우리에게 주어졌다. 이러한 툴은 java.util.concurrent 패키지에 존재한다.

스레드 오브젝트를 만드는 것보다는, 스레드 생성은 대신에 Executor 인터페이스를 만든다.

```java
public interface Excutor
{
    void execute(Runnable command);
}
```

이 인터페이스를 구현하는 클래스는 반드시 execute(0)를 정의하고 Runnable 오브젝트에 의해서 건내져야한다. 자바 개발자에게, 이것은 Executor을 사용하는 것보다는 분리된 스레드를 만드는 것이고 start() 메서드를 호출한다. Executor은 다음과 같다.

```java
Executor service = new Executor;
service.execute(new Task());
```
Executor 프레임워크는 생산자-소비자 모델을 기초로 한다. Runnable 인터페이스를 구현한 태스크는 생산되고 이런 태스크를 소비하는 스레드를 가진다. 이 접근의 장점은 스레드 생성을 실행과 나눌뿐만이 아니라 현재 실행중인 태스크간의 통신 메커니즘을 제공한다.

스레드간의 데이터 공유는 윈도우와 Pthreads 사이에서 쉽게 가지는데, 공유 데이터가 전역으로 선언되기 때문이다. 순수한 OOL에서는, 자바는 전역이라는 정의가 없다. 우리는 Runnable을 통해서 파라미터를 전할수 있다. 그러나 자바 스레드는 결과를 리턴할 수 없다. 이런 필요를 충족하기 위해서 java.util.concurrent 패키지는 Callable 인터페이스를 추가로 정의해서 Runnable이 결과를 리턴하는 것을 돕는다. 예시코드는 이 기능을 이용한다.

서메이션 클래스는 Callable 인터페이스를 구현한다. 그것은 call() 메서드이고 여기서 분리된 스레드에서 실행되는 call() 메서드이다. 이 코드를 실행할려면, 우리는 newSingleThreadExecutor 오브젝트를 만들고, ExecutorService의 종류이고 submit 메서드를 사용하는 callable 메서드이다.(execute와 submit의 큰 차이는 결과를 리턴하지않는다와 한다이다.) 한번 우리가 callable 태스크를 스레드에 제출하면, 우리는 그것의 get() 메서드를 불러서 Future 오브젝트가 리턴되는 것을 기다린다.

단순하게 스레드를 만들고 그것의 종료를 조인하는 것보다 어려워 보일수도 있다. 그러나 이 방법을 하는 것은 문제의 단계에 이득을 준다. 우리가 보았듯이, Callable과 Future은 스레드가 결과를 리턴하는 것을 허용한다.

추가적으로, 이런 접근은 그들이 만드는 결과와 스레드의 생성을 분할한다. 결과가 나오기까지 스레드를 기다리는 것보다는, 부모가 대신에 결과물이 생길떄까지 기다리는 것이다. 마지막으로, 4.5.1절에서, 이 프레임워크는 많은 수의 스레드 관리를 위한 단단한 기능을 제공한다.

## 4.5 Implicit Threading

멀티 스레딩의 성장과 함꼐, 앱들은 수백, 수천개의 스레드를 포함한다. 이런 앱들을 디자인하는 것은 사소한 일이 아니다. 프로그래머들은 반드시 4.2의 강조 사항만 지시할뿐 아니라 추가적인 어려운 일들이 있다. 이런 어려움은 프로그램 정확성과 관련있고 6장과 8장에서 다룬다.

이런 일들을 해결하는 한가지 방법과 나은 해결책은 concurrent와 parallel 앱들의 디자인이 컴파일러와 런타임 라이브러리를 통해서 생성학 관리하는 것이다. 이 전략은, **Implicit threading**이라고 하고, 점점 인기있는 추세를 가진다. 이 절에서, 우리는 Implicit threading을 멀티코어 프로세서에서 가지는 장점을 4가지 방안으로 소개하겠다. 우리가 보게될, 이런 전략은 보통 앱 개발자들이 스레드가 아니라 병렬 처리되는 *task*를 구별하는 것이 필요하다. 태스크는 보통 함수로 쓰이고, 런타임 라이브러리가 분리된 스레드에 매핑하고, 일반적으로 many-to-many 모델을 사용한다. 이 접근의 장점은 개발자는 오직 병렬 태스크만 구별하고 라이브러리가 스레드의 생성과 관리에 대한 명세를 결정한다.

### 4.5.1 스레드 풀

4.1절에서, 우리는 멀티스레드 웹서버를 설명했다. 이 상황에서, 서버가 요청을 받을때마다, 그것은 서비스의 요청으로 분리된 스레드를 생성한다. 반면에 분리된 스레드 생성은 전적으로 프로세스 만들기보다 낫더라도, 멀티스레드 서버는 잠재적 문제를 가진다. 첫번째 이슈는 스레드를 만들기 위한 시간이 필요한 것이다. 스레드가 그것의 일을 마무리하면 버려진다는 사실이 있다. 두번째 이슈는 더욱 문제이다. 만약 우리가 새로운 스레드에 concurrent 리퀘스트를 허용하면, 우리는 시스템에서 스레드 수의 제한을 두지 않는다. 무제한 스레드는 시스템 리소스(CPU 시간, 메모리)를 모두 소진한다. 이 것을 해결하는 방법은 **Thread Pool**이다.

스레드 풀의 아이디어는 시작할 때에 스레드를 미리 만들어두고 그들이 안착되고 일을 기다리는 풀안에 그들을 넣어두는 것이다. 서버가 요청을 받으면, 스레드를 만들기보다는, 스레드풀에 요청을 보내고 추가적인 리퀘스트까지 기다린다. 만약 풀안에 스레드가 있으면, 그것은 깨어나고, 요청은 즉각적으로 서비스된다. 만약 풀에 스레드가 없으면, 그것은 풀을 리턴하고 더 많은 일을 기다린다. 스레드 풀은 풀에 보내는 태스크가 비동기적으로 실행될때 잘 작동된다. 다음과 같은 이점을 제공한다.

1. 존재하는 스레드를 서비스하는 것이 스레드를 만드는 것보다 낫다.
2. 스레드 풀은 한 지점에 존재하는 스레드의 수를 제한한다. 이것은 많은 수의 concurrent 스레드를 사용하는 시스템에서 매우 중요하다.
3. 태스크를 만드는 메카닉으로부터 태스크를 분리하는 것은 태스크 동작에 다른 전략을 사용하는 것을 허용한다. 예를 들어서, 태스크는 타임 딜레이 또는 주기적으로 실행되게 스케쥴한다.

풀안의 스레드는 시스템안의 CPU 수, 물리 메모리, 동시 존재하는 클라이언트 수에 기반해서 경험적으로 세팅한다. 더욱 정교한 스레드 풀 구조는 사용 패턴에 따라서 풀안의 스레드를 조정할 수 있다. 이런 구조는 더 작은 풀을 가지는 것을 제공하고 더 적은 메모리를 소비한다. 우리는 이런 구조를 Apple's Grand Central Dispatch로 설명하겠다.

윈도우 API는 스레드 풀과 관련된 몇가지 기능을 제공한다. 스레드 풀 API는 Thread_Create() 함수와 비슷하다. 여기서 우리는 몇가지 분리된 스레드를 정의한다. 여기서, 분리된 스레드가 정의된다. 이런 함수는 다음과 같이 나타난다.
```c
DWORD WINAPI PoolFunction(PVOID Param){
    /* this function runs as a seperate thread*/
}
```

PoolFunction()의 포인터는 스레드 풀 API의 한개의 함수로 전달되고, 풀에서의 스레드는 이 함수를 실행한다. 스레드 풀의 한 멤버 API는 QueueUserWorkItem() 함수이고 3가지 파라미터를 전해준다.
- LPTHREAD_START_ROUTINE Function - 분리된 스레드를 실행하는 함수 포인터를 의미한다.
- PVOID Param - 함수에 주어지는 파라미터이다.
- ULONG Flags - 스레드 풀이 생기고 스레드의 실행을 관리하는 플래그이다.

함수를 실행하는 것은 다음과 같다.
`QueueUserWorkItem(&PoolFunction, NULL, 0);`
이 문장은 스레드 풀로부터 PoolFunction() 스레드를 실행하게 한다. 이 예시에서, 우리는 PoolFunction()에 아무런 파라미터를 건네지 않았다. 우리가 flag를 0으로 설정했기에 우리는 스레드 풀을 스레드 생성없이 제공한다. 

#### 4.5.1.1 자바 스레드 풀

java.util.concurrent package는 스레드 풀 구조를 위한 다양한 구조를 제공한다. 여기서 우리는 3가지 모델에 집중하겠다.

1. 싱글 스레드 실행자 - newSingleThreadExecutor() 사이즈 1의 풀을 생성한다.
2. 고정 스레드 실행자 - newFixedThreadPool(int size) 지정한 숫자의 스레드를 가진 스레드 풀을 생성한다.
3. 캐시드 스레드 실행자 - newCachedThreadPool() 제한 없는 스레드 풀을 생성하고, 많은 인스턴스에서 스레드를 재사용한다.

우리는 이미 4.4.3절에서 스레드 풀을 사용해보았다. 그 절에서 우리는 Java Executor framework가 단단한 스레딩 풀을 건설하는데 쓰인다고 노트했다. 우리는 스레드 풀을 생성하기 위해서 어떻게 쓰이는지 설명한다.

스레드 풀은 Executors 클래스로 팩토리 메소드를 만들겠다.

- static ExecutorService newSingleTHreadExecutor()
- static ExecutorService newFixedThreadPool(int size)
- static ExecutorService newCachedThreadPool()

각각의 팩토리 메소드는 ExecutorService 인터페이스로 구현하는 객체 인스턴스를 생성하고 리턴한다. ExecutorService 는 Executor 인터페이스로 확장되고, execute() 메서드를 실행하게 허용한다. 추가로, ExecutorService는 스레드 풀의 관리 메서드를 제공한다.

예시는 캐시드 스레드 풀을 만들고 execute() 메서드로 실행한다. shutdown() 메서드가 실행되면 모든 존재하는 태스크가 종료를 완료한다.

### 4.5.2 Fork Join

4.4 절에서는 스레드 생성을 위한 전략을 보았고 **fork-join** 모델이라고 알려져있다. 이 메서드를 상기하면, 메인 부모 스레드는 하나 또는 여러 자식 스레드를 만들고(forks) 자식의 종료를 join으로 기다리고 그들의 결과를 합치고 추적했다. 이 동기화 모델은 보통 explicit 스레드 생성으로 특징 지어진다. 그러나 implicit 스레딩도 잘 쓰일 수 있다. 후자의 상황은 스레드들은 fork stage에서 직접적으로 생성되지 않는다. 오히려, 병렬 태스크가 지정된다. 라이브러리는 만들어진 스레드를 관리하고 스레드에게 태스크를 할당한다. 몇가지 방법으로, 이 fork-join 모델은 스레드 풀의 동기화 버전이고 라이브러리가 스레드의 수를 직접 결정한다.

#### 4.5.2.1 Fork Join in Java

자바는 fork-join 라이브러리를 1.7버전을 가지고 퀵소트와 머지소트 같은 재귀 분할 정복 알고리즘을 디자인하기 위해서 가지게 되었다. 이 라이브러리가 가지는 분할 정복 알고리즘을 실행할때, 분할된 태스크들은 분할 단계에서 포크되고 원래 문제의 작은 서브셋들이 할당된다. 알고리즘들은 이런 분리된 태스크들이 동시에 실행되게끔 디자인 되어야만 한다. 몇가지 관점에서, 태스크에 할당되는 문제의 크기가 직접 풀수 있을 정도로 간단해지면 더이상 태스크를 만들지 않고 직접 문제를 해결한다. 자바의 fork-join 모델 일반 재귀 알고리즘은 다음과 같다.
```java
Task(problem)
    if problem is small enough
        solve the problem directly
    else
        subtask1 = fork(new Task(subset of problem))
        subtask2 = fork(new Task(subset of problem))

        result1 = join(subtask1)
        result2 = join(subtask2)

        return combined results
```

우리는 자바의 fork-join 전략을 인티저들을 모두 합하는 분할 정복 알고리즘으로 디자인한다. 자바 API 1.7버전에서 새로운 스레드 풀이 소개되었다. 태스크를 할당하는 ForkJoinPool은 추상 베이스 클래스 ForkJoinTask(우리는 여기서 SumTask Class라고 하겠다.)를 가진다. ForkJoinPool 객체를 만들고 첫번째 태스크를 그것의 invoke() 메서드로 실행한다.
```java
ForkJoinPool pool = new ForkJoinPool();
//array contains the integer to be summed
int[] array = new int[SIZE];

SumTask task = new SumTask(0, SIZE -1, array);
int sum = pool.invoke(task);
```

완료 후에, invoke()는 어레이의 합을 리턴한다.
클래스 SumTask는 Fork-join을 통해서 분할 정복 알고리즘을 구현한다. 메소드 compute()는 서브셋의 합을 직접적으로 계산할떄까지 할당한다. join()은 태스크가 완료될떄, 즉 join이 compute()를 결과를 리턴할때까지 블럭한다.

SumTask는 RecursiveTask를 확장한다. 자바 fork-join 전략은 ForkJoinTask라는 추상 기본 클래스로 구성되고 RecursiveTask와 RecursiveActioin 클래스는 이 클래스를 확장한다. 두 클래스간의 기본적인 차이는 RecursiveTask는 결과를 리턴하고 RecursiveAction은 결과를 리턴하지 않는다.

충분히 적은 시점이 언제인지를 결정하는 것은 중요한 이슈이다. SumTask에서 이것은 THRESHOLD 값으로 결정되고 우리는 임의로 1000으로 지정했다. 여기서, 언제 문제가 해결될지는 조심스로운 타이밍 시도로 결정되고, 값은 구현에따라 다양하다.

자바 fork-join 모델에서 흥미로운 점은 라이브러리가 워커 스레드의 풀을 짓고 태스크의 로드안에서 하는 태스크의 관리이다. 몇가지 상황에서, 수천개의 태스크가 생기고, 일을 수행하는 스레드는 아직 충분하다. 추가적으로 ForkJoinPool의 각 스레드는 포크된 태스크의 큐를 유지하고 만약 큐가 비게된다면, 그것은 다른 스레드의 큐 태스크를 work stealing 알고리즘으로 훔쳐온다. 그러므로 모든 스레드 간의 일 부담은 밸런스가 맞게된다.

### 4.5.3 OpenMP

OpenMP는 공유메모리 환경을 통해서 병렬 프로그래밍을 지원하는 C, C++, FORTRAN으로 쓰인 프로그램을 위한 API와 같은 컴파일러 관리자집합이다. OpenMP는 병렬로 동작하는 코드의 병렬 구역을 식별한다. 앱 개발자들은 병렬 구역에 컴파일러 관리자(Compiler directives)이고 이 관리자들은 해당구역을 병렬로 실행하는 런타임 라이브러리이다. 다음 코드는 printf() 구문을 포함하는 병렬 구역위에서 컴파일러 관리자를 지시한다.
```c
#include <omp.h>
#include <stdio.h>

int main(int argc, char *argv[])
{
    /*sequential comde */
    
    #pragma omp parallel
    {
        printf("I am a parallel region.");
    }

    /*sequential code */
    return 0;
}
```

OPENMP가 directive `#pragma omp parallel`을 만나면 그것은 시스템의 프로세싱 코어만큼의 스레드를 생성한다. 그러므로, 듀얼 코어 시스템에서는, 2개의 스레드가 생성된다. 모든 스레드들은 동시에 공유 영역을 실행한다. 각 스레드가 공유 영역을 나가면, 그것은 종료된다.

OpenMP는 병렬 코드 영역을 실행하기 위해서 몇가지 추가적인 directives를 제공한다(병렬 루프 포함). 예를 들어서 우리가 2개의 어레이 a와 b를 가진다고 생각하자. 우리는 그들의 콘텐츠를 더하고 결과를 어레이 c에 넣고 싶다. 우리는 이런 태스크를 다음과 같은 코드 부분을 따르고, for 루프를 컴파일러 관리자가 포함한다.
```c
#pragma omp parallel for
for(i = 0;i < n ; i++){
    c[i] = a[i] + b[i];
}
```
OpenMP는 `#pragma omp parallel for`를 통해서 for 루프 사이의 스레드를 포함한 일을 실행한다.

병렬화를 위한 명령 제공외에도, OpenMP는 개발자가 몇가지 단계의 병렬을 선택하게 제공한다. 예를 들어서, 그들은 스레드의 수를 수동으로 선택 가능하다. 또한 개발자가 데이터가 스레드사이에 공유될지 아닐지 선택이 가능하다. OpenMP는 몇가지 오픈 소스와 리눅스 상업용 컴파일러 버전이 존재한다. 우리는 챕터 마지막에 있는 OpenMP에 관한 것을 읽기를 추천한다.

### 4.5.4 Grand Central Dispatch

GCD는 맥을 위해서 만들어진 기술이다. 그것은 개발자가 병렬로 작동하는 코드를 구별하는 런타임 라이브러리와 API와 언어 확장의 조합이다. OpenMP처럼 GCD는 대부분의 스레딩 명세를 관리한다. GCD는 *dispatch queue*에 올림으로서 런타임 실행중인 태스크를 스케쥴한다. 태스크가 큐에서 사라지면, 그것은 태스크에 풀에서 가용한 스레드를 할당한다. GCD는 두가지의 dispatch queues가 있다.(직렬 병렬) 

태스크는 FIFO 순서로 직렬 큐에 배치된다. 한번 태스크가 큐에서 사라지면, 그것은 반드시 다른 태스크가 제거되기전에 실행을 완료해야한다. 각각의 프로세스는 그것의 serial queue(**main queue**)를 가지고 개발자는 로컬에 있는 특정 프로세스에 추가적인 시리얼 큐를 생성할 수 있다.(이게 시리얼 큐가 *private dispatch queus*라고 불리는 이유이다.) 시리얼 큐는 몇가지 태스크를 직렬로 실행하기에 도움이 된다.

병렬 큐에서 태스크는 또한 FIFO 순서로 제거된다. 그러나 몇가지 태스크는 한번에 제거되고, 그러므로 다중 태스크를 병렬로 실행한다. 4가지의 클래스로 나누어진 몇가지 시스템 와이트 병렬 큐가 존재한다.

- QOS_CLASS_USER_INTERATIVE : **user-interactive** 클래스는 유저와 상호작용하는 클래스를 대표하고, 이런 유저 인터페이스, 이벤트 핸들링,  반응형 유저 인터페이스 같은 것이 있다. 이 클래스에 포함된 태스크를 완료하는 것은 반드시 작은 일을 필요로한다.

- QOS_CLASS_USER_INITIATED : **user-initiated** 클래스는 반응형 유저 인터페이스와 관련된 유저 소통형 클래스이다. 그러나 유저 이니시에이트 태스크는 더욱 긴 프로세싱 타임을 가진다. 파일이나 URL을 여는 것이 user-initialted task이다. 이 클래스에 포함된 태스크는 시스템과 상호작용하는 것을 지속하기 위해서 유저를 위해서 완료해야한다. 그러나 그들은 유저-상호 큐에서 빠르게 서비스될 필요는 없다.

- QOS_CLASS_UTILITY - **utility** 클래스는 더 더욱 긴 시간을 요구하지만 즉각적인 결과를 요규하지 않는다. 이 클래스는 데이터 임포팅과 같은 일을 포함한다.

- QOS_CLASS_BACKGROUN - **backgroun** 클래스는 유저에게 보이지 않고 시간에 예민하지 않다. 예시는 메일박스 시스템과 백업 실행이 있다.

디스패치 큐에 제출된 태스크들은 2가지 방법으로 실행된다.

1. C, C++, 오브젝트-c 언어를 위해서, GCD는 *블럭*으로 알려진 언어 확장을 식별한다. 간단한 단위 일을 실행한다. 블럭은 {braces}와 ^을 적당히 넣어서 실행한다. {}안의 코드는 단위 일을 식별한다. 

` ^{printf("I am a block"); }`

2. 스위프트 언어를 위해서, 태스크는 *closure*를 사용해서 구별되고 함수의 유닛과 비슷하게 표현된다. 종합적으로 스위프트 클러조는 블럭과 같은 방식으로 쓰인다. 대신에 ^(caret)을 뺸다.
다음 코드는 user-initiated 클래스로 병렬 큐를 가지고 dispatch_async() 함수를 통해서 태스크를 큐에 제출한다.
```swift
let queue = dispatch_get_global_queue
    (QOS_CLASS_USER_INITIATED, 0)

dispatch_async(queue, {print("I am a closure")})
```

내부적으로, GCD의 스레드 풀은 포식스 스레드로 만들어졌다. GCD는 풀을 활동적으로 관리하고, 스레드의 수가 자라거나 줄어들면 시스템 커패시티와 앱 디맨드에 따라서 조절하는 것을 허용한다. GCD는 libdispatch 라이브러리로 구현되고, 아파치 커먼 라이센스 아래에서 애플이 발매한 것이다. 그것은 FreeBSD 운영체제로 포트되었다.

### 4.5.5. Intel Thread Building Blocks

인텔 스레딩 블럭(TBB)는 C++에서 병렬 애플리케이션 디자인을 지원하는 템플릿 라이브러리이다. 이것이 라이브러리인만큼, 이것은 특별한 컴파일러 또는 언어 도움이 필요하지 않다. 개발자는 병렬로 작동할 태스크를 명세하고, TBB 태스크 스케쥴러는 이러한 태스크 밑에있는 스레드에 매핑한다. 더욱이, 태스크 스케쥴러는 부하 밸런싱과 캐시 경고(데이터가 캐시메모리에 저장되어있기에 태스크를 우선적으로 실행하고 빠르게 실행가능하다.)를 제공한다. TBB는 다양한 기능을 제공하는데, 병렬 루프 구조, atomic 명령어, mutual exclusion locking을 포함한다. 덧붙여서, 해시맵, 큐, 벡터같은 C++ STL 데이터 구조와 같이 스레드에 안전한 스레드 병렬용으로 제공한다.

루프를 예시로 시작해보겠다. 처음으로, apply(float value)라는 함수가 있다고 생각하자 이것은 파라미터 value를 가진다. 만약 n사이즈의 float 값을 가진 array v가 있다고 생각하면, 우리는 다음과 같은 시리얼 루프를 apply() function에  사용가능하다.
```c++
for(int i=0; i<n;i++){
    apply(v[i]);
}
```

개발자는 수종적으로 데이터 병렬성을 멀티코어 시스템에서 구현이 가능하다. array v의 다른 구역을 프로세싱 코어에 할당해주는 것이다. 그러나 이것은 물리적인 하드웨어에 가깝게 병렬성을 구현하는 기술에 불과하다. 알고리즘은 프로세싱 코어와 특정한 아키텍처에 따라서 수정되고 다시 컴파일되어야만 한다.

대신에, 개발자는 TBB를 사용할 수 있고, TBB는 parallel_for 템플릿을 제공한다. 
`parallel_for(range, body)`
range는 이터레이트될 원소의 범위이고 body는 각 원소의 서브레인지에 적용될 명령이다.

이제 우리는 for 루프를 다음과 같이 TBB parallel_for을 이용해서 쓸수 있어진다.
`parallel_for( size_t(0), n, [=](size_t i) { apply(v[i]);})`
첫번째 두 파라미터는 이터레이션 공간을 0부터 n-1로 특정할 수 있다.(array v의 범위와 같다.) 두번째 파라미터는 C++ 람다 함수이다. [=](size_t i)는 파라미터 i이고, 반복자 공간을 가정한다. 각 i 값은 v[i]로 전달이 되는 것이다.

TBB 라이브러리는 루프 반복자를 분리된 "chunks"로 나눌 것이고 이런 청크를 수행할 많은 태스크를 생성한다.(물론 parallel_for 함수는 원한다면 청크의 크기도 조절이 가능하다.) TBB는 스레드를 생성하고 가용한 스레드에 태스크를 할당한다. 이것은 자바의 fork-join 라이브러리와 비슷하다. 이 접근의 장점은 오직 개발자가 어떤 명령어가 병렬적으로 작동할지만 구별해주는 것이고, 라이브러리는 병렬적으로 수행할 분리된 태스크를 나누고 명세를 관리해줄 것이다. 인텔 TBB는 상업적이고 오픈소스 버전이 있고 윈도우, 리눅스, 맥에서 작동이 가능하다. TBB 사용을 위한 bibliography를 확인 하기를 바란다.

## 4.6 스레딩 이슈

이 절에서는, 우리는 스레드 프로그램 디자인에 대한 몇가지 이슈를 토론하겠다.

### 4.6.1 fork()와 exec() 시스템 콜

3장에서, 우리는 fork() 시스템 콜이 어떻게 작동하고 프로세스를 복제하는지 설명했다. fork()와 exec() 시스템 콜의 의미가 멀티 스레드 프로그램에서 변한다.

만약 프로그램 안의 하나의 스레드가 fork()를 부르면, 새로운 프로세스가 모든 스레드를 복제하는지, 새로운 싱글 스레드 프로세스 인가? 몇몇 유닉스 시스템은 fork()의 두가지 버전을 골랐고, 하나는 모든 스레드를 복제하고 다른 것은 오직 fork() 시스템 콜이 실행된 스레드만을 복제한다.

exec() 시스템 콜은 챕터 3와 똑같이 작동한다. 즉, 만약 스레드가 exec() 시스템 콜을 실행하면, 프로그램은 모든 스레드를 포함한 전체 프로세스를 교체할 것이다. 

두가지 버전이 fork()중에 무엇을 사용할지는 앱에 달려있다. 만약 exec()가 포킹 이후에 즉시 실행된다면, 모든 스레드의 복제는 불필요하다. exec()에서 명시된 프로그램 파라미터가 프로세스를 교제하기 때문이다. 이런 경우에, 부르는 스레드만 복제하는 것이 적절하다. 만약, 그러나, 분리된 프로세스가 exec()를 포킹 이후에 부르지 않으면, 분리된 프로세스는 반드시 모든 스레드를 복제해야한다.

### 4.6.2 시그널 핸들링
**시그널**은 유닉스 시스템에서 특정 이벤트가 발생했다는 것을 프로세스에게 알리기 위해서 쓰인다. 시그널은 동기적, 비동기적으로 받아질 수 있고, 출처와 이벤트가 시그널된 이유에 따라서 달린다. 모든 시그널은, 비동기적이든 동기적이든 다음과 같은 공통 패턴을 따른다.

1. 시그널은 특정 이벤트의 발생에 의해서 생긴다.
2. 시그널은 프로세스에 배달된다.
3. 한번 배달되면, 시그널은 반드시 조절되어야한다.

동기적인 시그널의 예시는 불법 메모리 접근과 0으로 나누기 같은 것을 포함한다. 만약 실행중인 프로그램이 이런 행동을 취하면, 시그널은 생성된다. 동기화 시그널은 시그널은 야기한 명령어를 수행한 같은 프로세스에 전달된다.(그들이 동기적이라고 표현되는 이유이다.)

한번 시그널이 작동중인 프로세스의 외부 이벤트에 의해서 생기면, 그 프로세스는 시그널을 비동기적으로 받는다. 이런 시그널의 예시는 특정한 키 입력과 함께 프로세스를 종료하는 것을 포함하고 타이머 만료를 가진다. 일반적으로, 비동기적인 시그널은 다른 프로세스에 의해서 보내진다.

시그널은 두가지 가능한 핸들러중 하나에 의해서 핸들된다. 
1. 디폴트 시그널 핸들러
2. 유저 정의 시그널 핸들러

모든 시그널은 시그널을 핸들링할때 커널이 실행되는 **default signal handler**를 가진다. 이런 디폴트 액션은 **user-defined signal handler**로 오버라이드 될 수 있다. 시그널들은 다른 방법으로 핸들된다. 몇가지 시그널들은 다른것들은 프로그램을 종료함으로서 무시될 수 있다.

한개의 스레드에서 시그널을 핸들링하는 것은 직관적이다. 시그널들은 항상 프로세스에 배달된다. 그러나, 복잡한 멀티스레드 프로그램에서 시그널 배달은 더욱 복잡하다. 그러면 시그널은 어디로 가야할까?

보통은 다음과 같은 옵션이 존재한다.

1. 어떤 시그널이 적용되는 스레드에 시그널을 보낸다.
2. 프로세스 안의 모든 스레드에 시그널을 보낸다.
3. 프로세스 안의 특정 스레드에 시그널을 보낸다.
4. 몇가지 특정 스레드를 모든 시그널을 받게끔 할당한다.

시그널 배달의 방법은 형성된 시그널의 타입에 따라 결정된다. 예를 들어서, 동기화 시그널은 시그널을 야기하는 스레드에 배달해야하고 프로세스 안의 다른 스레드에는 배달하면 안된다. 그러나, 비동기 시그널은 딱히 명확하지 않다. 몇몇 비동기 시그널(프로세스 종료 같은 시그널)은 모든 스레드에 보내져야한다.

시그널을 배달하는 스탠다드 UNIX 함수는 `kill(pid_t pid, int siganl)`이다. 

이 함수는 프로세스(pid)에 특정 시그널(signal)을 보내지도록 한다. 대부분의 유닉스 멀티 스레드 버전은 스레드가 어떤 시그널이 받고 어떤 시그널이 막을지를 특정화하는 것을 허용한다. 그러므로, 이런 경우에, 비동기 시그널은 막지 않는 시그널에만 시그널을 보내도록 한다. 그러나, 시그널이 오직 한번만 핸들되는 것이 필요하기 때문에, 시그널은 보통 막지않는 첫번쨰 스레드에만 배달한다. POSIX Pthreads는 다음과 같은 함수를 제공하는데, 시그널이 특정 스레드에 배달되게한다.

`pthread_kill(pthread_t tid, int signal)`

비록 윈도우가 시그널을 위한 지원을 확실하게 하지는 않지만, **Asynchronous Procedure Calls(APCs)**라는 것을 지원한다. APC 시설은 스레드가 유저 스레드가 특정 이벤트의 알림을 받았을떄 함수를 명세하는 것을 허용한다. 이름 그대로, APC는 유닉스의 비동기 시그널과 같다. 그러나, 유닉스가 반드시 멀티스레드 시스템에서 어떻게 시그널을 다뤄야하는지 다퉈야는데 비해서, APC는 더욱 직관적이고, APC는 프로세스보다는 특정한 스레드에 시그널을 배달하낟.

### 4.6.3 스레드 취소

**Thread Canscellation**은 그것이 완료되기전에 종료하는 것을 포함한다. 예를 들어서, 만약 다양한 스레드가 데이터 베이스를 동시에 검색하고 한 스레드가 결과를 리턴하면, 나머지 스레드는 취소될 것이다. 다른 상황은 유저가 웹페이지가 로딩하는 것을 더 멈추는 웹브라우저의 버튼을 눌렀을때 생길수 있다. 자주, 웹 페이지는 몇가지 스레드를 이용해서 로딩을 한다.(각 이미지는 분리된 스레드로 로딩된다.) 유저가 스탑 버튼을 브라우저에서 누르면 모든 스레드는 페이지 로딩을 취소한다.

취소된 스레드는 보통 **target thread**라고 불린다. 타겟 스레드의 취소는 두가지 시나리오를 야기한다.

1. Asynchronous cancellation : 한가지 스레드가 타겟 스레드를 즉시 종료한다.
2. Deffered cancellation : 타겟 스레드가 누가 종료될지 주기적으로 체크하고, 그것 자체가 순서대로 종료할 기회를 허용하낟.

취소하는 것의 어려움은 리소스가 취소된 스레드에 할당되거나 스레드가 다른 스레드와 공유중하면서 데이터를 업데이트 하는 중간에 취소되는 경우에 생긴다. 이것은 asynchornous cancellation과 함께 특히 힘들어졌다. 자주, 운영체제는 취소된 리소스에서 시스템 리소스를 재정의하지만 모든 리소스를 재정의하지는 않는다. 그러므로, 스레드를 비동기적으로 취소하는 것은 필요한 시스템 와이드 리소스를 풀어주지 못한다.

defferd cancellation은 반면에, 한 스레드가 타겟 스레드가 종료되도록 지정한다. 그러나 취소는 오직 타겟스레드가 취소되어야할지 아닌지 구별하는 플래그를 체크함으로서 실행된다. 스레드는 그것이 안전하게 취소될수 있는 포인트를 체크함으로서 실행한다. 

Pthreads에서, 스레드 취소는 pthread_cancel()을 통해서 시작할수 있다. 타겟스레드의 식별자는 함수에 의해서 파라미터로 전달된다. 다음 코드는 스레드의 취소와 생성을 설명한다.

```c
pthread_t tid;

/*create the thread */
pthread_create(&tid, 0, worker, NULL);

/* cancel the thread */
pthread_cancel(tid);

/*waid for the thread to terminate */
pthread_join(tid, NULL);
```

pthread_cancel()을 실행하는 것은 타겟 스레드를 취소하는 명령을 가르킬뿐이다. 실제 취소는 어떻게 타겟 스레드가 리퀘스트를 핸들할지 셋업하느냐에 달려있다. 타겟 스레드가 마침내 종료되면, pthread_join()이 스레드 취소를 리턴한다. Pthreads는 3가지 취소 모드를 지원한다. 각각의 모드는 스테이트와 타입을 정의한다. 스레드는 API를 이용해서 스테이트와 타입을 세팅한다.

Pthreads는 스레드가 취소 활성화/비활성화를 허용한다. 명백하게, 스레드는 만약 취소가 비활성화되면 취소될수 없다. 그러나, 취소 리퀘스트는 기다리고, 그래서 스레드는 나중에 취소를 활성화하고 명령에 반응한다.

디폴트 취소 타입은 deferred cancellation이다. 그러나, 취소는 오직 스레드가 **cancellation point**에 도달했을떄만 일어난다. 대부분의 POSIX와 C 라이브러리의 블락킹 시스템 콜은 cancellation point로 저으이되고, 이것들은 리눅스 시스템에서 man pthread를 불렀을때 리스트된다. 예를 들어서, read() 시스템 콜이 read()로부터 인풋을 기다리면서 블락된 스레드 취소를 허용하는 취소 포인트다.

취소 포인트를 만드는 한가지 기술은 pthread_testcancel() 함수를 이용하는 것이다. 만약 취소 리퀘스트가 대기중인 것을 찾으면, ptrhread_testcancel() 함수는 리턴되지않고, 스레드는 종료될 것이다. 다른 경우에는 함수로의 콜은 리턴되고, 스레드는 계속 실행된다. 추가적으로, Pthreads는 **cleanup handler**로 알려져있는데 만약 스레드가 취소되면 실행된다. 이 함수는 스레드가 가진 어떤 리소스도 스레드가 종료되기전에 해제하도록 한다.

다음과 같은 코드는 어떻게 스레드가 취소 리퀘스트를 실행하는지 보여준다.
```c
while(1){
    /* do some work for a while */

    /* check if there is a cancellation request */
    pthread_testcancel();
}
```

이슈에 대해 일찍이 말했듯이, 비동기 취소는 Pthread 도큐에서 추천되지 않는다. 흥미로운 점은, Pthread API를 이용한 스레드 취소는 시그널을 통해서이다.

자바에서의 스레드 취소는 Pthread의 deffered cancellation과 비슷하다. 자바 스레드를 취소하기 위해서, 너는 인터럽션 스테이터스가 트루가 되도록 interrupt() 메서드를 실행한다. 스레드는 그것의 isInerrupted() 메서드를 통해서 그것의 인터럽션 스테이터스를 체크하고 상태를 확인가능하다.

```java
Thread worker;
worker.interrupt()
while(!Thread.currentTrhead().isInterrupted()){

}
```

### 4.6.4 스레드 로컬 스토리지

프로세스에 소속된 스레드들은 프로세스의 데이터를 공유한다. 실제로, 이 데이터 공유는 멀티스레드 프로그래밍의 이점을 제공한다. 그러나, 몇몇 환경에서, 각각의 스레드는 일부 데이터의 자신의 전용 카피를 필요로 할 수 있다. 우리는 이런 데이터를 **Thread local stroage(TLS)**라고 한다. 예를 들어서, 트랜잭션 프로세싱 시스템에서, 우리는 분리된 스레드에서 각 트랜잭션을 서비스 할 수 있다. 더욱이, 각 트랜잭션은 특별한 식별자에 의해서 할당될 수 있다. 각 스레드와 관련하기 위해서, 우리는 스레드 로컬 스토리지를 사용한다.

TLS와 로컬 변수를 헷갈리기는 쉽다. 그러나, 로컬 변수는 한 단일 함수의 발동중에만 보이고 반면에 TLS 데이터는 모든 함수 발동에 보인다. 추가적으로, 개발자가 스레드 생성 프로세스의 제어권이 없다면, 예를 들어서, 내포적인 기술(스레드풀)을 사용하면 다른 접근이 필요하다.

몇가지 방법에서, TLS는 static 데이터가 비슷하게 있다. 차이는 TLS 데이터가 각 스레드에 유니크하다. 대부분의 스레드 라이브러리와 컴파일러는 TLS를 지원한다. 예를 들어서 자바는 ThreadLocal<T> 클래스를 set()rhk get() 메서드를 통해서 제공한다. Pthreads는 pthread_key_t를 포함하고, 각 스레드에 특별한 키를 제공한다. 이 키는 TLS 데이터의 접근에 필요하다. 이 마이크로 소프트의 C# 언어는 간단하게 [ThreadStatic]이라는 스레드 로컬 데이터를 더한다. gcc 컴파일러는 스토리지 클래스 키워드 __thread를 TLS 데이터 선언을 위해서 사용한다. 예를 들어서, 만약에 우리가 유니크 식별자를 주기 원한다면 우리는 다음과 같이 선언 가능하다.
`static __thread int threadID;`

### 4.6.4 스케쥴러 활성화

멀티스레드 프로그램을 위한 마지막 이슈는 커널과 스레드 라이브러리 사이의 통신이다. 이것은 앞서말한 many-to-many와 two-level 모델을 필요로한다. 이런 조정은 최고의 성능을 위해서 커널 스레드가 동적으로 조정되는 것을 돕는다. 

many-to-many 또는 two-level 모델을 구현하는 많은 시스템들은  유저와 커널 스레드 사이의 중간 데이터 구조를 둔다. 이 데이터 구조는 **lightweigh process**라고 알려져있다. 유저 스레드 라이브러리에서, LWP는 앱이 유저 스레드가 실행되게 스케쥴링하는 가상 프로세스이다. 각 커널 스레드에 LWP에 붙으면, 운영체제를 물리적 프로세서에서 스케쥴하는 커널스레드이다. 만약 커널 스레드가 막으면, LWP또한 막는다.(예를 들어서 I/O 명령이 완료되길 기다리는 것). 이런 체인에서, LWP에 붙은 유저 레벨 스레드도 막힌다.

앱은 LWP가 효율적으로 일하도록 한다. CPU 바운드 앱이 싱글 프로세서에서 돌아간다. 이 시나리오에서, 오직 하나의 스레드가 한번에 작동하고, 한 LWP는 충분하다. I/O 인텐시브 앱은 다중 LWP를 필요로한다. 일반적으로 LWP는 각 동시 블럭킹 시스템 콜을 필요로한다. 5개의 다른 파일-리드가 동시에 생성된다고 가정하자. 5개의 LWP가 필요하고, 커널에서 모든 I/O 완료를 기다린다. 만약 프로세스가 4개의 LWP를 가지면, 5번쨰 리퀘스트는 커널로부터 LWP를 한개 리턴받기를 기다려야한다.

유저 스레드 라이브러리와 커널 사이의 통신을 하는 방식은 **scheduler activation**으로 알려져 있다. 그것은 다음과 같다. 커널은 LWP(가상 프로세서)를 제공하고, 앱은 가용한 가상 프로세서에 유저 스레드를 스케쥴한다. 더욱더, 커널은 반드시 일부 이벤트에 대해서 앱을 공지한다. 이런 프로시저는 **upcall**이라고 한다. 업콜은 스레드 라이브러리에 의해서 핸들되고 **upcall handler**은 반드시 가상 프로세서에서 작동된다.

업콜을 실행하는 한가지 이벤트는 앱 스레드가 막히기전에 실행된다. 이런 시나리오에서, 커널은 앱에 스레드가 막히기 전이고 특정 스레드를 구별하고 업콜을 만든다. 커널은 새로운 가상 프로세서를 앱에 할당한다. 앱은 업콜 핸들러를 새로운 가상 프로세서에 실행하고, 블럭킹 스레드의 상태를 저장하고, 블럭킹 스레드를 실행하는 가상 프로세서를 포기한다. 업콜 핸들러는 다른 스레드를 새로운 가상 프로세서에 실행한다. 