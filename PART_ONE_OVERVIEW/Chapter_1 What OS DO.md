# Introduction

운영체제는 컴퓨터의 하드웨어를 관리하는 소프트웨어이다. 그것은 어플리케이션 프로그램을 기본으로 제공하고 컴퓨터와 하드웨어의 중개자역할을 한다.
운영체제의 놀라운 점은 넓은 범위의 컴퓨팅 환경을 달성한다는 것이다. 운영 시스템들은 자동차, IOT, 스마트폰, 개인 컴퓨터, 기업 컴퓨터, 클라우드 컴퓨터 등 어디에나 있다.

현대 운영체제의 역할을 살펴보기 위해서, 기관과 컴퓨터 하드웨어의 구조를 이해하는 것은 중요하다. 이 것은 CPU, memory, I/O 장치, 저장소를 포함한다. 운영체제의 기본적인 책임은 자원을 프로그램에 할당하는 것이다.

운영체제는 크고 복잡하기에 조각으로 생성되고 인풋, 아웃풋, 펑션이 잘 기술된 부분으로 되어있다.

우리는 이단원에서 현대 컴퓨터 시스템의 주요 부분을 공부하고 운영체제가 제공하는 기술을 공부한다.
더불어서, 우리는 책의 여분을 도울 몇가지 단계도 도울 것이다. : 자료구조, 컴퓨팅 환경, 오픈소스, 무료 운영체제.

## Chapter Objectives

- 컴퓨터 시스템의 구성과 인터럽트의 역할을 전반적으로 설명한다.
- 현대 멀티프로세서 컴퓨터 시스템을 설명한다.
- 유저 모드에서 커널 모드로의 변환을 설명한다.
- 운영체제가 어떻게 다양한 컴퓨팅 환경에서 사용되는지 논의한다.
- 무료 오픈소스 운영체제를 소개한다.

## 1.1 운영체제는 무슨 일을 하는가
우리는 전체적인 컴퓨터 시스템에서 운영체제가 무엇을 하는지부터 알아보겠다. 컴퓨터는 크게 4가지로 나뉜다.: 하드웨어, 운영체제, 앱 프로그램, 사용자.

> 하드웨어
>> CPU, memory, IO devices : 시스템을 위한 기본적인 컴퓨팅 자원을 제공한다.

> 앱 프로그램
>> 워드프로세서, 스프레드시트, 컴파일러, 웹브라우저 : 유저의 컴퓨팅 문제를 해결하는 자원을 의미한다.

아니면 하드웨어, 소프트웨어, 데이터로서 컴퓨터 시스템을 볼수도 있다. 운영체제는 정부와도 같다. 정부처럼, 그것은 그 자체로서는 일하지 않는다. 그것은 오직 다른 프로그램이 유용하게 활용되게끔 도울 뿐이다. 더 깊게 이해하기 위해서는 우리는 두가지 관점으로 운영체제를 보아야한다. 유저와 시스템이다.

### 1.1.1 사용자 관점
컴퓨터의 사용자 관점은 어떤 인터페이스가 사용되냐에 따라 달라진다. 사용자들은 모니터, 키보드, 마우스를 포함한 랩탑 또는 PC 앞에 앉아있다. 이러한 시스템은 유저가 그것의 자원을 독점하게 만든다. 
목적은 작업(게임)을 극대화하는 것이다. 이런 경우에, 운영 체제는 ##간단한 사용##을 목적으로 만들어진다. 여기에는 퍼포먼스와 보안에 약간, ##자원의 활용도##는 신경쓰지 않는다. 

많은 사용자들이 스마트폰과 모바일 기기를 사용하는 추세이다. 이러한 기기들은 무선 기술과 연결되어있다. 모바일 컴퓨터 사용자의 인터페이스는 터치스크린이고 손가락으로 이루어진다. 그리고 애플의 시리 같은 음성인식으로도 사용된다. 

몇몇 컴퓨터들은 사용자의 관점이 전혀 고려되지 않는다. 예를 들어, 집안의 임베디드 컴퓨터와 자동차는 물론 우리가 키패드 좀 있고 지시등은 있어도, 사용자의 개입 없이 잘 작동하게끔 만든다.

### 1.1.2 시스템 관점
컴퓨터의 관점에서 운영체제는 하드웨어와 매우 친밀한 프로그램이다. 이 문맥은, 우리는 운영체제를 자원 할당자로 보는 것이다. 컴퓨터 시스템은 해결해야할 많은 문제가 있다.: CPU time, memory space, storage space, I/O devices 등등. 운영 체제는 이러한 자원의 관리자로서 일한다. 다양하고 가능한 리소스 요청 충돌을 마주하면서 운영체제는 반드시 자원을 특정 프로그램에 할당하고 컴퓨터 시스템이 효율적이고 공평하게 운영되게끔 도와야한다.

운영체제의 다른 관점은 I/O 디바이스와 유저 프로그램을 적절하게 관리해야한다. 운영체제는 Control program이다. 관리 프로그램은 유저 프로그램을 관리하고 에러와 컴퓨터의 오용을 막는다.
특히 운영과 I/O장치가 고려된다.

### 1.1.3 운영체제를 정의하는 것

이제, 당신은 #운영체제#가 많은 역할과 기능을 포함한다는 것을 보았다. 컴퓨터들은 토스터, 자동차, 배, 우주선, 집, 사업 등 어디에나 존재한다. 그들은 게임 기계, 케이블 티비, 산업 관리 시스템에도 있다.

이러한 다양성을 설명하기 위해, 우리는 컴퓨터의 역사를 돌아봐야한다. 컴퓨터는 비교적 짧은 역사를 가졌지만, 그들은 빠르게 진화했다. 컴퓨팅은 군사적 사용을 위해서 시작되었다. 암호해독, 미사일 탄도 그림, 인구 조사 등을 위해서 발전했다. 이런 초기의 컴퓨터는 공용 목적으로 진화했고, 다기능 프레임이었고 이게 운영체제의 탄생이다. 컴퓨터는 목적을 가지게 되었고, 작아졌고 수많은 사용자와 수많은 운영체제를 탄생시켰다. 

그래서 운영체제가 뭔지 알겠는가? 보통 우리는 운영체제의 완벽한 정의를 갖지 않는다.  운영체제는 그들이 쓸만한 컴퓨팅 시스템을 만드는 문제를 적절한 해결책을 위해서 존재한다. 컴퓨터 시스템의 근본적인 목적은 프로그램을 실행하고 유저 문제를 쉽게 해결하게 한다. 컴퓨터 하드웨어는 이 목적을 위해서 만들어진다. 나체의 하드웨어 혼자서는 적절한 일을 쉽게하지 못하고 이러한 것은 I/O 디바이스가 관리하는 것을 돕는다. 그러면서 자원을 할당하고 관리하는 것은 따라오게 되는 것이다. 이러한 하나하나가 뭉친게 운영체제다.

더해서, 우리는 운영체제의 정확한 범우주적인 명확한 정의는 없다. 간단한 관점은 당신이 무언가를 시켰을때 다 포함 된 것이다. 기능은 시스템을 걸쳐서 다있다. 몇몇 시스템은 작은 화면도 없을 정도로 메가 바이트보다 작고, 반면에 눈이 즐거운 윈도우는 기가바이트보다 클수있다. 더 간단한 정의는 컴퓨터에서 항상 실행중인 것이다. 이런걸 ##커널##이라고 부른다. 커널을 따라서, 프로그램은 두가지가 있다. ##시스템 프로그램##이라는 운영체제가 관련되어는 있지만 커널의 부분은 아닌 것과 시스템의 운영에 전혀 관계없는 앱 프로그램이다.

운영 체제를 만드는 문제는 점점 중요하고 복잡하고 섬세해지고 있다. 1988년에 MS사는 미국 정부에게 운영체제가 너무 많은 기능을 제공해서 앱 판매자를 죽인다고 소송걸렸다. 결과적으로 MS사는 운영 체제가 독점했고 유죄라고 판단 받았다.

오늘날, 만약 우리가 모바일 기기의 운영체제를 본다면, 우리는 다양한 기능이 운영체제를 포함하고 늘어간다는 것을 볼 수 있다. 모바일 운영체제는 보통 코어 커널 뿐아니라, 미들웨어도 포함한다. 예를 들어서 애플의 IOS와 구글의 안드로이드다. 이것은 데이터베이스, 멀티미디어, 그래픽을 지원하는 미들웨어 커널이 있다.

요약하자면, 운영체제는 항상 작동하는 커널이 있고, 미들웨어 프레임워크가 앱 개발을 쉽게하고 기능을 제공하고, 시스템 프로그램이 시스템을 돕는 것이다.

## 1.2 컴퓨터 시스템 구조

현대의 컴퓨터 시스템은 여러개의 CPU와 공유된 메모리와 컴포넌트와 다양한 디바이스 컨트롤러를 연결하는 각각의 디바이스 컨트롤러는 특적한 기기에 책임을 진다. 예를 들어서 하나의 USB 포트는 여러개의 디바이스가 연결되는 USB 허브를 연결한다. 디바이스 컨트롤러는 지역 버퍼 공간과 특별한 목적 레지스터를 유지한다. 
특히 운영체제는 ##디바이스 드라이버##를 가지고 있다. 이 디바이스 드라이버는 컨트롤러를 이해하고 운영체제가 디바이스에 일정한 인터페이스를 제공한다. CPU와 디바이스 컨트롤러는 병행으로 실행되고 메모리 사이클로 경쟁한다. 이것을 확인하기 위해서 공유된 메모리에 순서대로 접근을하고 메모리 컨트롤러는 동기화된다.

다음 하위섹션에서는, 우리는 시스템이 어떻게 작동하는지, 시스템의 3개의 관점에 집중하겠다. 우리는 인터럽트를 시작으로 CPU가 관심을 요하는 이벤트에 어떻게 경고하는지 보겠다. 그리고 스토리지 구조와 I/O구조를 보겠다.

### 1.2.1 인터럽트

특정한 컴퓨터 명령을 고려하자 : 프로그램 I/O 실행. I/O실행을 시작하기 위해서, 디바이스 드라이버는 디바이스 컨트롤러를 적절한 레지스터에 부른다. 디바이스 컨트롤러는 이런 레지스터의 콘텐츠가 어떤 헹동을 취할지 말해준다. 컨트롤러는 데이터를 디바이스에서 버퍼로 옮긴다. 그때 데이터의 전송은 완료되고 디바이스 컨트롤러는 디바이스 드라이버에게 명령이 끝났다고 말한다. 디바이스 드라이버는 그러고 운영체제의 다른 부분을 조작하고 데이터를 반환하거나 명령이 읽힌 데이터의 포인터를 반환한다. 다른 명령은 디바이스 드라이버가 "읽기 완료됨"이라는 상태 정보를 반환하거나 "디바이스 바쁨"을 반환한다. 그러나 어떻게 컨트롤러가 그 명령이 끝났다는 것을 어떻게 알것인가? ##인터럽트##가 해준다.

### 1.2.1.1 개요

하드웨어는 시스템 버스를 통해서 CPU에 시그널을 보냄으로서 인터럽트를 발생시킨다.(컴퓨터 시스템에는 다양한 시스템 버스가 있고 시스템 버스는 주요한 부품들간의 경로이다.)
인터럽트들은 다양한 목적으로 사용되고 운영체제와 하드웨어가 어떻게 작동하는지 중요한 열쇠이다.

CPU가 인터럽트일때, 그것은 행동을 멈추고 즉시 고정된 지점으로 행동한다. 이 고정된 지점은 보통 인터럽트를 위한 서비스 루틴이 저장된 시작 주소로 이동한다. 인터럽트 서비스 루틴은 완료되면, CPU는 인터럽드 당한 연산을 다시 시작한다. 

인터럽트는 컴퓨터 아키텍처에서 중요한 부분이다. 각각의 컴퓨터 디자인은 고유의 인터럽트 메커니즘이 있지만, 몇몇은 공통을 가진다. 인터럽트는 반드시 전송 조작을 적절한 인터럽트 서비스 루틴에 넣어야한다. 전송을 관리하는 가장 직관적인 방법은 인터럽트 정보를 제너릭 루틴에 부르는 것이다. 그 루틴은 특정 인터럽트 핸들러를 부를 것이다. 그러나 인터럽트는 반드시 빠르게 수행되고 자주 생길 것이다. 서비스 루틴의 포인터의 테이블은 필요한 속도를 제공하기 위해서 쓰인다. 인터럽트 루틴은 테이블로 간접적을 불리고 중간 루틴은 필요가 없다. 보통 포인터의 테이블은 low memory에 저장된다. 이런 위치는 인터럽트 서비스 루틴이 다양한 기기에 적용된다. 이 인터럽트 벡터(어레이)는 특정한 번호로 저장되있고, 인터럽트 요청이다. 운영체제에 따라서 이 구성은 다르다.

인터럽트 아키텍처는 반드시 무엇이 방해되었든 상태 정보를 저장해야한다. 그래서 그것이 이 정보를 복구할수 있기때문이다. 만약에 인터럽트 루틴이 프로세서 상태를 바꿀 필요가 있다. 예를 들어 레지스터 값을 바꾸면 그것은 반드시 현재 상태에 저장되고 그 상태를 반환하기 전에 복구되어야한다. 인터럽트가 끝난후에 저장된 복구 지점은 PC에서 불러지고 새로운 인터럽트가 생기기 전까지 생기지 않는다.

### 1.2.1.2 Implementation

기본 인터럽트 메커니즘은 다음과 같이 작동한다. CPU 하드웨어는 ##Interrupt-request line##이라는 CPU가 매 명령마다 반응하는 와이어가 있다. CPU가 컨트롤러가 시그널을 보냈는지는 이 line에서 확인하고 인터럽트 숫자를 읽고 인터럽트 벡터의 인덱스 숫자에 맞게 ##Interrupt-handler routine##으로 들어간다. 그리고는 인덱스에 맞는 일을 한다. 인터럽트 핸들러는 그것의 행동 동안 변경되는 어떤 상황도 저장하고 인터럽트의 원인을 결정하고 필요한 프로세싱을 수행하고, 상태 복구를 실행하고 #return_from_interrupt#를 실행한다. 디바이스 컨트롤러는 인터럽트를 어필하고 CPU는 인터럽트를 캣치하고 그것을 인터럽트핸들러에 실행한다. 그리고 핸들러는 디바이스를 서비싱함으로서 인터럽트를 지운다.

기본적인 인터럽트 메커니즘은 CPU가 비동기된 이벤트를 가능하게 한다. 그리고 디바이스 컨트롤러가 준비되면 반응한다. 현대의 운영체제에서 우리는 더 섬세한 인터럽트 핸틀링 기능이 필요하다.

1. 우리는 중요한 프로세싱 중에 인터럽트를 미룰 수 있는 능력이 필요하다.
2. 우리는 디바이스를 위한 인터럽트 핸들러로 보낼 효율적인 방법이 필요하다.
3. 우리는 다단계의 인터럽트가 필요하다. 즉 운영체제가 높은 우선순위의 인터럽트와 낮은 우선순위의 인터럽트를 급박함의 단계에 따라서 구분할 수 있어야 한다.

현대의 컴퓨터 하드웨어는 3가지 기능을 CPU와 #interrupt-controller-hardware#로 제공한다.
대부분의 CPU는 두가지 인터럽트 요청 라인이 있다. 하나는 #nonmaskable interrupt#인데 복구 불가능한 메모리 에러 상황을 저장한다. 두번째 인터럽트 라인은 #maskable#이다. 이 것은 CPU가 중요한 명령 단계일때 꺼지는 기능이 있다. maskable 인터럽트는 디바이스 컨트롤러에게 쓰인다.

인터럽트 메커니즘의 벡터화 목적은 단일 이너럽트 핸들러가 인터럽트의 모든 원인을 파악하고 어떤 서비스가 필요한지 도움을 주는 것이다. 실전에서는, 컴퓨터에게 인터럽트 벡터보다 사실 더 많은 디바이스가 있다. 이를 해결하는 방법은 #인터럽트 Chaining#이다. 인터럽트가 생겼을때 관련된 리스트를 필요한 서비스를 찾을때까지 찾는 것이다. 이 구조는 큰 인터럽트 테이블과 단일 인터럽트 핸들러를 보내는 비효율성등을 만든다.

인터럽트 메커니즘은 또한 인터럽트 우선 레벨의 시스템또한 기능한다. 이러한 레벨은 CPU가 낮은 우선순위 인터럽트를 마스킹 없이 무시하게 해준다. 그리고 반대로는 높은 우선순위의 인터럽트가 하위 우선순위의 동작을 선점하게 한다.

요약하자면, 인터럽트는 현대 운영체제 시스템에 사용되고 비동기 이벤트이다. 디바이스 컨트롤러와 하드웨어 손상은 인터럽트를 부른다. 이런 긴박한 일을 먼저 실행하는 것을 가능하게 하고 현대 컴퓨터는 인터럽트 우선의 시스템을 사용한다. 인터럽트가 시간에 민감하기 때문에, 효율적인 인터럽트 핸들링이 좋은 시스템 퍼포먼스를 위해서 필요하다.

### 1.2.2 Storage Structure

CPU는 메모리로부터 명령을 읽어내고 프로그램은 실행되기 위해서 메모리로 들어가야한다. 컴퓨터는 대부분의 프로그램이 다시 쓰기 가능한 메모리에서 작동된다.(RAM이라고 불린다.) 메인 메모리는 DRAM이라고 불리는 반도체 기술이다.

컴퓨터는 다른 형태의 메모리도 사용한다. 예를 들어서 첫번째 프로그램은 컴퓨터가 켜질때 돌아가는 것은 부트스트랩 프로그램이고 OS에서 로드 된다. RAM이 휘발성이고 파워가 꺼지면 정보를 잃지만 우리는 부트스트랩 프로그램을 믿고 맡길 수 없다. 대신에 다른 목적으로 컴퓨터는 EEPROM을 사용하고 펌웨어라는 자주 읽히지 않고 비휘발성을 쓴다. EEPROM은 바뀔수는 있지만 자주는 바꾸지 않는다. 더욱이 그것은 매우 느리고 자주 사용하지 않는 보통 정적인 프로그램과 데이터를 저장한다. 예를 들어서, 아이폰은 EEPROM을 시리얼 넘버와 하드웨어 정보를 저장하는데 쓴다.

모든 메모리의 형태는 바이트의 배열이다. 각각의 바이트는 고유한 주소를 가진다. 교환은 특정 메모리 주소에 load와 store 명령으로 이루어진다. load 명령어는 바이트나 워드를 메인 메모리로부터 CPU의 내부 레지스터에 옮기고 STORE는 레지스터의 값을 메인메모리로 옮긴다. 명확한 로드와 스터어외에도 CPU는 명령을 메인메모리로부터 부르고 프로그램 카운터에 저장한다.

특정한 명령-명령주기는 폰노이만 아키텍처에서 실행되고 명령은 메모리에서 그리고 인스트럭션 레지스터에 명령을 저장한다. 명령은 디코드되고 메모리로부터 가져온 피연산함수는 몇몇 내부 레지스터에 저장된다. 명령위에서 피연산자가 실행되면, 결과는 다시 메모리에 저장된다. 메모리 유닛은 메모리 주소의 흐름만을 본다는 것을 기억해라. 그것은 어떻게 그들이 생겼는지는 모른다.  우리는 메모리 주소가 어떻게 프로그램에 의해서 생겼는지는 무시하는 것이다. 우리는 오직 메모리 주소의 연속에만 관심이 있다. 

이상적으로 우리는 프로그램과 데이터가 메인 메모리에서 항상 있기를 바란다. 두가지 이유로 불가능하다.
1. 메인 메모리는 모든 프로그램을 저장하기에는 너무 작다.
2. 메인 메모리는 휘발성이고 파워가 꺼지면 사라진다.

그러므로 대부분의 컴퓨터는 ##secondary storage##를 제공한다. 2차 메모리의 필요는 큰 양의 데이터를 영구적 저장이 가능하다는 것이다. 이런 2차 저장소는 ##Hard-disk drives##와 ##Nonvolatile memory(NVM) devices##이다. 대부분의 프로그램은 2차메모리에서 저장되있다가 메모리에 로드된다. 많은 프로그램은 소스와 그들의 프로세싱의 목적지로 사용한다. 2차 저장소는 메인메모리보다 많이 느리다. 따라서 적절한 2차메모리의 관리는 11장에서 언급하겠다.

큰 관점에서, 저장소 구조는 레지스터, 메모리, 2차메모리로 구성되어있다. 다른 가능한 컴포넌트는 캐시메모리, 씨디롬, 자기 테이프가 있다. 이런 것들은 느리고 크고 특정 목표로만 쓰인다. 이런 것들을 ##tertiary stoarge##라고 부른다. 각 저장 시스템은 기본적인 자료를 부르는 방식과 이전 시간으로 부르는 기능을 제공한다. 저장소간의 차이는 속도, 크기, 휘발여부가 있을 것이다.

후에도 이런 저장소에 대해서 언급하기 위한 용어 정리를 하겠다.

- 휘발성 저장소는 메모리라고 할 것이다. 만약 특정 저장 장치(레지스터)를 의미하면 우리는 정확히 얘기하겠다.
- 비휘발성 저장소는 전원이 꺼져도 컨텐츠를 저장한다. 그것은 ##NVS##라고 부르겠다. NVS는 2차 저장소를 언급할때 많이 쓰일 것이고 두가지 형태가 있다.
  + Mechanical. 적은 에시의 저장 시스템이고 HDD, 광학 디스크, 자기 테이프가 되겠다. 
  + Electircal. FRAM, NRAM SSD같은 플래시 메모리가 되고 NVM이라고도 불린다.

완벽한 저장 시스템은 반드시 모든 요소가 밸런스에 맞게 되어야한다. 그것은 최대한 필요한 만큼 비싸고 그러면서 최대한 싸야한다. 캐시는 엑세스 시간이나 전송효율을 높이는데 큰 차이를 준다.

### 1.2.3 I/O Structure

운영체제의 코드중 큰 부분을 I/O관리에 헌신하는데 왜냐하면 시스템의 성능과 의존성의 중요성이 있다. 

이 세션을 시작할 때를 생각해보면 보편적인 목적 컴퓨터 시스템은 여러가지 디바이스를 포함하고 커먼 버스를 통해서 데이터를 주고받는다. 인터럽트 기반 I/O는 1.2.1에서 설명했고 적은 양의 데이터를 옮기는데 도움된다. 그리고 너무 큰 것을 옮기면 오버헤드가 일어난다. 이런 문제를 해결하기 위해서, ##DMA##가 이용된다. 버퍼, 포인터, 카운터를 지정하고 디바이스 컨트롤러는 데이터의 전체 블럭을 전송한다. 오직 하나의 인터럽트는 블록에서 생성되고 디바이스 드라이버가 명령이 완료되었다고 말해준다. 디바이스 컨트롤러가 이런 명령을 수행하면서 CPU는 다른 일을 한다.

몇몇 하이엔드 시스템은 버스 아키텍처보다는 스위치를 사용하기도 한다. 이런 시스템에서는 여러개의 컴포넌트가 병행으로 대화한다. 이런 경우에 DMA는 더욱 효과적이다.


## 1.3 컴퓨터 시스템 아키텍처

앞서 1.2절에서, 우리는 컴퓨터 시스템의 전형적인 구조를 보았다. 컴퓨터 시스템은 여러가지 방식으로 구성될 수 있고 우리는 공통 목적의 프로세서를 분류화 할 수 있다.

### 1.3.1 싱글 프로세서 시스템

수년전, 많은 컴퓨터는 하나의 단일 프로세싱 코어를 가진 CPU를 가진 싱글 프로세서였다. 코어는 명령을 실행하고과 데이터를 저장하는 구성요소이다. 
하나의 메인 CPU는 명령어 세트를 실행하는 것이 가능하다. 이러한 시스템들은 특별한 목적을 가진 프로세서이다. 그들은 디스크, 키보드, 그래픽 컨트롤러 같은 특정 디바이스를 위한 프로세서일수도있다.

특정한 목적을 가진 프로세서들은 제한된 명령어 세트에서 작동하고 프로세스를 실행하지는 않는다. 가끔 그들은 운영체제에 의해서 관리되고, 운영체제는 그들에게 다음 작업에 대한 정보를 보내고 그들의 상태를 관찰한다. 예를 들어 디스크 컨트롤러 마이크로프로세서는 CPU로 부터 명령을 받고 그들의 디스크 큐와 스케줄링 알고리즘을 실행한다. 이런 것들은 메인 시피유의 디스크 스케쥴링 오버헤드를 경감시킨다. PC는 CPU로 키보드의 타닥을 변환해서 보내는 마이크로 프로세서가 있다. 다른 시스템이나 환경에서 특정 목적 프로세서는 낮은 레벨의 구성요소로서 하드웨어에 들어간다. 운영체제는 다른 프로세서와 소통을 하지 않는다. 그들은 독자적으로 그들의 일을 한다. 특별한 목적을 가진 마이크로 프로세서는 일반적이고 멀티프로세서라고 하지는 않는다. 만약 오직 하나의 범용 CPU가 하나만 있으면 그건 싱글 프로세서 시스템이다. 정의에 따르면 현대의 컴퓨터 시스템들은 싱글 프로세서 시스템이다.

### 1.3.2 멀티 프로세서 시스템

현대의 컴퓨터들은 모바일부터 서버까지 멀티 프로세서 시스템이 대부분이다. 전통적으로 이러한 시스템들은 두개 혹은 더 많은 프로세서를 가지고 있고 각각은 싱글 코어 CPU이다. 프로세서는 컴퓨터 버스를 공유하고 가끔은 클락, 메모리, 주변 기기를 공유한다. 멀티프로세서의 장점은 향상된 처리량이다. 즉, 프로세서의 수를 늘림으로서, 우리는 많은 일을 더 적은 시간동안 할 수 있다. 물론 N개의 프로세서는 N배의 효율보다는 적다. 많은 프로세서가 협업할때, 일부 오버헤드가 모든 일에서 생기기 때문이다. 이 오버헤드와 공유된 자원에 대한 논쟁은 추가적인 프로세서의 예상된 이득을 줄인다.

가장 일반적인 멀티프로세서 시스템은 ##Symmetric multiprocessing(SMP)##이라는 각각의 동료 CPU프로세서가 운영체제 기능과 유저 프로세서를 모두 처리하는 것이다. 각각의 대칭 CPU 프로세서는 그들의 레지스터를 개인, 로컬 캐시로서 가지고 있다. 그러나 모든 프로세서는 시스템 버스를 통해서 물리적인 메모리를 공유하고 있다.

이 모델의 장점은 여러개의 프로세서가 동시에 작동한다는 것이다. N의 프로세스가 N의 CPU에서 일하는 것이다. 그러나 CPU가 분리되면서 하나는 부하가 걸리면서 하나는 휴식할 수도 있다. 이런 비효율성은 프로세서가 공통적인 자료구조를 공유하는 것으로 회피할 수 있다. 멀티프로세서 시스템은 프로세스와 자원을 다양한 프로세서간에 동적으로 공유되게하고 프로세서의 부담을 줄인다. 이런 것은 5장과 6장에서 자세히 언급하겠다.

멀티프로세서의 정의는 시간을 걸쳐서 진화했고 이제 멀티코어 시스템을 포함한다. 멀티코어 시스템들은 하나의 싱글 코어 멀티칩보다 효율적이다. 왜냐하면 칩 안의 통신이 칩 간의 통신보다 빠르기 때문이다. 멀티 코어를 가진 하나의 칩은 여러개의 칩보다 훨씬 적은 파워를 소비하고 랩탑이나 모바일 기기에 중요한 문제이다. 

멀티 코어 구조는 각각의 코어에 Level1의 L1캐시라는 독립 캐시를 가지고 있고 코어간의 공유하는 Level2의 L2 캐시라는 공유 캐시또한 가지고 있다. 대부분의 아키텍처는 이런 방법을 택해서 지역과 공유된 캐시를 가지게했다. 지역 레벨이 낮은 캐시는 보통 작고 윗단의 공유 캐시보다 빠르게 설계된다.
이런 구조적인 성질들은 운영체제 디자이너, 앱 개발자가 효율적인 프로세싱 코어를 만들도록 노력하게 했고 4장에서 보게될 것이다. 가상적으로 모든 현대 운영체제는 멀티코어 SMP 시스템을 지원한다.

추가적인 CPU는 컴퓨팅 파워를 높였다. 그러나 말했듯이, 너무 많은 CPU가 추가 되고 시스템 버스의 경쟁이 병목현상을 만들고 성능이 떨어지기 시작했다. 다른 방안으로 제공된 방법은 각각의 CPU에 그들의 지역 메모리를 작고 빠른 로컬 버스로 각각 연결하는 것이다. CPU는 공유된 시스템 연결로 모든 CPU가 하나의 물리적인 주소를 공유한다. 이런 방법은 ##Non-uniform memory access or NUMA##라고 불린다. 이 장점은 CPU가 그것의 지역 메모리에 접근하는 것이 빨라지고 시스템 연결간에 경쟁이 사라지게했다. 그러므로 NUMA 시스템은 프로세서가 더 추가되게 했다.

NUMA의 잠재적인 약점은 CPU가 시스템 내부 연결을 통해서 멀리 있는 메모리에 접근해서 생긴 증가된 지연시간이다. 다른 말로 CPU0은 CPU3의 메모리에 CPU0의 지역 메모리보다 빠르게 접근 할 수 없고 결국은 느려진다는 것이다. 운영체제는 CPU 스케쥴링과 메모리 관리를 조심스럽게 함으로서 이런 NUMA의 단점을 극복했고 5.5.2와 10.5.4에서 자세히 얘기하겠다. NUMA 시스템은 많은 수의 프로세서가 상주하게끔 하기 때문에, 그들은 서버에서도 인기가 늘어나고 고사양 컴퓨팅 시스템에서도 각광 받고 있다.

> 컴퓨팅 시스템 구성요소의 정의
  - CPU : 명령을 실행하는 하드웨어
  - 프로세서 : 하나 혹은 여러개의 CPU를 가진 물리적인 칩
  - 코어 : CPU의 기본 연산 장치
  - 멀티코어 : 같은 CPU내에 여러개의 계산 코어를 가지고 있는 것
  - 멀티프로세서 : 다양한 프로세서를 포함한 것

### 1.3.3 클러스터드 시스템

멀티 프로세서 시스템의 다른 종류는 클러스터드 시스템이다. 클러스터드 시스템은 멀티프로세서 시스템과 다르게 2개 또는 여러개의 개별 시스테(노드)가 합쳐진 것이다. 각각의 노드는 멀티코어 시스템이다. 각각의 시스템은 ##loosely coupled##되어있다. 우리는 클러스터의 뜻을 명확히 하지 않았다. 많은 상업 오픈소스 패키지들은 클러스터 시스템이 뭔지 그리고 왜 이것보다 나은지 씨름하고 있다. 보편적으로 대중화된 정의는 클러스터드 컴퓨터가 저장 공간을 공유하고 LAN으로 연결되어있다는 것이다.

클러스터링은 다른 시스템이 죽더라도 다른 시스템은 계속 일을 하는 높은 유효성을 보여준다. 보통 우리는 높은 유효성을 중복을 늘리면서 얻는다. 클러스터 노드에서 한 층의 클러스터 레이어를 작동한다. 각각의 노드는 하나 혹은 여러개의 노드를 감시한다. 만약 모니터하다가, 그 기계가 실패하면 모니터하던 기계가 그 권한을 가지고 그 앱을 재시작한다. 유저와 클라이언트는 오직 약간의 서비스 방해만을 느낄 뿐이다.

높은 유효성은 높은 신뢰성을 만들어낸다. 서비스를 생존하는 하드웨어의 레벨에 비레해서 계속 서비스하는 것을 ##graceful degradation##이라고 한다. 몇몇 시스템들은 ##fault tolerant##라고 한다. 왜냐하면 그들은 하나의 구성요소의 실패를 겪어도 계속 명령하기 때문이다. 이것은 실패가 포착되고 진단되는 것이 가정되어야하고 가능하다면 고칠수 있어야한다.

클러스터링은 대칭적일 수도 있고 아닐 수도 있다. 비대칭적인 클러스터링은 하나의 기계가 항상 대기하는 상태이다. 대기하는 호스트 머신은 활동중인 서버를 모니터할 뿐이다. 만약 서버가 실패한다면, 대기중인 호스트는 활동을 시작한다. 대칭적인 클러스터링은 2개 또는 더 많은 호스트들이 앱을 실행하면서 서로를 감시하고 있다. 이런 구조는 가능한 하드웨어를 모두 사용하기 때문에 효율적이다. 그러나 그것은, 하나의 앱을 더 실행할 여유가 필요하다.

클러스터가 몇몇 컴퓨터 시스템을 네트워크로 연결하면서 클러스터는 높은 성능의 컴퓨팅 환경을 제공한다. 이런 시스템들은 더욱 큰 컴퓨테이셔널 파워를 싱글 프로세서 또는 SMP 시스템보다 더 크게 지원한다. 왜냐하면 클러스터의 모든 컴퓨터에서 동시에 작동하기 때문이다. 이 앱은 반드시 클러스터에서 좋게 작동하게 쓰여야한다. 이 기술은 ##parallelization##이라고 하고 프로그램을 각각의 구성요소에서 일하게 한다. 특히 이런 앱은 문제의 일부분만을 해결하고 모든 노드의 부분합이 최종 결과에 반영되게끔 한다.

다른 형태의 병렬 클러스터는 WAN이라고 19단원에서 언급될 것이다. 병렬 클러스터는 다중 호스트가 같은 데이터에 공유된 저장소로 접근한다. 운영체제는 동시에 여러 호스트에서 데이터 접근을 지원을 부족하게 해서 우리는 새로운 앱이 필요하다. 예를 들어 오라클의 데이터 베이스가 있을 것이다. 각각의 기계는 오라클을 실행하고 소프트웨어의 층은 공유된 디스크를 따라서 접근한다. 각각의 기계는 데이터 베이스의 모든 데이터에 full access를 가지고 있다. 이런 것을 확신하기 위해서 이 시스템은 엑세스 컨트롤과 락킹을 확실히 지원한다. 이런 기능은 ##Distributed lock manager(DLM)##이라고 불린다.

클러스터 기술은 급변하고 있다. 몇몇 클러스터 제품은 클러스터에서 천개의 시스템을 지원하고 몇 마일 사이에서도 작동한다. 이런 발전은 ##Storage-area-networks(SANs)##의 발전으로 얻어졌고 11.7.4절에서 설명하겠다. 만약 앱과 그들의 데이터가 SAN에 연결되어있으면, 클러스터 소프트웨어는 SAN이 달린 어떤 호스트에서도 작동할 수 있다. 만약 호스트가 실패하면 다른 호스트가 실행한다. 데이터 베이스 클러스터에서 많은 호스트들은 같은 데이터베이스를 공유하고 성능과 믿음을 향상시켰다.

## 1.4 운영체제 명령

컴퓨터 시스템 구조와 아키텍처에 대한 기본적인 정보를 말했으니 이제는 운영체제에 대해 얘기하겠다. 운영체제는 프로그램이 작동할 수 있는 환경을 제공한다. 내부적으로 운영체제는 다양하다. 그러나 공통점은 있다. 

컴퓨터가 시작할려면 그것은 처음으로 실행할 프로그램이 있다. 말했듯이 이 시작 프로그램이 부트스트랩 프로그램이다. 보통 그것은 컴퓨터 하드웨어의 펌웨어에 있다. 그것은 모든 방향의 시스템을 CPU 레지스터와 디바이스 컨트롤러 부터 메모리 콘텐츠에서 시작한다. 부트 스트랩 프로그램은 운영체제를 어떻게 불러오는지 알아야하고 그 시스템을 실행할줄 알아야한다. 이 것을 만족하기 위해서 부트스트랩 프로그램은 반드시 운영체제 커널을 메모리에 넣어야한다. 

커널이 불러와지고 실행되면, 그것은 유저를 위해서 실행된다. 몇몇 서비스는 시스템 프로그램 밖의 커널로 부터 제공되고 ##System-daemons##에 불러와진다. 리눅스에서 첫 시스템 프로그램은 'systemd'이고 그것은 많은 daemon을 실행한다. 이 단계가 완료되면 시스템은 완벽히 부팅되고 시스템은 이벤트가 생기길 기다린다.

만약 프로세스가 실행되지 않으면, 어떤 I/O 디바이스, 어떤 유저도 반응할 수 없다. 이벤트는 대부분 인터럽트의 발생으로 신호를 받는다. 다른 형태의 인터럽트는 ##trap##이고 소프트웨어가 어떤 에러에 대해서 생기는 것이다. 특정한 요청으로 운영체제는 시스템 콜을 실행한다. 

### 1.4.1 멀티 프로그래밍과 멀티 태스킹

운영체제의 가장 주용한 점중 하나는 다양한 프로그램을 실행하는 것이다. 그러면서도 I/O 장치와 CPU를 바쁜 것은 놓지 않는다. 더욱이 유저는 여러개의 프로그램을 실행하기를 원한다. 멀티프로그래밍은 CPU의 효율을 높이고 유저가 만족하게 해준다. 이런 멀티 프로그램 시스템에서 프로그램은 프로세스라고 불린다. 

운영체제는 몇몇 프로세스를 동시에 작동한다. 운영체제는 하나의 프로세스를 고르고 작동을 시작한다. 마침내, 프로세스는 다른 일을 기다린다. 멀티프로그램 시스템이 아니면 CPU는 휴식시간이 많다. 하지만 멀티프로그램 시스템에서 운영체제는 다른 프로세스를 작동한다. 그리고 그 프로세스가 다시 멈추면, CPU는 다른 프로세스를 실행한다. 마침내 첫번째 프로세스가 대기를 멈추고 CPU로 돌아온다. 이러면서 CPU는 절대 쉬지 않게 된다.

이런 발상은 일상에서도 마찬가지다. 변호사는 한명의 고객만을 위해 일하지 않는다. 하나의 소송이 기다리는 동안 변호사는 다른 소송을 준비한다. 만약 충분한 고객이 있다면, 변호사는 절대로 쉬지 않는다.

멀티 태스킹은 논리적으로 멀티프로그래밍의 확장이다. 멀티 태스킹 시스템에서 CPU는 다양한 프로세스를 교환하면서 실행한다. 그러나 교환은 매우 빈번히 일어나면서 유저에게 빠른 반응 시간을 제공한다. 프로세스가 실행된다고 고려하고 그것은 짧은 시간동안 종료되고 I/O를 실행한다. I/O는 상호적일수 있고 즉 결과물은 유저에게 보여진다. 인풋은 유저의 키보드로 들어오고. 암만 사람이 빨리쳐도 키보드보다 느리다. 그럼으로서 이런 상호작용 인풋이 CPU를 멈추게 하는 것보다 CPU는 다른 프로세스를 빠르게 교체하는 것이다.

메모리에 몇가지 프로세스를 가지는 것은 메모리 관리가 필요하다. 이것은 9와 10장에서 다루겠다. 더불어, 만약 몇몇 프로세스가 동시에 준비되면 시스템은 어떤 프로세스를 고를지 고민해야한다. 그리고 이런 결정을 하는 것이 CPU 스케쥴링이다. 마침내, 다중 프로세스를 동시에 작동하는 것은 운영체제의 모든 단계에서 쓰인다. 이것은 계속 계속 우리가 고민하게 될 것이다.

멀티태스킹 시스템에서 운영체제는 반드시 적절한 반응시간이 보장되어야한다. 보편적인 방법은 ##virtual memory##이다. 이 기술은 프로세스가 실행중일 때 메모리안에 완벽히 없는 것이다. 이 방식의 장점은 유저가 실제 메모리보다 더 큰 프로그램을 가능하게하는 것이다. 더욱이, 그것은 메인 메모리를 크고 평평한 공간의 행렬에 넣고 논리 메모리를 유저의 관점으로 물리 메모리에서 분리하는 것이다. 이 방법은 프로그래머를 메모리 공간 제한에서 자유롭게 해주었다.

멀티프로그래밍과 멀티태스킹 시스템은 반드시 파일 시스템을 지원해야한다. 파일 시스템은 2차 저장소에 존재한다. 따라서 저장소 관리는 제공이 꼭 되어야한다. 더불어서, 시스템은 부적절한 사용을 보호해야한다. 절차적인 실행을 확실하게 하기 위해서 시스템은 반드시 프로세스 동기화와 통신을 제공해야한다. 그러면서 데드락도 피해야한다.

### 1.4.2 Dual-Mode and Multimode operation

운영체제와 유저가 하드웨어와 컴퓨터 시스템의 소프트웨어 자원을 고융하면서, 잘 디자인된 운영체제는 반드시 이상한 프로그램이 다른 프로그램을 이상하게 실행하게 하면 안된다. 이것을 확실하게 하기위해서, 시스템의 적절한 실행은 우리가 반드시 운영체제 코드와 유저 코드를 확실하게 구분하는 것이다. 이런 접근은 대부분의 커퓨터 시스템에서 적용된다.

적어도, 우리는 두가지 명령의 모드가 있다. ##User mode 와 Kernel mode##이다. ##mode bit##라고 불리는 비트는 컴퓨터의 하드웨어가 지금 어떤 모드인지 가르키기 위해서 사용된다. 모드비트와 함께, 우리는 지금 하는 일이 누구의 일인지 확실하게 구분가능하다. 만약에 유저 앱이 커널모드에게 일을 시키면 시스템 콜을 통해서 커널모드로 전환해서 요청을 완수한다.

시스템 부팅중에 하드웨어는 커널 모드로 시작한다. 운영체제는 그러면 불려오고 유저 모드에서 유저 앱을 실행한다. 트랩이나 인터럽트거 생기면, 하드웨어는 유저모드에서 커널모드로 바뀐다. 그러므로 운영체제는 원하면 언제든지 컴퓨터의 컨트롤을 얻는다. 시스템은 항상 유저 앱을 실행하기 이전에 유저 모드로 바꾼다.

명령의 듀얼 모드는 우리에게 운영체제가 잘못된 유저로부터 보호를 한다. 우리는 특권잇는 명령 같은 기계를 나쁘게 할 수 있는 명령을 정함으로서 보호한다. 하드웨어는 이 특권 명령을 오직 커널모드에서만 실행하게 한다. 만약 이게 유저모드에서 실행될려면, 하드웨어는 이 명령을 실행하지 않고 불법적이고 운영체제에서 트랩으로 처리한다.

커널모드 변경 명령은 특권 명령이다. 몇몇 예시는 I/O 컨트롤, 타이머 관리, 인터럽트 관리가 있다. 책의 전반에서 이 내용들은 나오게 될 것이다.

모드의 개념은 2가지보다 더 나뉠 수 있다. 예를 들어 인텔 프로세서는 4개의 보호 링이 있고 0번째 링은 커널 모드 3번쨰 링은 유저 모드이다.(2, 3번째는 뭐 특별한 건데 잘 안쓰인다.). 암v8시스템은  7개의 모드가 있다. 가상화를 지원하는 CPU는 별도의 모드를 지칭한다. 이 모드에서 VMM은 유저 프로세스보다 더 많은 권한을 가지고 더 적은 권한을 커널보다 가지고 있다. 

우리는 명령의 라이프 사이클을 이제 더 쉽게 이해할 수 있다. 첫번쨰 컨트롤은 명령은 커널 모드에서 실행된다. 그리고 컨트롤이 유저 앱 프로그램으로 넘어가면 모드는 유저 모드이다. 결국은, 컨트롤은 유저 시스템의 인터럽트, 트랩, 시스템 콜로 매번 바뀐다.  대부분의 운영체제들은 운영체제의 보호를 위해서 듀얼모드를 지원한다. 

시스템 콜은 유저프로그램 편에서 유저 프로그램에게 운영체제가 예약된 운영체제의 일을 실행할지 묻는 역할이다. 어떤 형태든 그것은 프로세스에게 운영체제가 일을 할지 묻는 것이다. 시스템 콜은 보통 트랩의 형태를 취하고 인터럽트 벡터에 내재된다. 이 트랩은 제너릭 트랩 명령으로 실행되면서도 몇몇 시스템은 syscall 명령을 가진다.

시스템 콜이 실행되면, 그것은 하드웨어에게 보통 소프트웨어 인터럽트로 인식받는다. 컨트롤은 인터럽트 벡터를 통해서 운영체제의 서비스 루틴으로 흘러간다. 그리고 모드 비트 또한 커널 모드로 된다. 시스템 콜 서비스 루틴은 운영체제의 일부분이다. 커널은 어떤 시스템 콜이 발생했는지 인터럽팅 명령어로 결정한다. 파라미터는 어떤 종류의 유저 프로그램이 요청하는지 알려준다. 추가적인 정보는 레지스터, 스택, 메모리를 통해서 알려진다. 

하드웨어 보호가 있으면, 그것은 모드를 위반하는 에러를 찾아낸다. 이런 에러들은 보통 운영체제에 의해서 관리된다. 만약 유저 프로그램이 불법 명령 또는 유저의 주소 공간이 아닌 메모리에 할려고 하면 하드웨어는 운영체제를 트랩한다. 트랩은 컨트롤을 인터럽트 벡터를 통해서 전달하고 인터럽트처럼 작동한다. 프로그램이 에러가 생기면 운영체제는 반드시 프로그램을 종료해야한다. 이런 상황은 유저 요청 강제 종료와 같이 제어된다. 적절한 에러메시지가 주어지면, 프로그램의 메모리는 버려진다. 메모리 덤프는 포통 파일에 쓰이고 프로그래머가 고치고 다시 프로그램을 시작하게끔한다.

### 1.4.3 타이머

우리는 운영체제가 CPU를 통해서 작동된다는 것을 안다. 우리는 유저 프로그램이 무한한 루프에 빠지고 시스템 서비스를 부르는걸 실패하고 돌아오는 것을 실패하게 해서는 안된다. 이런 것을 수행하기 위해서 타이머를 이용한다. 타이머는 컴퓨터가 특정 주기후에 인터럽트 되게 설정가능하다. 이 주기는 고쳐질수있다. 다양한 타이머는 보통 고정된 클락과 카운터에 의해서 제공된다. 운영체제는 카운터를 정한다. 매번 클락이 지나면, 카운터는 줄어든다. 그리고 카운터가 0이되면 인터럽트가 발생한다. 예를 들어서 10비트 카운터가 1밀리세컨드 클락이면 1미리세컨드에서1024미리세컨드사이에 설정가능하다.

유저에게 컨트롤을 주기전에 운영체제는 타이머가 인터럽트되게 정할수 있다. 만약 타이머가 인터럽트면, 컨트롤은 운영체제로 넘어간다. 이 것은 페이탈 에러 또는 프로그램에 더 많은 시간으 준다. 즉, 명령어는 특권있는 것이다.