# Introduction

운영체제는 컴퓨터의 하드웨어를 관리하는 소프트웨어이다. 그것은 어플리케이션 프로그램을 기본으로 제공하고 컴퓨터와 하드웨어의 중개자역할을 한다.
운영체제의 놀라운 점은 넓은 범위의 컴퓨팅 환경을 달성한다는 것이다. 운영 시스템들은 자동차, IOT, 스마트폰, 개인 컴퓨터, 기업 컴퓨터, 클라우드 컴퓨터 등 어디에나 있다.

현대 운영체제의 역할을 살펴보기 위해서, 기관과 컴퓨터 하드웨어의 구조를 이해하는 것은 중요하다. 이 것은 CPU, memory, I/O 장치, 저장소를 포함한다. 운영체제의 기본적인 책임은 자원을 프로그램에 할당하는 것이다.

운영체제는 크고 복잡하기에 조각으로 생성되고 인풋, 아웃풋, 펑션이 잘 기술된 부분으로 되어있다.

우리는 이단원에서 현대 컴퓨터 시스템의 주요 부분을 공부하고 운영체제가 제공하는 기술을 공부한다.
더불어서, 우리는 책의 여분을 도울 몇가지 단계도 도울 것이다. : 자료구조, 컴퓨팅 환경, 오픈소스, 무료 운영체제.

## Chapter Objectives

- 컴퓨터 시스템의 구성과 인터럽트의 역할을 전반적으로 설명한다.
- 현대 멀티프로세서 컴퓨터 시스템을 설명한다.
- 유저 모드에서 커널 모드로의 변환을 설명한다.
- 운영체제가 어떻게 다양한 컴퓨팅 환경에서 사용되는지 논의한다.
- 무료 오픈소스 운영체제를 소개한다.

## 1.1 운영체제는 무슨 일을 하는가
우리는 전체적인 컴퓨터 시스템에서 운영체제가 무엇을 하는지부터 알아보겠다. 컴퓨터는 크게 4가지로 나뉜다.: 하드웨어, 운영체제, 앱 프로그램, 사용자.

> 하드웨어
>> CPU, memory, IO devices : 시스템을 위한 기본적인 컴퓨팅 자원을 제공한다.

> 앱 프로그램
>> 워드프로세서, 스프레드시트, 컴파일러, 웹브라우저 : 유저의 컴퓨팅 문제를 해결하는 자원을 의미한다.

아니면 하드웨어, 소프트웨어, 데이터로서 컴퓨터 시스템을 볼수도 있다. 운영체제는 정부와도 같다. 정부처럼, 그것은 그 자체로서는 일하지 않는다. 그것은 오직 다른 프로그램이 유용하게 활용되게끔 도울 뿐이다. 더 깊게 이해하기 위해서는 우리는 두가지 관점으로 운영체제를 보아야한다. 유저와 시스템이다.

### 1.1.1 사용자 관점
컴퓨터의 사용자 관점은 어떤 인터페이스가 사용되냐에 따라 달라진다. 사용자들은 모니터, 키보드, 마우스를 포함한 랩탑 또는 PC 앞에 앉아있다. 이러한 시스템은 유저가 그것의 자원을 독점하게 만든다. 
목적은 작업(게임)을 극대화하는 것이다. 이런 경우에, 운영 체제는 ##간단한 사용##을 목적으로 만들어진다. 여기에는 퍼포먼스와 보안에 약간, ##자원의 활용도##는 신경쓰지 않는다. 

많은 사용자들이 스마트폰과 모바일 기기를 사용하는 추세이다. 이러한 기기들은 무선 기술과 연결되어있다. 모바일 컴퓨터 사용자의 인터페이스는 터치스크린이고 손가락으로 이루어진다. 그리고 애플의 시리 같은 음성인식으로도 사용된다. 

몇몇 컴퓨터들은 사용자의 관점이 전혀 고려되지 않는다. 예를 들어, 집안의 임베디드 컴퓨터와 자동차는 물론 우리가 키패드 좀 있고 지시등은 있어도, 사용자의 개입 없이 잘 작동하게끔 만든다.

### 1.1.2 시스템 관점
컴퓨터의 관점에서 운영체제는 하드웨어와 매우 친밀한 프로그램이다. 이 문맥은, 우리는 운영체제를 자원 할당자로 보는 것이다. 컴퓨터 시스템은 해결해야할 많은 문제가 있다.: CPU time, memory space, storage space, I/O devices 등등. 운영 체제는 이러한 자원의 관리자로서 일한다. 다양하고 가능한 리소스 요청 충돌을 마주하면서 운영체제는 반드시 자원을 특정 프로그램에 할당하고 컴퓨터 시스템이 효율적이고 공평하게 운영되게끔 도와야한다.

운영체제의 다른 관점은 I/O 디바이스와 유저 프로그램을 적절하게 관리해야한다. 운영체제는 Control program이다. 관리 프로그램은 유저 프로그램을 관리하고 에러와 컴퓨터의 오용을 막는다.
특히 운영과 I/O장치가 고려된다.

### 1.1.3 운영체제를 정의하는 것

이제, 당신은 #운영체제#가 많은 역할과 기능을 포함한다는 것을 보았다. 컴퓨터들은 토스터, 자동차, 배, 우주선, 집, 사업 등 어디에나 존재한다. 그들은 게임 기계, 케이블 티비, 산업 관리 시스템에도 있다.

이러한 다양성을 설명하기 위해, 우리는 컴퓨터의 역사를 돌아봐야한다. 컴퓨터는 비교적 짧은 역사를 가졌지만, 그들은 빠르게 진화했다. 컴퓨팅은 군사적 사용을 위해서 시작되었다. 암호해독, 미사일 탄도 그림, 인구 조사 등을 위해서 발전했다. 이런 초기의 컴퓨터는 공용 목적으로 진화했고, 다기능 프레임이었고 이게 운영체제의 탄생이다. 컴퓨터는 목적을 가지게 되었고, 작아졌고 수많은 사용자와 수많은 운영체제를 탄생시켰다. 

그래서 운영체제가 뭔지 알겠는가? 보통 우리는 운영체제의 완벽한 정의를 갖지 않는다.  운영체제는 그들이 쓸만한 컴퓨팅 시스템을 만드는 문제를 적절한 해결책을 위해서 존재한다. 컴퓨터 시스템의 근본적인 목적은 프로그램을 실행하고 유저 문제를 쉽게 해결하게 한다. 컴퓨터 하드웨어는 이 목적을 위해서 만들어진다. 나체의 하드웨어 혼자서는 적절한 일을 쉽게하지 못하고 이러한 것은 I/O 디바이스가 관리하는 것을 돕는다. 그러면서 자원을 할당하고 관리하는 것은 따라오게 되는 것이다. 이러한 하나하나가 뭉친게 운영체제다.

더해서, 우리는 운영체제의 정확한 범우주적인 명확한 정의는 없다. 간단한 관점은 당신이 무언가를 시켰을때 다 포함 된 것이다. 기능은 시스템을 걸쳐서 다있다. 몇몇 시스템은 작은 화면도 없을 정도로 메가 바이트보다 작고, 반면에 눈이 즐거운 윈도우는 기가바이트보다 클수있다. 더 간단한 정의는 컴퓨터에서 항상 실행중인 것이다. 이런걸 ##커널##이라고 부른다. 커널을 따라서, 프로그램은 두가지가 있다. ##시스템 프로그램##이라는 운영체제가 관련되어는 있지만 커널의 부분은 아닌 것과 시스템의 운영에 전혀 관계없는 앱 프로그램이다.

운영 체제를 만드는 문제는 점점 중요하고 복잡하고 섬세해지고 있다. 1988년에 MS사는 미국 정부에게 운영체제가 너무 많은 기능을 제공해서 앱 판매자를 죽인다고 소송걸렸다. 결과적으로 MS사는 운영 체제가 독점했고 유죄라고 판단 받았다.

오늘날, 만약 우리가 모바일 기기의 운영체제를 본다면, 우리는 다양한 기능이 운영체제를 포함하고 늘어간다는 것을 볼 수 있다. 모바일 운영체제는 보통 코어 커널 뿐아니라, 미들웨어도 포함한다. 예를 들어서 애플의 IOS와 구글의 안드로이드다. 이것은 데이터베이스, 멀티미디어, 그래픽을 지원하는 미들웨어 커널이 있다.

요약하자면, 운영체제는 항상 작동하는 커널이 있고, 미들웨어 프레임워크가 앱 개발을 쉽게하고 기능을 제공하고, 시스템 프로그램이 시스템을 돕는 것이다.

## 1.2 컴퓨터 시스템 구조

현대의 컴퓨터 시스템은 여러개의 CPU와 공유된 메모리와 컴포넌트와 다양한 디바이스 컨트롤러를 연결하는 각각의 디바이스 컨트롤러는 특적한 기기에 책임을 진다. 예를 들어서 하나의 USB 포트는 여러개의 디바이스가 연결되는 USB 허브를 연결한다. 디바이스 컨트롤러는 지역 버퍼 공간과 특별한 목적 레지스터를 유지한다. 
특히 운영체제는 ##디바이스 드라이버##를 가지고 있다. 이 디바이스 드라이버는 컨트롤러를 이해하고 운영체제가 디바이스에 일정한 인터페이스를 제공한다. CPU와 디바이스 컨트롤러는 병행으로 실행되고 메모리 사이클로 경쟁한다. 이것을 확인하기 위해서 공유된 메모리에 순서대로 접근을하고 메모리 컨트롤러는 동기화된다.

다음 하위섹션에서는, 우리는 시스템이 어떻게 작동하는지, 시스템의 3개의 관점에 집중하겠다. 우리는 인터럽트를 시작으로 CPU가 관심을 요하는 이벤트에 어떻게 경고하는지 보겠다. 그리고 스토리지 구조와 I/O구조를 보겠다.

### 1.2.1 인터럽트

특정한 컴퓨터 명령을 고려하자 : 프로그램 I/O 실행. I/O실행을 시작하기 위해서, 디바이스 드라이버는 디바이스 컨트롤러를 적절한 레지스터에 부른다. 디바이스 컨트롤러는 이런 레지스터의 콘텐츠가 어떤 헹동을 취할지 말해준다. 컨트롤러는 데이터를 디바이스에서 버퍼로 옮긴다. 그때 데이터의 전송은 완료되고 디바이스 컨트롤러는 디바이스 드라이버에게 명령이 끝났다고 말한다. 디바이스 드라이버는 그러고 운영체제의 다른 부분을 조작하고 데이터를 반환하거나 명령이 읽힌 데이터의 포인터를 반환한다. 다른 명령은 디바이스 드라이버가 "읽기 완료됨"이라는 상태 정보를 반환하거나 "디바이스 바쁨"을 반환한다. 그러나 어떻게 컨트롤러가 그 명령이 끝났다는 것을 어떻게 알것인가? ##인터럽트##가 해준다.

### 1.2.1.1 개요

하드웨어는 시스템 버스를 통해서 CPU에 시그널을 보냄으로서 인터럽트를 발생시킨다.(컴퓨터 시스템에는 다양한 시스템 버스가 있고 시스템 버스는 주요한 부품들간의 경로이다.)
인터럽트들은 다양한 목적으로 사용되고 운영체제와 하드웨어가 어떻게 작동하는지 중요한 열쇠이다.

CPU가 인터럽트일때, 그것은 행동을 멈추고 즉시 고정된 지점으로 행동한다. 이 고정된 지점은 보통 인터럽트를 위한 서비스 루틴이 저장된 시작 주소로 이동한다. 인터럽트 서비스 루틴은 완료되면, CPU는 인터럽드 당한 연산을 다시 시작한다. 

인터럽트는 컴퓨터 아키텍처에서 중요한 부분이다. 각각의 컴퓨터 디자인은 고유의 인터럽트 메커니즘이 있지만, 몇몇은 공통을 가진다. 인터럽트는 반드시 전송 조작을 적절한 인터럽트 서비스 루틴에 넣어야한다. 전송을 관리하는 가장 직관적인 방법은 인터럽트 정보를 제너릭 루틴에 부르는 것이다. 그 루틴은 특정 인터럽트 핸들러를 부를 것이다. 그러나 인터럽트는 반드시 빠르게 수행되고 자주 생길 것이다. 서비스 루틴의 포인터의 테이블은 필요한 속도를 제공하기 위해서 쓰인다. 인터럽트 루틴은 테이블로 간접적을 불리고 중간 루틴은 필요가 없다. 보통 포인터의 테이블은 low memory에 저장된다. 이런 위치는 인터럽트 서비스 루틴이 다양한 기기에 적용된다. 이 인터럽트 벡터(어레이)는 특정한 번호로 저장되있고, 인터럽트 요청이다. 운영체제에 따라서 이 구성은 다르다.

인터럽트 아키텍처는 반드시 무엇이 방해되었든 상태 정보를 저장해야한다. 그래서 그것이 이 정보를 복구할수 있기때문이다. 만약에 인터럽트 루틴이 프로세서 상태를 바꿀 필요가 있다. 예를 들어 레지스터 값을 바꾸면 그것은 반드시 현재 상태에 저장되고 그 상태를 반환하기 전에 복구되어야한다. 인터럽트가 끝난후에 저장된 복구 지점은 PC에서 불러지고 새로운 인터럽트가 생기기 전까지 생기지 않는다.

### 1.2.1.2 Implementation

기본 인터럽트 메커니즘은 다음과 같이 작동한다. CPU 하드웨어는 ##Interrupt-request line##이라는 CPU가 매 명령마다 반응하는 와이어가 있다. CPU가 컨트롤러가 시그널을 보냈는지는 이 line에서 확인하고 인터럽트 숫자를 읽고 인터럽트 벡터의 인덱스 숫자에 맞게 ##Interrupt-handler routine##으로 들어간다. 그리고는 인덱스에 맞는 일을 한다. 인터럽트 핸들러는 그것의 행동 동안 변경되는 어떤 상황도 저장하고 인터럽트의 원인을 결정하고 필요한 프로세싱을 수행하고, 상태 복구를 실행하고 #return_from_interrupt#를 실행한다. 디바이스 컨트롤러는 인터럽트를 어필하고 CPU는 인터럽트를 캣치하고 그것을 인터럽트핸들러에 실행한다. 그리고 핸들러는 디바이스를 서비싱함으로서 인터럽트를 지운다.

기본적인 인터럽트 메커니즘은 CPU가 비동기된 이벤트를 가능하게 한다. 그리고 디바이스 컨트롤러가 준비되면 반응한다. 현대의 운영체제에서 우리는 더 섬세한 인터럽트 핸틀링 기능이 필요하다.

1. 우리는 중요한 프로세싱 중에 인터럽트를 미룰 수 있는 능력이 필요하다.
2. 우리는 디바이스를 위한 인터럽트 핸들러로 보낼 효율적인 방법이 필요하다.
3. 우리는 다단계의 인터럽트가 필요하다. 즉 운영체제가 높은 우선순위의 인터럽트와 낮은 우선순위의 인터럽트를 급박함의 단계에 따라서 구분할 수 있어야 한다.

현대의 컴퓨터 하드웨어는 3가지 기능을 CPU와 #interrupt-controller-hardware#로 제공한다.
대부분의 CPU는 두가지 인터럽트 요청 라인이 있다. 하나는 #nonmaskable interrupt#인데 복구 불가능한 메모리 에러 상황을 저장한다. 두번째 인터럽트 라인은 #maskable#이다. 이 것은 CPU가 중요한 명령 단계일때 꺼지는 기능이 있다. maskable 인터럽트는 디바이스 컨트롤러에게 쓰인다.

인터럽트 메커니즘의 벡터화 목적은 단일 이너럽트 핸들러가 인터럽트의 모든 원인을 파악하고 어떤 서비스가 필요한지 도움을 주는 것이다. 실전에서는, 컴퓨터에게 인터럽트 벡터보다 사실 더 많은 디바이스가 있다. 이를 해결하는 방법은 #인터럽트 Chaining#이다. 인터럽트가 생겼을때 관련된 리스트를 필요한 서비스를 찾을때까지 찾는 것이다. 이 구조는 큰 인터럽트 테이블과 단일 인터럽트 핸들러를 보내는 비효율성등을 만든다.

인터럽트 메커니즘은 또한 인터럽트 우선 레벨의 시스템또한 기능한다. 이러한 레벨은 CPU가 낮은 우선순위 인터럽트를 마스킹 없이 무시하게 해준다. 그리고 반대로는 높은 우선순위의 인터럽트가 하위 우선순위의 동작을 선점하게 한다.

요약하자면, 인터럽트는 현대 운영체제 시스템에 사용되고 비동기 이벤트이다. 디바이스 컨트롤러와 하드웨어 손상은 인터럽트를 부른다. 이런 긴박한 일을 먼저 실행하는 것을 가능하게 하고 현대 컴퓨터는 인터럽트 우선의 시스템을 사용한다. 인터럽트가 시간에 민감하기 때문에, 효율적인 인터럽트 핸들링이 좋은 시스템 퍼포먼스를 위해서 필요하다.

### 1.2.2 Storage Structure

CPU는 메모리로부터 명령을 읽어내고 프로그램은 실행되기 위해서 메모리로 들어가야한다. 컴퓨터는 대부분의 프로그램이 다시 쓰기 가능한 메모리에서 작동된다.(RAM이라고 불린다.) 메인 메모리는 DRAM이라고 불리는 반도체 기술이다.

컴퓨터는 다른 형태의 메모리도 사용한다. 예를 들어서 첫번째 프로그램은 컴퓨터가 켜질때 돌아가는 것은 부트스트랩 프로그램이고 OS에서 로드 된다. RAM이 휘발성이고 파워가 꺼지면 정보를 잃지만 우리는 부트스트랩 프로그램을 믿고 맡길 수 없다. 대신에 다른 목적으로 컴퓨터는 EEPROM을 사용하고 펌웨어라는 자주 읽히지 않고 비휘발성을 쓴다. EEPROM은 바뀔수는 있지만 자주는 바꾸지 않는다. 더욱이 그것은 매우 느리고 자주 사용하지 않는 보통 정적인 프로그램과 데이터를 저장한다. 예를 들어서, 아이폰은 EEPROM을 시리얼 넘버와 하드웨어 정보를 저장하는데 쓴다.

모든 메모리의 형태는 바이트의 배열이다. 각각의 바이트는 고유한 주소를 가진다. 교환은 특정 메모리 주소에 load와 store 명령으로 이루어진다. load 명령어는 바이트나 워드를 메인 메모리로부터 CPU의 내부 레지스터에 옮기고 STORE는 레지스터의 값을 메인메모리로 옮긴다. 명확한 로드와 스터어외에도 CPU는 명령을 메인메모리로부터 부르고 프로그램 카운터에 저장한다.

특정한 명령-명령주기는 폰노이만 아키텍처에서 실행되고 명령은 메모리에서 그리고 인스트럭션 레지스터에 명령을 저장한다. 명령은 디코드되고 메모리로부터 가져온 피연산함수는 몇몇 내부 레지스터에 저장된다. 명령위에서 피연산자가 실행되면, 결과는 다시 메모리에 저장된다. 메모리 유닛은 메모리 주소의 흐름만을 본다는 것을 기억해라. 그것은 어떻게 그들이 생겼는지는 모른다.  우리는 메모리 주소가 어떻게 프로그램에 의해서 생겼는지는 무시하는 것이다. 우리는 오직 메모리 주소의 연속에만 관심이 있다. 

이상적으로 우리는 프로그램과 데이터가 메인 메모리에서 항상 있기를 바란다. 두가지 이유로 불가능하다.
1. 메인 메모리는 모든 프로그램을 저장하기에는 너무 작다.
2. 메인 메모리는 휘발성이고 파워가 꺼지면 사라진다.

그러므로 대부분의 컴퓨터는 ##secondary storage##를 제공한다. 2차 메모리의 필요는 큰 양의 데이터를 영구적 저장이 가능하다는 것이다. 이런 2차 저장소는 ##Hard-disk drives##와 ##Nonvolatile memory(NVM) devices##이다. 대부분의 프로그램은 2차메모리에서 저장되있다가 메모리에 로드된다. 많은 프로그램은 소스와 그들의 프로세싱의 목적지로 사용한다. 2차 저장소는 메인메모리보다 많이 느리다. 따라서 적절한 2차메모리의 관리는 11장에서 언급하겠다.

큰 관점에서, 저장소 구조는 레지스터, 메모리, 2차메모리로 구성되어있다. 다른 가능한 컴포넌트는 캐시메모리, 씨디롬, 자기 테이프가 있다. 이런 것들은 느리고 크고 특정 목표로만 쓰인다. 이런 것들을 ##tertiary stoarge##라고 부른다. 각 저장 시스템은 기본적인 자료를 부르는 방식과 이전 시간으로 부르는 기능을 제공한다. 저장소간의 차이는 속도, 크기, 휘발여부가 있을 것이다.

후에도 이런 저장소에 대해서 언급하기 위한 용어 정리를 하겠다.

- 휘발성 저장소는 메모리라고 할 것이다. 만약 특정 저장 장치(레지스터)를 의미하면 우리는 정확히 얘기하겠다.
- 비휘발성 저장소는 전원이 꺼져도 컨텐츠를 저장한다. 그것은 ##NVS##라고 부르겠다. NVS는 2차 저장소를 언급할때 많이 쓰일 것이고 두가지 형태가 있다.
  + Mechanical. 적은 에시의 저장 시스템이고 HDD, 광학 디스크, 자기 테이프가 되겠다. 
  + Electircal. FRAM, NRAM SSD같은 플래시 메모리가 되고 NVM이라고도 불린다.

완벽한 저장 시스템은 반드시 모든 요소가 밸런스에 맞게 되어야한다. 그것은 최대한 필요한 만큼 비싸고 그러면서 최대한 싸야한다. 캐시는 엑세스 시간이나 전송효율을 높이는데 큰 차이를 준다.

### 1.2.3 I/O Structure

운영체제의 코드중 큰 부분을 I/O관리에 헌신하는데 왜냐하면 시스템의 성능과 의존성의 중요성이 있다. 

이 세션을 시작할 때를 생각해보면 보편적인 목적 컴퓨터 시스템은 여러가지 디바이스를 포함하고 커먼 버스를 통해서 데이터를 주고받는다. 인터럽트 기반 I/O는 1.2.1에서 설명했고 적은 양의 데이터를 옮기는데 도움된다. 그리고 너무 큰 것을 옮기면 오버헤드가 일어난다. 이런 문제를 해결하기 위해서, ##DMA##가 이용된다. 버퍼, 포인터, 카운터를 지정하고 디바이스 컨트롤러는 데이터의 전체 블럭을 전송한다. 오직 하나의 인터럽트는 블록에서 생성되고 디바이스 드라이버가 명령이 완료되었다고 말해준다. 디바이스 컨트롤러가 이런 명령을 수행하면서 CPU는 다른 일을 한다.

몇몇 하이엔드 시스템은 버스 아키텍처보다는 스위치를 사용하기도 한다. 이런 시스템에서는 여러개의 컴포넌트가 병행으로 대화한다. 이런 경우에 DMA는 더욱 효과적이다.


## 1.3 컴퓨터 시스템 아키텍처

앞서 1.2절에서, 우리는 컴퓨터 시스템의 전형적인 구조를 보았다. 컴퓨터 시스템은 여러가지 방식으로 구성될 수 있고 우리는 공통 목적의 프로세서를 분류화 할 수 있다.

### 1.3.1 싱글 프로세서 시스템

수년전, 많은 컴퓨터는 하나의 단일 프로세싱 코어를 가진 CPU를 가진 싱글 프로세서였다. 코어는 명령을 실행하고과 데이터를 저장하는 구성요소이다. 
하나의 메인 CPU는 명령어 세트를 실행하는 것이 가능하다. 이러한 시스템들은 특별한 목적을 가진 프로세서이다. 그들은 디스크, 키보드, 그래픽 컨트롤러 같은 특정 디바이스를 위한 프로세서일수도있다.

특정한 목적을 가진 프로세서들은 제한된 명령어 세트에서 작동하고 프로세스를 실행하지는 않는다. 가끔 그들은 운영체제에 의해서 관리되고, 운영체제는 그들에게 다음 작업에 대한 정보를 보내고 그들의 상태를 관찰한다. 예를 들어 디스크 컨트롤러 마이크로프로세서는 CPU로 부터 명령을 받고 그들의 디스크 큐와 스케줄링 알고리즘을 실행한다. 이런 것들은 메인 시피유의 디스크 스케쥴링 오버헤드를 경감시킨다. PC는 CPU로 키보드의 타닥을 변환해서 보내는 마이크로 프로세서가 있다. 다른 시스템이나 환경에서 특정 목적 프로세서는 낮은 레벨의 구성요소로서 하드웨어에 들어간다. 운영체제는 다른 프로세서와 소통을 하지 않는다. 그들은 독자적으로 그들의 일을 한다. 특별한 목적을 가진 마이크로 프로세서는 일반적이고 멀티프로세서라고 하지는 않는다. 만약 오직 하나의 범용 CPU가 하나만 있으면 그건 싱글 프로세서 시스템이다. 정의에 따르면 현대의 컴퓨터 시스템들은 싱글 프로세서 시스템이다.

### 1.3.2 멀티 프로세서 시스템

현대의 컴퓨터들은 모바일부터 서버까지 멀티 프로세서 시스템이 대부분이다. 전통적으로 이러한 시스템들은 두개 혹은 더 많은 프로세서를 가지고 있고 각각은 싱글 코어 CPU이다. 프로세서는 컴퓨터 버스를 공유하고 가끔은 클락, 메모리, 주변 기기를 공유한다. 멀티프로세서의 장점은 향상된 처리량이다. 즉, 프로세서의 수를 늘림으로서, 우리는 많은 일을 더 적은 시간동안 할 수 있다. 물론 N개의 프로세서는 N배의 효율보다는 적다. 많은 프로세서가 협업할때, 일부 오버헤드가 모든 일에서 생기기 때문이다. 이 오버헤드와 공유된 자원에 대한 논쟁은 추가적인 프로세서의 예상된 이득을 줄인다.

가장 일반적인 멀티프로세서 시스템은 ##Symmetric multiprocessing(SMP)##이라는 각각의 동료 CPU프로세서가 운영체제 기능과 유저 프로세서를 모두 처리하는 것이다. 각각의 대칭 CPU 프로세서는 그들의 레지스터를 개인, 로컬 캐시로서 가지고 있다. 그러나 모든 프로세서는 시스템 버스를 통해서 물리적인 메모리를 공유하고 있다.

이 모델의 장점은 여러개의 프로세서가 동시에 작동한다는 것이다. N의 프로세스가 N의 CPU에서 일하는 것이다. 그러나 CPU가 분리되면서 하나는 부하가 걸리면서 하나는 휴식할 수도 있다. 이런 비효율성은 프로세서가 공통적인 자료구조를 공유하는 것으로 회피할 수 있다. 멀티프로세서 시스템은 프로세스와 자원을 다양한 프로세서간에 동적으로 공유되게하고 프로세서의 부담을 줄인다. 이런 것은 5장과 6장에서 자세히 언급하겠다.

멀티프로세서의 정의는 시간을 걸쳐서 진화했고 이제 멀티코어 시스템을 포함한다. 멀티코어 시스템들은 하나의 싱글 코어 멀티칩보다 효율적이다. 왜냐하면 칩 안의 통신이 칩 간의 통신보다 빠르기 때문이다. 멀티 코어를 가진 하나의 칩은 여러개의 칩보다 훨씬 적은 파워를 소비하고 랩탑이나 모바일 기기에 중요한 문제이다. 

멀티 코어 구조는 각각의 코어에 Level1의 L1캐시라는 독립 캐시를 가지고 있고 코어간의 공유하는 Level2의 L2 캐시라는 공유 캐시또한 가지고 있다. 대부분의 아키텍처는 이런 방법을 택해서 지역과 공유된 캐시를 가지게했다. 지역 레벨이 낮은 캐시는 보통 작고 윗단의 공유 캐시보다 빠르게 설계된다.
이런 구조적인 성질들은 운영체제 디자이너, 앱 개발자가 효율적인 프로세싱 코어를 만들도록 노력하게 했고 4장에서 보게될 것이다. 가상적으로 모든 현대 운영체제는 멀티코어 SMP 시스템을 지원한다.

추가적인 CPU는 컴퓨팅 파워를 높였다. 그러나 말했듯이, 너무 많은 CPU가 추가 되고 시스템 버스의 경쟁이 병목현상을 만들고 성능이 떨어지기 시작했다. 다른 방안으로 제공된 방법은 각각의 CPU에 그들의 지역 메모리를 작고 빠른 로컬 버스로 각각 연결하는 것이다. CPU는 공유된 시스템 연결로 모든 CPU가 하나의 물리적인 주소를 공유한다. 이런 방법은 ##Non-uniform memory access or NUMA##라고 불린다. 이 장점은 CPU가 그것의 지역 메모리에 접근하는 것이 빨라지고 시스템 연결간에 경쟁이 사라지게했다. 그러므로 NUMA 시스템은 프로세서가 더 추가되게 했다.

NUMA의 잠재적인 약점은 CPU가 시스템 내부 연결을 통해서 멀리 있는 메모리에 접근해서 생긴 증가된 지연시간이다. 다른 말로 CPU0은 CPU3의 메모리에 CPU0의 지역 메모리보다 빠르게 접근 할 수 없고 결국은 느려진다는 것이다. 운영체제는 CPU 스케쥴링과 메모리 관리를 조심스럽게 함으로서 이런 NUMA의 단점을 극복했고 5.5.2와 10.5.4에서 자세히 얘기하겠다. NUMA 시스템은 많은 수의 프로세서가 상주하게끔 하기 때문에, 그들은 서버에서도 인기가 늘어나고 고사양 컴퓨팅 시스템에서도 각광 받고 있다.

> 컴퓨팅 시스템 구성요소의 정의
  - CPU : 명령을 실행하는 하드웨어
  - 프로세서 : 하나 혹은 여러개의 CPU를 가진 물리적인 칩
  - 코어 : CPU의 기본 연산 장치
  - 멀티코어 : 같은 CPU내에 여러개의 계산 코어를 가지고 있는 것
  - 멀티프로세서 : 다양한 프로세서를 포함한 것

### 1.3.3 클러스터드 시스템

멀티 프로세서 시스템의 다른 종류는 클러스터드 시스템이다. 클러스터드 시스템은 멀티프로세서 시스템과 다르게 2개 또는 여러개의 개별 시스테(노드)가 합쳐진 것이다. 각각의 노드는 멀티코어 시스템이다. 각각의 시스템은 ##loosely coupled##되어있다. 우리는 클러스터의 뜻을 명확히 하지 않았다. 많은 상업 오픈소스 패키지들은 클러스터 시스템이 뭔지 그리고 왜 이것보다 나은지 씨름하고 있다. 보편적으로 대중화된 정의는 클러스터드 컴퓨터가 저장 공간을 공유하고 LAN으로 연결되어있다는 것이다.

클러스터링은 다른 시스템이 죽더라도 다른 시스템은 계속 일을 하는 높은 유효성을 보여준다. 보통 우리는 높은 유효성을 중복을 늘리면서 얻는다. 클러스터 노드에서 한 층의 클러스터 레이어를 작동한다. 각각의 노드는 하나 혹은 여러개의 노드를 감시한다. 만약 모니터하다가, 그 기계가 실패하면 모니터하던 기계가 그 권한을 가지고 그 앱을 재시작한다. 유저와 클라이언트는 오직 약간의 서비스 방해만을 느낄 뿐이다.

높은 유효성은 높은 신뢰성을 만들어낸다. 서비스를 생존하는 하드웨어의 레벨에 비레해서 계속 서비스하는 것을 ##graceful degradation##이라고 한다. 몇몇 시스템들은 ##fault tolerant##라고 한다. 왜냐하면 그들은 하나의 구성요소의 실패를 겪어도 계속 명령하기 때문이다. 이것은 실패가 포착되고 진단되는 것이 가정되어야하고 가능하다면 고칠수 있어야한다.

클러스터링은 대칭적일 수도 있고 아닐 수도 있다. 비대칭적인 클러스터링은 하나의 기계가 항상 대기하는 상태이다. 대기하는 호스트 머신은 활동중인 서버를 모니터할 뿐이다. 만약 서버가 실패한다면, 대기중인 호스트는 활동을 시작한다. 대칭적인 클러스터링은 2개 또는 더 많은 호스트들이 앱을 실행하면서 서로를 감시하고 있다. 이런 구조는 가능한 하드웨어를 모두 사용하기 때문에 효율적이다. 그러나 그것은, 하나의 앱을 더 실행할 여유가 필요하다.

클러스터가 몇몇 컴퓨터 시스템을 네트워크로 연결하면서 클러스터는 높은 성능의 컴퓨팅 환경을 제공한다. 이런 시스템들은 더욱 큰 컴퓨테이셔널 파워를 싱글 프로세서 또는 SMP 시스템보다 더 크게 지원한다. 왜냐하면 클러스터의 모든 컴퓨터에서 동시에 작동하기 때문이다. 이 앱은 반드시 클러스터에서 좋게 작동하게 쓰여야한다. 이 기술은 ##parallelization##이라고 하고 프로그램을 각각의 구성요소에서 일하게 한다. 특히 이런 앱은 문제의 일부분만을 해결하고 모든 노드의 부분합이 최종 결과에 반영되게끔 한다.

다른 형태의 병렬 클러스터는 WAN이라고 19단원에서 언급될 것이다. 병렬 클러스터는 다중 호스트가 같은 데이터에 공유된 저장소로 접근한다. 운영체제는 동시에 여러 호스트에서 데이터 접근을 지원을 부족하게 해서 우리는 새로운 앱이 필요하다. 예를 들어 오라클의 데이터 베이스가 있을 것이다. 각각의 기계는 오라클을 실행하고 소프트웨어의 층은 공유된 디스크를 따라서 접근한다. 각각의 기계는 데이터 베이스의 모든 데이터에 full access를 가지고 있다. 이런 것을 확신하기 위해서 이 시스템은 엑세스 컨트롤과 락킹을 확실히 지원한다. 이런 기능은 ##Distributed lock manager(DLM)##이라고 불린다.

클러스터 기술은 급변하고 있다. 몇몇 클러스터 제품은 클러스터에서 천개의 시스템을 지원하고 몇 마일 사이에서도 작동한다. 이런 발전은 ##Storage-area-networks(SANs)##의 발전으로 얻어졌고 11.7.4절에서 설명하겠다. 만약 앱과 그들의 데이터가 SAN에 연결되어있으면, 클러스터 소프트웨어는 SAN이 달린 어떤 호스트에서도 작동할 수 있다. 만약 호스트가 실패하면 다른 호스트가 실행한다. 데이터 베이스 클러스터에서 많은 호스트들은 같은 데이터베이스를 공유하고 성능과 믿음을 향상시켰다.

## 1.4 운영체제 명령

컴퓨터 시스템 구조와 아키텍처에 대한 기본적인 정보를 말했으니 이제는 운영체제에 대해 얘기하겠다. 운영체제는 프로그램이 작동할 수 있는 환경을 제공한다. 내부적으로 운영체제는 다양하다. 그러나 공통점은 있다. 

컴퓨터가 시작할려면 그것은 처음으로 실행할 프로그램이 있다. 말했듯이 이 시작 프로그램이 부트스트랩 프로그램이다. 보통 그것은 컴퓨터 하드웨어의 펌웨어에 있다. 그것은 모든 방향의 시스템을 CPU 레지스터와 디바이스 컨트롤러 부터 메모리 콘텐츠에서 시작한다. 부트 스트랩 프로그램은 운영체제를 어떻게 불러오는지 알아야하고 그 시스템을 실행할줄 알아야한다. 이 것을 만족하기 위해서 부트스트랩 프로그램은 반드시 운영체제 커널을 메모리에 넣어야한다. 

커널이 불러와지고 실행되면, 그것은 유저를 위해서 실행된다. 몇몇 서비스는 시스템 프로그램 밖의 커널로 부터 제공되고 ##System-daemons##에 불러와진다. 리눅스에서 첫 시스템 프로그램은 'systemd'이고 그것은 많은 daemon을 실행한다. 이 단계가 완료되면 시스템은 완벽히 부팅되고 시스템은 이벤트가 생기길 기다린다.

만약 프로세스가 실행되지 않으면, 어떤 I/O 디바이스, 어떤 유저도 반응할 수 없다. 이벤트는 대부분 인터럽트의 발생으로 신호를 받는다. 다른 형태의 인터럽트는 ##trap##이고 소프트웨어가 어떤 에러에 대해서 생기는 것이다. 특정한 요청으로 운영체제는 시스템 콜을 실행한다. 

### 1.4.1 멀티 프로그래밍과 멀티 태스킹

운영체제의 가장 주용한 점중 하나는 다양한 프로그램을 실행하는 것이다. 그러면서도 I/O 장치와 CPU를 바쁜 것은 놓지 않는다. 더욱이 유저는 여러개의 프로그램을 실행하기를 원한다. 멀티프로그래밍은 CPU의 효율을 높이고 유저가 만족하게 해준다. 이런 멀티 프로그램 시스템에서 프로그램은 프로세스라고 불린다. 

운영체제는 몇몇 프로세스를 동시에 작동한다. 운영체제는 하나의 프로세스를 고르고 작동을 시작한다. 마침내, 프로세스는 다른 일을 기다린다. 멀티프로그램 시스템이 아니면 CPU는 휴식시간이 많다. 하지만 멀티프로그램 시스템에서 운영체제는 다른 프로세스를 작동한다. 그리고 그 프로세스가 다시 멈추면, CPU는 다른 프로세스를 실행한다. 마침내 첫번째 프로세스가 대기를 멈추고 CPU로 돌아온다. 이러면서 CPU는 절대 쉬지 않게 된다.

이런 발상은 일상에서도 마찬가지다. 변호사는 한명의 고객만을 위해 일하지 않는다. 하나의 소송이 기다리는 동안 변호사는 다른 소송을 준비한다. 만약 충분한 고객이 있다면, 변호사는 절대로 쉬지 않는다.

멀티 태스킹은 논리적으로 멀티프로그래밍의 확장이다. 멀티 태스킹 시스템에서 CPU는 다양한 프로세스를 교환하면서 실행한다. 그러나 교환은 매우 빈번히 일어나면서 유저에게 빠른 반응 시간을 제공한다. 프로세스가 실행된다고 고려하고 그것은 짧은 시간동안 종료되고 I/O를 실행한다. I/O는 상호적일수 있고 즉 결과물은 유저에게 보여진다. 인풋은 유저의 키보드로 들어오고. 암만 사람이 빨리쳐도 키보드보다 느리다. 그럼으로서 이런 상호작용 인풋이 CPU를 멈추게 하는 것보다 CPU는 다른 프로세스를 빠르게 교체하는 것이다.

메모리에 몇가지 프로세스를 가지는 것은 메모리 관리가 필요하다. 이것은 9와 10장에서 다루겠다. 더불어, 만약 몇몇 프로세스가 동시에 준비되면 시스템은 어떤 프로세스를 고를지 고민해야한다. 그리고 이런 결정을 하는 것이 CPU 스케쥴링이다. 마침내, 다중 프로세스를 동시에 작동하는 것은 운영체제의 모든 단계에서 쓰인다. 이것은 계속 계속 우리가 고민하게 될 것이다.

멀티태스킹 시스템에서 운영체제는 반드시 적절한 반응시간이 보장되어야한다. 보편적인 방법은 ##virtual memory##이다. 이 기술은 프로세스가 실행중일 때 메모리안에 완벽히 없는 것이다. 이 방식의 장점은 유저가 실제 메모리보다 더 큰 프로그램을 가능하게하는 것이다. 더욱이, 그것은 메인 메모리를 크고 평평한 공간의 행렬에 넣고 논리 메모리를 유저의 관점으로 물리 메모리에서 분리하는 것이다. 이 방법은 프로그래머를 메모리 공간 제한에서 자유롭게 해주었다.

멀티프로그래밍과 멀티태스킹 시스템은 반드시 파일 시스템을 지원해야한다. 파일 시스템은 2차 저장소에 존재한다. 따라서 저장소 관리는 제공이 꼭 되어야한다. 더불어서, 시스템은 부적절한 사용을 보호해야한다. 절차적인 실행을 확실하게 하기 위해서 시스템은 반드시 프로세스 동기화와 통신을 제공해야한다. 그러면서 데드락도 피해야한다.

### 1.4.2 Dual-Mode and Multimode operation

운영체제와 유저가 하드웨어와 컴퓨터 시스템의 소프트웨어 자원을 고융하면서, 잘 디자인된 운영체제는 반드시 이상한 프로그램이 다른 프로그램을 이상하게 실행하게 하면 안된다. 이것을 확실하게 하기위해서, 시스템의 적절한 실행은 우리가 반드시 운영체제 코드와 유저 코드를 확실하게 구분하는 것이다. 이런 접근은 대부분의 커퓨터 시스템에서 적용된다.

적어도, 우리는 두가지 명령의 모드가 있다. ##User mode 와 Kernel mode##이다. ##mode bit##라고 불리는 비트는 컴퓨터의 하드웨어가 지금 어떤 모드인지 가르키기 위해서 사용된다. 모드비트와 함께, 우리는 지금 하는 일이 누구의 일인지 확실하게 구분가능하다. 만약에 유저 앱이 커널모드에게 일을 시키면 시스템 콜을 통해서 커널모드로 전환해서 요청을 완수한다.

시스템 부팅중에 하드웨어는 커널 모드로 시작한다. 운영체제는 그러면 불려오고 유저 모드에서 유저 앱을 실행한다. 트랩이나 인터럽트거 생기면, 하드웨어는 유저모드에서 커널모드로 바뀐다. 그러므로 운영체제는 원하면 언제든지 컴퓨터의 컨트롤을 얻는다. 시스템은 항상 유저 앱을 실행하기 이전에 유저 모드로 바꾼다.

명령의 듀얼 모드는 우리에게 운영체제가 잘못된 유저로부터 보호를 한다. 우리는 특권잇는 명령 같은 기계를 나쁘게 할 수 있는 명령을 정함으로서 보호한다. 하드웨어는 이 특권 명령을 오직 커널모드에서만 실행하게 한다. 만약 이게 유저모드에서 실행될려면, 하드웨어는 이 명령을 실행하지 않고 불법적이고 운영체제에서 트랩으로 처리한다.

커널모드 변경 명령은 특권 명령이다. 몇몇 예시는 I/O 컨트롤, 타이머 관리, 인터럽트 관리가 있다. 책의 전반에서 이 내용들은 나오게 될 것이다.

모드의 개념은 2가지보다 더 나뉠 수 있다. 예를 들어 인텔 프로세서는 4개의 보호 링이 있고 0번째 링은 커널 모드 3번쨰 링은 유저 모드이다.(2, 3번째는 뭐 특별한 건데 잘 안쓰인다.). 암v8시스템은  7개의 모드가 있다. 가상화를 지원하는 CPU는 별도의 모드를 지칭한다. 이 모드에서 VMM은 유저 프로세스보다 더 많은 권한을 가지고 더 적은 권한을 커널보다 가지고 있다. 

우리는 명령의 라이프 사이클을 이제 더 쉽게 이해할 수 있다. 첫번쨰 컨트롤은 명령은 커널 모드에서 실행된다. 그리고 컨트롤이 유저 앱 프로그램으로 넘어가면 모드는 유저 모드이다. 결국은, 컨트롤은 유저 시스템의 인터럽트, 트랩, 시스템 콜로 매번 바뀐다.  대부분의 운영체제들은 운영체제의 보호를 위해서 듀얼모드를 지원한다. 

시스템 콜은 유저프로그램 편에서 유저 프로그램에게 운영체제가 예약된 운영체제의 일을 실행할지 묻는 역할이다. 어떤 형태든 그것은 프로세스에게 운영체제가 일을 할지 묻는 것이다. 시스템 콜은 보통 트랩의 형태를 취하고 인터럽트 벡터에 내재된다. 이 트랩은 제너릭 트랩 명령으로 실행되면서도 몇몇 시스템은 syscall 명령을 가진다.

시스템 콜이 실행되면, 그것은 하드웨어에게 보통 소프트웨어 인터럽트로 인식받는다. 컨트롤은 인터럽트 벡터를 통해서 운영체제의 서비스 루틴으로 흘러간다. 그리고 모드 비트 또한 커널 모드로 된다. 시스템 콜 서비스 루틴은 운영체제의 일부분이다. 커널은 어떤 시스템 콜이 발생했는지 인터럽팅 명령어로 결정한다. 파라미터는 어떤 종류의 유저 프로그램이 요청하는지 알려준다. 추가적인 정보는 레지스터, 스택, 메모리를 통해서 알려진다. 

하드웨어 보호가 있으면, 그것은 모드를 위반하는 에러를 찾아낸다. 이런 에러들은 보통 운영체제에 의해서 관리된다. 만약 유저 프로그램이 불법 명령 또는 유저의 주소 공간이 아닌 메모리에 할려고 하면 하드웨어는 운영체제를 트랩한다. 트랩은 컨트롤을 인터럽트 벡터를 통해서 전달하고 인터럽트처럼 작동한다. 프로그램이 에러가 생기면 운영체제는 반드시 프로그램을 종료해야한다. 이런 상황은 유저 요청 강제 종료와 같이 제어된다. 적절한 에러메시지가 주어지면, 프로그램의 메모리는 버려진다. 메모리 덤프는 포통 파일에 쓰이고 프로그래머가 고치고 다시 프로그램을 시작하게끔한다.

### 1.4.3 타이머

우리는 운영체제가 CPU를 통해서 작동된다는 것을 안다. 우리는 유저 프로그램이 무한한 루프에 빠지고 시스템 서비스를 부르는걸 실패하고 돌아오는 것을 실패하게 해서는 안된다. 이런 것을 수행하기 위해서 타이머를 이용한다. 타이머는 컴퓨터가 특정 주기후에 인터럽트 되게 설정가능하다. 이 주기는 고쳐질수있다. 다양한 타이머는 보통 고정된 클락과 카운터에 의해서 제공된다. 운영체제는 카운터를 정한다. 매번 클락이 지나면, 카운터는 줄어든다. 그리고 카운터가 0이되면 인터럽트가 발생한다. 예를 들어서 10비트 카운터가 1밀리세컨드 클락이면 1미리세컨드에서1024미리세컨드사이에 설정가능하다.

유저에게 컨트롤을 주기전에 운영체제는 타이머가 인터럽트되게 정할수 있다. 만약 타이머가 인터럽트면, 컨트롤은 운영체제로 넘어간다. 이 것은 페이탈 에러 또는 프로그램에 더 많은 시간으 준다. 즉, 명령어는 특권있는 것이다.

## 1.5 리소스 관리

운영체제는 **리소스 관리자**라고도 불린다. 시스템의 CPU, 메모리 공간, 파일 공간, I/O 장치에서 운영체제는 반드시 리소스를 관리해야한다.

### 1.5.1 프로세스 관리

프로그램은 CPU가 명령을 실행하기 전까지 아무런 행동도 하지 않는다. 프로그램이 동작중이면, 말했듯이 프로세스이다. 컴파일러 같은 프로그램은 프로세스이고 워드 프로세서 또한 프로세스이다. 비슷하게, SNS 앱또한 프로세스이다.  이제 프로세스는 프로그램이 실행중인 프로세스의 인스턴스라고 생각하면된다. 챕터 3에서 말하듯이, 프로세스가 하위 프로세스를 동시에 실행하게 시스템 콜이 허락한다. 

프로세스는 CPU 시간, 메모리, 파일, I/O 장치 같은 일부 자원을 필요로 한다. 이런 자원은 프로세스가 동작하는 동안 할당된다. 더불어 다양한 물리/논리적 자원이 프로세스가 생성되었을때 할되고 다양한 초기화 데이터가 지나다닌다. 예를 들어, 웹 페이지의 내용을 띄워주는 웹 브라우저 프로세스를 생각해보자. 이 프로세스는 URL을 입력으로 주고 적절한 명령을 실행하고 원하는 정보를 스크린에 띄워준다. 프로세스가 종료되었을때, 운영 체제는 어떤 재사용 가능한 자원을 다시 정의한다.

우리는 프로그램 자체는 프로세스가 아니라는 것을 강조한다. 프로그램은 디스크의 저장된 자료라는 수동적인 집단이고 프로세스는 활동적인 집단이다. 싱글 쓰레드 프로세스는 하나의 프로그램 카운터가 있다. 이 프로세스의 행동은 일련적일 것이다. CPU는 프로세스의 하나의 명령을 차례로 할것이다. 그리고 언제든지 하나의 명령은 프로세스의 편에서 실행된다. 비록, 두개의 프로세스가 같은 프로그램에 연관되어도 그들은 두개의 분리된 두 개의 분리된 실행 절차로 고려된다. 멀티쓰레드 프로세스는 다양한 프로그램 카운터를 가지지만, 각각은 주어진 쓰레드의 다음 명령만을 가르칠 뿐이다.

프로세스는 시스템에서 일의 단위요소이다. 시스템은 프로세스의 집단을 포함하고 몇몇은 운영체제 프로세스이고 나머지는 유저 프로세스이다. 모든 프로세스는 잠재적으로 하나의 CPU에서 concurrently 작동하거나 여러개의 CPU에서 parallel하게 작동한다. 운영체제는 다음과 같은 활동을 프로세스 관리에서 한다.

- 유저, 시스템 프로세스를 만들거나 삭제한다.
- CPU에서 프로세스와 쓰레드를 스케쥴링한다.
- 프로세스를 재시작하거나 멈춘다.
- 프로세스 동기화 메커니즘을 제공한다.
- 프로세스 통신 메커니즘을 제공한다.

### 1.5.2 메모리 관리

메인 메모리는 현대 컴퓨터 시스템의 중심이라 할 수 있다. 메인 메모리는 큰 바이트의 행렬이고, 사이즈는 정말 크다. 각각의 바이트는 그것의 고유한 주소를 가지고 있다. 메인 메모리는 CPU에 의해서 공유되는 빠르게 접근가능한 레포지토리이다. CPU는 메인 메모리로부터 명령을 읽고 가져오고 메인 메모리로부터 데이터 페치 사이클 동안 데이터를 읽거나 쓴다.

미리 말했듯이, 메인 메모리는 CPU가 직접 지시하고 접근할 수 있는 유일한 큰 저장 장치이다. 예를 들어, 디스크로부터 CPU에서 프로세스 데이터, 이 데이터는 반드시 CPU가 만든 I/O 콜로부터만 전송될 수 있다. 비슷하게, 명령은 반드시 CPU가 실행되기 위해서 메모리 속에 있어야한다.

프로그램이 실행되면, 그것은 반드시 절대적인 주소에 매핑되고 메모리로부터 불러와져야한다. 프로그램이 실행되면 그것은 프로그램 명령과 메모리에 절대적인 주소가 생성된 데이터에 접근한다.  결국, 프로그램은 종료되고 그것의 메모리 공간은 사용가능하게 선언되고, 다음 프로그램이 불러와져서 실행된다.

이런 CPU의 효율성과 컴퓨터의 반응 속도를 높이기 위해서, 커퓨터는 반드시 몇가지 프로그램을 메모리에 저장해두어야한다. 많은 방식이 사용되고 있다. 이런 방식들은 다양한 접근을 반영하고 상황에 따라서 효과가 다양하다. 특정 시스템을 위해서 메모리 관리를 선택하는 것은 우리가 반드시 다양한 요소에 책임을 져야한다. 특히 시스템의 하드웨어 디자인이다. 각각의 알고리즘은 그것의 하드웨어 지원이 필요하다.

운영체제는 메모리 관리를 위해서 다음과 같은 책임이 있다.

- 어떤 부분의 메모리가 현재 사용되고 어떤 프로세스가 그들을 사용하는지 추적한다.
- 메모리 공간을 필요한 만큼 할당하고 해제하는 것
- 어떤 프로세스와 데이터가 메모리에서 벗어나고 들어올지 결정하는 것이다.

### 1.5.3 파일 시스템 관리

컴퓨터 시스템이 사용자에게 편리하기 위해서, 운영 체제는 정보 저장의 동일하고 논리적인 관점을 제공한다. 운영체제는 파일이라는 논리적인 저장 유닛을 물리적 저장공간에서 추출한다. 운영체제는 파일을 물리적인 미디어에 매핑하고 이런 파일을 저장 공간을 통해서 접근한다.

파일 관리는 운영체제에서 가장 눈에 띄는 구성요소이다. 컴퓨터는 정보를 다양한 물리적인 미디어에 저장한다. 2차 저장공간이 가장 일반적이나 3차 저장 공간 또한 가능은 하다. 각각의 미디어는 그들의 특성과 물리적인 구성을 가지고 있다. 대부분은 디바이스에 의해서 관리된다. 이런 특성들은 접근 속도, 용량, 데이터 전송 비율, 접근 방법(sequential or random)이 있다.

파일은 생성자가 정의한 관련있는 정보의 집합이다. 일반적으로, 파일은 프로그램과 데이터를 대표한다. 파일은 형식이 자유롭고(텍스트 파일), 또는 명확하게 규정될 수도 있다.(mp3 파일). 정확히는 파일의 개념은 하나이다.

운영체제는 추상적인 파일의 개념을 거대한 공간에서 관리한다. 더불어서, 파일들은 보통 쉽게 이용되기 위해서 디렉토리에서 구성된다. 결론적으로, 다양한 유저들이 파일에 접근할수 있고, 어떤 유저가 접근하고 어떻게 유저가 접근하는지 정의한느 것이 이상적이다.

운영체제는 파일 시스템 관리를 위해서 다음과 같은 책임이 있다.

- 파일 생성과 삭제
- 파일을 구성하기 위한 디렉토리 생성과 삭제
- 파일과 디렉토리 관리를 위한 기초요소 지원
- 파일을 저장공간에 매핑
- 안정적인(비휘발성) 저장 미디어에 파일을 백업하기

### 1.5.4 매스 스토리지 관리

우리가 봤듯이 컴퓨터 시스템은 메인 메모리 지원을 위해서 2차 저장공간을 지원한다. 대부분의 현대 컴퓨터 시스템은 HDD와 NVM 장치를 프로그램과 데이터를 위한 저장 미디어로 사용한다. 대부분의 프로그램- 컴파일러, 웹브라우저, 워드 프로세서, 게임들은 이런 디바이스에 저장되어있다. 프로그램은 그들의 프로세싱의 원천과 목적지로서 동시에 쓰인다. 따라서 적절한 2차 저장 공간의 관리는 컴퓨터 시스템에서 중요하다. 운영체제는 2차 저장공간 관리를 위해서 다음과 같은 책임이 있다.

- 마운팅과 언마운팅
- 무료한 공간 관리
- 공간 할당
- 디스크 스케쥴링
- 파편화
- 보호

2차 저장공간은 자주 쓰이고 넓게 쓰이기 때문에, 효율적으로 사용되어야만 한다. 컴퓨터의 명령 전체 속도는 2차 저장 시스템과 그것을 관리하는 알고리즘에 전적으로 달려있다.

같은 방법으로, 2차 저장공간보다 느리고 낮은 비용의 방법도 있다. 디스크 데이터의 백업, 가끔 쓰이는 데이터의 공간, 오래동안 기록된 공간이 있을 것이다. 자기 테이프 드라이브와 그들의 테이프와 씨디, 블루레이 드라이버는 3차 저장공간의 전형적인 예시이다.

3차 저장공간은 시스템 성능에 중요하지 않지만, 역시나 관리되어야 한다. 몇몇 운영 체제는 이런 일을 실행하고, 몇몇은 3차 저장소 관리를 앱 프로그램에 맡긴다. 운영체제가 제공하는 몇몇 기능은 디바이스에 바운팅과 언마운팅을 포함하고, 프로세스에 의한 특정한 목적으로 디바이스에 할당과 해제를 하고 2차 저장공간에서 3차 저장공간으로 데이터를 옮긴다.

### 1.5.5 캐시 관리

**캐싱**은 컴퓨터 시스템에서 중요한 방법이다. 정보는 보통 몇몇 저장 시스템에 저장된다. 그것이 사용이되면, 그것은 임시 저장소인 캐시라는 저장이 빠른 공간에 복사된다. 우리가 정보의 일부분이 필요하면, 우리는 우선 캐시에 있는지를 확인한다. 만약에 있다면 정보는 곧장 캐시로부터 사용된다. 만약 그렇지 않다면, 우리는 원본으로부터 정보를 사용하고, 그것을 조만간 다시 필요할거라고 생각하고 캐시에 둔다.

더불어서 내부 프로그래머블 레지스터는 메인 메모리를 위한 빠른 캐시를 제공한다. 프로그래머는 레지스터 할당과 레지스터 교체 알고리즘으로 정보가 메인메모리에 저장될지 레지스터에 유지될지 결정한다.

다른 캐시는 하드웨어에서 작동한다. 예를 들어 대부분의  시스템은 다음 명령을 저장하는 명령캐시가 있다. 이 캐시가 없다면 CPU는 명령이 메인 메모리로부터 가져오는 동안 몇 사이클을 기다려야한다. 비슷한 이유로, 대부분의 시스템들은 하나 또는 높은 속도의 데이터 케시가 메모리 계층에 있다. 우리는 이런 하드웨어만 있는 캐시를 다루지 않을 것이다. 이것은 운영체제 밖의 일이기 때문이다.

캐시는 사이즈가 한정되어 있어서, 캐시 관리는 중요한 디자인 문제이다. 캐시사이즈의 선택과 교체 정책은 엄청난 성능 차이를 가져온다. 이런 정보는 10장에서 더 다루겠다.

저장 공간 계층의 레벨사이 정보의 움직임은 명료하거나 내재적일수 있다. 예를 들어 캐시에서 CPU와 레지스터의 데이터 이동은 보통 하드웨어 기능인데, 운영체제가 없이도 가능하다. 반면에 디스크에서 메모리로의 데이터 이동은 보통 운영체제에 의해서 관리된다.

계층적인 저장 구조에서, 같은 데이터가 여러 레벨의 저장 시스템에 나타날 수 있다. 예를 들어서, 파일 B에 있는 정수 A가 1증가하고 싶어한다. 파일 B는 하드디스크에 거주하고 있다. 그 증가 명령은 먼저 발행되고 I/O 명령으로 A가 존재하는 메인메모리에 디스크 블락으로 카피한다. 그러므로 A의 복사는 몇군데의 장소에서 나타난다.: 하드디스크, 메인메모리, 캐시, 내부 레지스터가 있을 것이다. 내부 레지스터에서 증가가 일어나면 A의 값은 저장공간마다 다르게 나타날것이다. A의 값은 새로운 값이 내부 레지스터에서 하드디스크로 옮겨지고 나서 같아질 것이다.

한 프로세스가 실행되는 컴퓨팅 환경에서, 이런 것은 힘들지 않을 것이다. 하지만 A의 접근이 가장 높은 계층에서 카피된다. 그러나 멀티 태스킹 환경에서는 CPU가 다양한 프로세스를 바꾸고 특별한 주의가 필요할 것이다. 만약 몇몇 프로세스가 A에 접근하기를 원한다면 프로세스는 가장 최근에 업데이트된 A값을 얻을 것이다.

이 상황은 멀티프로세서 환경이면 더욱더 복잡해지고 내부 레지스터를 유지하고 각각의 CPU가 로컬 캐시를 포함한다. 이런 상황에서 A의 복사는 동시다발적일 수 있다. 다양한 CPU가 병렬적으로 실행되면서, 우리는 캐시안의 A의 값을 다른 캐시에도 똑같이 반영해야한다. 이런 상황이 ##캐시 일관성##라고 불리며 보통 하드웨어 이슈이다.

분할 환경에서, 상황은 더욱 복잡해진다. 이런 환경에서는 같은 파일의 복사본은 다른 컴퓨터에 있다. 다양한 복사본이 접근되고 동시다발적으로 업데이트 되면, 몇몇 분산 시스템은 복사본이 한곳에서 업데이트가 된다면, 모든 복사본을 당장 가져온다. 이런 것을 지키는 것은 챕터 19에서 나올 것이다.

### 1.5.6 I/O 시스템 관리

운영체제의 목적은 특정 하드웨어 디바이스의 기벽을 숨기는 것이다. 예를 들어서 유닉스에서는 I/O디바이스의 기벽은 운영체제의 서브시스템에 의해서 가려진다. I/O 서브시스템은 다음을 포함한다.
- 버퍼링, 캐싱, 스풀링을 포함한 메모리 관리 컴포넌트
- 일반적인 디바이스 드라이버 인터페이스
- 특별한 하드웨어 장치 드라이버

오직 디바이스 드라이버만이 특정 기기의 기벽을 그것이 할당 되었을 때 안다.

우리는 인터럽트 핸들러와 디바이스 드라이버가 I/O 서브시스템의 효율성을 위해서 사용된다고 말했다. 챕터 12에서 I/O 서브시스템 인터페이스에 대해서 이야기하겠다.

## 1.6 보안과 보호

만약 컴퓨터 시스템이 여러 유저를 가지고 있고 여러 프로세스를 동시에 허가해서 데이터 접근이 규제된다. 그러면 파일, 메모리 구역, CPU, 다른 리소스가 운영체제로부터 적절한 권한을 받아서 운영되어야한다. 예를 들어서, 메모리를 가르키는 하드웨어는 오직 그것의 주소 공간을 작동하게 보장해야 한다. 타이머는 끝날떄가지 어떤 프로세스도 CPU의 컨트롤을 얻게 해서는 안된다. 디바이스 컨트롤 레지스터는 유저가 접근해서는안되고 보조 장치들은 보호받아야한다.

보호는 프로세스의 접근과 유저가 리소스를 정하는 메커니즘을 통제하는 것이다. 이 메커니즘은 반드시 컨트롤을 명시하고 컨트롤을 강제하는 메커니즘을 제공해야한다. 

보호는 컴포넌트 서브 시스템과 인터페이스 간의 지연 에러를 잡는 것으로 신뢰성을 향상시킨다. 현대의 인터페이스 에러 감지는 다른 오작동하는 서브시스템으로부터 건강한 서브시스템의 오염을 예방한다. 더욱이, 보호 받지 못하는 리소스는 권한 없는 적절하지 않은 유저로서의 사용을 막지 못한다. 보호가 되는 시스템은 허가와 비허가 사용을 확실히 구분해준다.

시스템은 적절한 보호를 가지지만, 실패하는 경향과 적절하지 않은 접근을 가진다. 권한 정보가 도둑 맞은 유저를 생각해보자. 그녀의 데이터는 복사되거나 삭제된다. 그런데 파일과 메모리 보호는 여전히 일어나고 있다. 이게 내부와 외부의 공격을 시스템으로부터 막는 보안의 일이다. 이런 공격은 넓은 범위로 퍼져나갔고 바이러스와 웜, 도스, 명의 강탈을 포함한다. 이런 공격으로의 예방은 운영체제의 기능으로 고려되었다. 이런 보안 사건이 생기자, 운영체제 보안은 매우 빠르고 다양한 영역에서 연구되고 발전되었다.

보호와 보안은 시스템이 모든 유저를 구별하는 것이 필요하다. 대부분의 운영체제는 유저 이름과 관련된 유저 신분의 리스트를 가지고 있다. 운영체제 말투로는 SID라고 불린다. 이런 많은 아이디들은 유니크하다. 유저가 시스템에 로그인하면, 인증 단계는 유저를 위해서 유저 아이디를 판단한다. 그 유저 아이디는 모든 유저의 프로세스와 스레드에 관련되어있다. ID가 유저에 의해서 읽히길 원하면, 그것은 유저 리스트를 통해서 유저 이름을 읽는다.

몇몇 환경에서, 우리는 개인 유저보다는 많은 유저 사이에서 구분하기를 원한다. 예를 들어서, 유닉스 시스템에서의 파일의 주인은 파일에 관한 모든 명령을 허가할수 있는 반면에 몇몇 유저들은 오직 읽게만 할 수 있다. 이런 것을 성사하기 위해서, 우리는 그룹 네임을 지정한다. 그룹 기능은 시스템에 걸쳐서 나타난다. 유저는 한개의 그룹이나 여러개의 그룹에 운영체제 디자인에 따라서 들어갈 수 있다. 유저의 그룹 아이디는 또한 모든 관련된 프로세스와 스레드에 포함된다. 

일반적인 시스템 이용의 과정에서, 유저 ID와 그룹 ID는 충분하다. 그러나 유저는 가끔씩 권한을 높이기를 원한다. 예를 들어 운영체제는 다양한 방식의 권한 상향을 지원한다. 유닉스에서 예를 들어 setuid는 프로그램이 파일의 소유자에게 일하게 한다. 프로세스는 이런 효과적인 UID와 일한다.

## 1.7 가상화

가상화는 단일 컴퓨터의 하드웨어를 다른 실행 환경으로 만드는 기술을 의미한다. 즉, 분할된 환경에서 그것의 컴퓨터를 가진 환영을 만드는 것이다. 이런 환경들은 다른 개별 운영체제에서 보여진다. 가상 머신의 유저는 동시에 하나의 운영체제를 실행하면서 다양한 운영체제를 스위치할수 있다.

가상화는 운영체제가 다른 운영체제를 실행하는 것이다. 그곳에는 몇가지 기능적 문제가 있어보인다. 그러나 가상화 산업은 그것의 효율성과 중요성 때문에 방대하고 성장하고 있다.

넓게 보면, 가상화 소프트웨어는 모방을 포함한 클래스의 한 멤버이다. 에뮬레이션은 컴퓨터 하드웨어안의 소프트웨어를 시뮬레이트하는 것을 의미하고, 보통 소스 CPU 타입이 타겟 CPU 타입과 다를때 사용된다. 예를 들어서, 애플은 IBM 파워 CPU에서 인텔 CPU로 바꾸었다. 그것의 에뮬레이션 기능을 로제타라고 불렀고 IBM CPU를 위한 컴파일이 인텔 CPU에서 돌아가게끔 허가했다. 같은 개념은 전체적인 운영체제가 다른 플랫폼에서 돌아가게 하는 것이다. 에뮬레이션은 무거운 무게가 되었다. 모든 머신 레벨 명령은 소스시스템에 맞게 번역되어야한다. 만약 소스와 타겟 CPU가 비슷한 성능레벨을 가지면, 에뮬레이트된 코드는 자연어보다는 느릴 것이다.

가상화와 함꼐, 운영체제는 특정 CPU 아키텍처에서 작동되게 컴파일 된것이 다른 CPU를 위해서도 돌아가게 되었다. 가상화는 IBM 메인 프레임으로 다가왔다.. 다양한 가상 머신을 가동하는 것은 많은 유저가 개인 유저를 위해 시스템된 작업을 돌리게하는 것을 허용했다. 훗날에 이런 문제 때문에 VMware는 새로운 가상화 기술을 만들었고, 윈도우에서 돌아가는 것을 만들었다. 이것이 게스트개념이다. 각각이 각각의 앱을 돌린다. 그리고 이런 것을 관리하는 것이 **virtual machine manager**이다. VMM은 게스트 운영체제가 작동하게 하고, 그들의 자원사용을 관리하고 각각의 게스트를 다른이로부터 보호한다.

현대 운영체제가 다양한 앱을 돌리게하지만, 가상화의 역할은 커져만 간다. 랩탑과 데탑에서, VMM은 유저가 다양한 운영체제를 탐색하고 자신의 자연 운영체제와 다른 환경에서 쓰인 앱을 돌리게끔 도와준다. 예를 들어서 애플 랩탑은 윈도우 10 게스트를 윈도우 앱 실행을 위해서 작동가능하다. 기업들은 다양한 운영체제에서 쓰기 위한 도움으로 쓸 수 있다. 데이터 센터 내에서 가상화는 실행과 컴퓨팅 환경 관리를 위한 일반적인 방법이다. 

이 책에서는, 우리는 리눅스 가상 머신을 당신이 돌리게 해주고 우리가 제공한 개발 툴을 제공하고 내 시스템은 신경쓰지 않고 하게 해준다. 이런 설명은 18장에서 마무리 지을 것이다.

## 1.8 분산 시스템

분산 시스템은 물리적으로 떨어졌지만, 다양한 자원으로부터 유저들이 접근가능하게 네트워크된 다른 종류로 이루어진 컴퓨터 시스템들이다. 공유된 자원으로의 접근이 컴퓨테이션 속도, 기능, 데이터 신뢰성을 높여준다. 몇몇 운영 체제는 네트워킹의 디테일이 포함된 네트워크 인터페이스의 디바이스 드라이브와 함께 네트워크 접근을 파일 엑세스의 일부분으로 일반화한다. 다른것들은 유저가 네트워크 기능을 사용하게 한다. 보통 시스템들은 두가지 모드로 나눈다. FTP와 NFS가 있을 것이다. 이런 프로토콜은 분산화 시스템을 만들고 시스템의 효율성과 인기에 영향을 준다.

네트워크는 간단히 말하면 두개 또는 더 많은 시스템 사이의 소통이다. 분산 시스템의 기능성은 네트워킹에 달려있다. 네트워크는 어떤 프로토콜이 사용되냐에 갈리고, 노드간의 사이, 그리고 이동 미디어에 따라 다르다. TCP/IP는 가장 일반적인 네트워크 프로토콜이고 인터넷의 기초 구조를 제공한다. 대부분의 운영체제는 TCP/IP를 지원한다. 몇몇 시스템은 그들의 니즈를 만족시키기위해서 특별한 프로토콜을 지원하기도 한다. 운영체제에게 네트워크 인터페이스 드라이버를 가졌는지 중요하다. 이것은 데이터를 조절하는 소트프웨어이기도 하다. 이 개념은 책을 관통해서 계속 나올 것이다.

네트워크들은 그들의 노드 거리에 따라서 달라진다. LAN은 방사이, 캠퍼스, 건물을 연결하고 WAN은 빌딩들을 이어주고 도시를 이어주고 나라를 이어준다. 국제적인 기업들은 WAN을 가지고 있고 그것의 오피스를 전세계로 잡는다. 이런 네트워크는 하나 혹은 여러개의 프로토콜을 이용한다. 새로운 기술의 출현은 새로운 형태의 네트워크를 가져오고 있다. 예를 들어 **Metropolian-Area-Network**는 도시안의 빌딩을 연결한다. 블루트스와 802.11 장치들은 몇 피트 거리를 통신하는 무선 기술이다. 이 것은 핸드폰과 헤드셋, 스마트폰과 컴퓨터를 연결하는 **Personal-Area-Network**를 형성한다.

네트워크를 움직이는 미디어는 균일하게 분포되어있다. 그들은 구리선을 가지고, 섬유를 가지고, 위성간 무선 통신을 한다. 컴퓨팅 디바이스가 핸드폰에 연결되면 그들은 네트워크를 만든다. 단거리의 적외선 통신또한 네트워크에 사용될 수 있다. 가장 기초적인 레벨에서는 컴퓨터는 통신하고, 그들은 네트워크를 만들거나 사용한다. 이런 네트워크는 그들의 성능과 신뢰성에 따라 다양하다.

몇몇 운영체제는 네트워크 시스템을 가지고 오고 분산 시스템을 네트워크 연결 개념을 가지고 왔다. 네트워크 운영체제는 네트워크간에 파일을 공유하는 기능을 제공한다. 그리고 통신 기술은 다른 컴퓨터에서 메시지를 교환하는 다른 프로세스를 허용한다. 네트워크 운영체제를 운영하는 컴퓨터는 네트워크의 모든 다른 컴퓨터로부터 독자적으로 행동한다. 비록 그것이 네트워크를 인식하고 다른 네트워크안의 컴퓨터와 통신하더라도. 분산 운영 체제는 덜 독자적인 환경을 제공한다. 다른 컴퓨터들은 한개의 운영체제 시스템이 네트워크를 통제하는 환영을 제공한다. 우리는 이런 것을 19장에서 배우겠다.

## 1.9 커널 데이터 구조

우리는 운영체제 기능의 다음 주제로 넘어가겠다. 시스템에서 데이터가 구성되는 것이다. 이 절에서는 우리는 운영체제에서 쓰이는 몇가지 기본적인 데이터 구조를 설명한다.

### 1.9.1 리스트, 스택, 큐

배열은 각각의 원소가 직접 접근가능한 간단한 데이터 구조이다. 예를 들어서 메인 메모리는 배열로 만들어졌다. 만약 데이터 아이템이 1바이트보다 크다면 여러개의 바이트가 할당 될 것이고 아이템은 "item number X item"사이즈일 것이다. 그러나 크기가 다양한 아이템의 저장은?? 그리고 아이템을 삭제하는데 남아있는 관련 아이템의 위치가 유지되어야 한다면? 그런 상황에서, 배열은 다른 자료구조를 보인다.

배열 이후에, 리스트는 아마도 컴퓨터는 가장 단순한 자료 구조일 것이다. 반면에 각각의 행렬의 아이템은 직접 접근하면서, 아이템은 특정 순서로 연결되어있다. 즉 리스트는 데이터의 일련이라고 생각하면 된다. 가장 일반적인 방법은 링크드 리스트이다. 아이템이 연결된 것이다. 이 종류들은 다음과 같다.

- singly linked list, doubly linked list, circularly linked list

링크드 리스트는 아이템을 다양한 사이즈로 저장하고 삽입과 삭제가 쉽다. 한 가지 단점은 특정 아이템을 찾는 기능이 복잡도가 O(n)이라는 것이다. 리스트는 커널 알고리즘으로 쓰인다.

스택은 정렬된 데이터로서 **LIFO(LAST IN FIRST OUT)**구조이다. 운영체제에서는 펑션 콜을 이용할때 스택을 많이 사용한다. 파라미터, 지역 변수, 리턴 주소를 스택의 가장 위에 두는 것이다.

큐는 **FIFO(FIRST IN FIRST OUT)**구조이다. 큐는 프린터에 쓰인다. Chapter 5에서 대기중인 작업이 큐에서 어떻게 구성되는지 보겠다.

### 1.9.2 트리

트리는 데이터를 계층적으로 보는데 사용된다. 일반적인 트리에서, 부모는 무한한 자식을 가진다. 바이너리 트리는 2명의 자식만이 있고 좌자식, 우자식이라고 부른다. 바이너리 서치 트리는 왼쪽 자식이 오른쪽 자식보다 큰 성질을 가지고 있다. 이거의 최악 경우는 n인데 이를 최대한 줄이는 방법은 밸런스 트리로 만드는 방법등이 있다. 그리고 5.7.1에서 리눅스가 RBT를 CPU 스케쥴링 알고리즘을 이용하는 것을 알수 있을 것이다.

### 1.9.3 해쉬 함수와 맵

해쉬 함수는 그것의 인풋을 데이터에 다양한 연산을 한후에 새로운 숫자 값을 주는 것이다. 숫자 값은 테이블의 인덱스로서 쓰이고 빠르게 데이터를 찾아낸다. 이걸로 O(1)의 찾는 속도를 얻어낼 수 있다. 이런 성능 때문에 해쉬 함수는 운영체제에서 널리 쓰인다. 

하나의 가능성있는 어려움은 두개의 인풋이 하나의 아웃풋을 내서 같은 위치에 저장되는 것이다. 이런 문제를 우리는 해시 컬리젼을 통해서 해결할 수 있다. 또다른 방법은 해시맵이다. [Key : value]페어를 만드는 것이다. 매핑이 한번 생기면, 우리는 이 해시 함수를 키에 적용하고 밸류값을 해시맵을 통해서 얻는다. 예를 들어서 유저 이름이 패스워드에 매핑되었다. 패스워드 인증은 다음을 따르게 된다. 유저가 그녀의 이름과 암호를 입력한다. 해시 펑션이 유저의 이름에 적용되고, 패스워드를 찾아낸다. 찾아낸 패스워드는 유저가 입력한 것을 비교해서 인증한다.

### 1.9.4 비트맵

비트맵은 n의 바이너리 디짓 스트링이다. n개의 아이템의 성질을 대표한다. 예를 들어 우리가 몇가지 리소스를 가지고 있다. 그리고 각 리소스의 사용가능 여부는 바이너리 값으로 알수 있다. 비트맵의 능력은 그들의 공간 효율성으로 알수 있다. 만약 우리가 8비트 불리언 밸류를 사용하면 그것은 8배의 차이를 만들어낸다. 그러므로 비트맵은 보통 큰 수의 리소스 사용 여부를 알리는데 사용된다. 디스크 드라이버는 좋은 예시이다. 중간 크기의 디스크 드라이브는 수천 수만개의 디스크 블락이라는 단위유닛으로 나뉠 것이다. 비트맵은 그리고 각 디스크 블락의 사용가능 여부를 알려줄 것이다.

요약하자면 데이터 구조는 운영체제에서 만연하다. 그러므로 우리는 이 책에서 커널 알고리즘과 그들의 도구를 따라서 구조를 보겠다.

## 1.10 컴퓨팅 환경

우리는 컴퓨터 시스템의 다양한 측면과 운영체제가 그들을 다루는 법을 봤다. 우리는 어떻게 운영체제가 컴퓨팅 환경에서 다양하게 쓰이는지 보겠다.

### 1.10.1 전통적인 컴퓨팅

컴퓨터가 성숙하면서, 많은 전통적인 컴퓨터 환경이라는 것은 희미해졌다. "특정한 사무실 환경"을 고려하겠다. 몇 년전에, 이 환경은 서버가 파일을 제공하고 프린트를 서비스하는 네트워크로 컴퓨터가 연결되었다. 먼 연결은 어색해졌고 휴대성은 랩탑 컴퓨터의 사용으로 발전했다.

오늘날, 웹 기술은 WAN 밴드위스로 전통 컴퓨팅의 바운더리를 넘겼다. 회사들은 포털을 개설했고 이를 통해서 내부 서버의 연결을 제공했다. 네트워크 컴퓨터는 웹베이스의 컴퓨팅은 더욱 보안이 강하고 쉬운 관리가 보장된 전통적인 워크스테이션을 터미널로 제공했다. 모바일 컴퓨터는 피시와 동기화 되었다. 모바일 디바이스 또한 무선 네트워크와 셀룰러 데이터 네트워크를 이용한 기업의 웹 포털로 연결되었다. 

집에서, 대부분의 유저들은 사무실과 연결된 느린 모뎀의 컴퓨터를 가졌다. 오늘날, 네트워크 연결 속도는 많은 분야에서 필수적으로 되었고 홈 유저들이 더 많은 데이터를 주게 되었다. 이런 빠른 데이터 연결들은 홈 컴퓨터들을 웹페이지에 대령했다. 많은 집에서 파이어 월이라는 그들의 네트워클을 보호하는 도구를 사용한다. 파이어월은 네트워크 상에서의 통신을 제한했다.

20세기의 말에, 컴퓨팅 자원은 생소했다. 몇세기 후에 시스템은 묶이고 상호작용한다. 배치 시스템은 미리 정해진 인풋부터 유저의 일을 묶어서 실행했다. 컴퓨팅 리소스의 사용을 최적화하기 위해서, 다중 유저들은 이 시스템에서 시간을 공유했다. 이 타임 쉐어링 시스템은 사이클 프로세스부터 CPU로 유저에게 자원의 공유를 주면서 타이머와 스케쥴링 알고리즘을 사용했다.

전통적인 타임 쉐어링 시스템은 이제 없다. 이 같은 스케쥴링 기술은 데스크탑 컴퓨터, 랩탑, 서버, 모바일 컴퓨터에서 사용되고 있고 모든 프로세스가 같은 유저에 의해서 소유된다. 유저 프로세스, 시스템 프로세스는 유저에게 서비스를 제공하고 컴퓨터 시간의 일부를 가져다 준다. 윈도우가 유저가 피시 작업하면서 생겼다고 하면, 사실을 같은 시간동안 다른 일을 하는 것이다. 웹브라우저마저도 다중 프로세스를 가지고 각각의 웹사이트는 방문되고잇고 공유된 각 웹브라우저 프로세스를 사용한다.