## What we gonna study

분산 시스템은 메모리 또는 클락을 공유하지 않는 프로세서의 집합이다. 대신에, 각 노드는 그것의 고유 로컬 메모리를 가진다. 노드는 가속 버스같은 다양한 네트워크를 통해서 다른 것과 소통한다. 분산된 시스템들은 더욱 관련이 있고, 너는 몇가지 분산된 서비스를 사용한다. 분산 시스템의 앱은 조직내에서 파일에 투명한 접근을 제공하는 것부터 대규모 클라우드 파일과 사진 저장소 서비스, 큰 데이터셋에서 사업 트렌드의 분석, 과학적 데이터의 평행적 프로세싱등이 있다. 실제로, 가장 일반적인 분산 시스템의 예시는 인터넷이다.

이 장에서, 우리는 일반적인 분산 시스템의 구조와 그들을 연결하는 네트워크를 알아보겠다. 우리는 또한 현재 분산 시스템 디자인의 타입과 역할에서의 차이를 대조하겠다. 마지막으로, 우리는 분산 파일 시스템에서의 기본 디자인과 어려운점을 보겠다.

## Objectives

- 네트워크, 분산 시스템의 장점을 설명한다.
- 분산 시스템을 연결하는 네트워크의 높은 레벨 개요를 제공하겠다.
- 오늘날 사용되는 분산시스템의 종류와 역할을 정의하겠다.
- 분산 파일 시스템의 디자인에 관련된 이슈를 논의하겠다.

## 19.1 분산 시스템의 장점

**distributed system**은 통신 네트워크에 의해서 연결된 loosely coupled nodes의 집합이다. 분산 시스템의 특정 노드의 관점에서, 나머지 노드와 그들의 각각의 리소스들은 원격이고, 반면에 그것의 리소스는 로컬이다. 분산 시스템의 노드는 사이즈와 함수에서 다양하다. 그들은 작은 마이크로 프로세서, pc, 큰 범용 컴퓨터 시스템을 포함할 수 있다. 이런 프로세서들은 그들이 언급하는 문맥에 따라 *processors, sites, hosts, machine*과 같이 다양한 이름으로 언급된다. 우리는 주로 머신의 위치를 말하기 위해서 *site*를 사용하고 사이트에서의 특정 시스템을 언급하기 위해서 *node*를 사용한다. 노드들은 *client-server*, *peer-to-peer*와 같은 상태로 존재할 수 있다. 일반적인 클라이언트-서버에서, one node at on site, the *server*는 다른 노드인 *client*가 사용하기를 원하는 리소스를 가지고 있다. peer-to-peer에서, 서버나 클라언트가 없다. 대신에, 노드들은 클라이언트와 서버로서 동등한 책임을 공유한다.

몇가지 사이트들은 통신 네트워크에 의해서 연결되어 있을때, 다양한 sites에 있는 유저들은 정보를 교환할 기회를 가진다. 낮은 레벨에서, **messages**들은 시스템 사이에서 전달되고, 3.4절에서 얘기한 단일 컴퓨터 메시지 시스템에서 프로세스간에 메시지가 교환되는 것과 비슷하다. 메시지 패싱이 주어지면, 단일 시스템에서 발견되는 모든 높은 레벨 기능은 분산 시스템을 포함하게 확장된다. 이런 함수는 파일 저장소, 앱의 실행, RPCs를 포함한다.

분산 시스템을 짓는 주요한 3가지 이유가 있다 : 리소스 공유, 연산 가속, 신뢰성. 이 절에서, 우리는 간단하게 이를 살펴보겠다.

### 19.1.1 리소스 공유

만약 많은 수의 다른 사이트들이 다른 것에 연결되면, 한 site에 있는 유저는 다른 곳에 가용한 리소스를 사용할 수 있다. 예를 들어서, site A의 유저는 site B에 있는 데이터베이스에 문의한다. 그 동안에, site B의 유저는 site A에 존재하는 파일에 접근한다. 일반적으로, 분산 시스템에서 **resource sharing** 원격 site에서 파일 공유, 분산 데이터 베이스에서의 데이터 처리, 원격 site의 파일 인쇄, 슈퍼 컴퓨터나 GPU같은 특화 하드웨어를 원격에서 사용하기 위한 메커니즘을 제공한다.

### 19.1.2 Computation SpeedUp

만약 특정 연산이 동시에 작동하는 서브 컴퓨테이션으로 분할될 수 있으면, 분산 시스템은 다양한 site사이에서 subcomputation을 분산하게 허용한다. subcomputation은 동시에 작동이 가능하고 그러므로 **computation speedup**을 제공한다. 이것은 근 데이터 셋의 처리를 진행할때 사용된다. 추가로, 만약 특정 site가 현재 요청이 과적되면, 그들의 일부가 덜 적재된 site로 이동하거나 재설정된다. 이런 행동을 **load balancing**이라고 부르고 분산 시스템 노드와 인터넷에서 제공되는 다른 서비스에서는 일반적이다.

### 19.1.3 Reliability

만약 분산 시스템에서 한개의 사이트가 실패하면, 나머지 사이트는 계속 작동하고, 시스템은 나은 신뢰성을 얻는다. 만약 시스템이 다중 대형 자율적인 설치로 구성되면, 그들중 하나의 실패는 나머지에게 영향을 주지 않는다. 만약 시스템이 몇몇 중요한 시스템 함수를 책임지는 다각화된 머신으로 구성되면, 한개의 실패는 전체 시스템을 멈추게한다. 일반적으로, 충분한 낭비와 함께라면, 시스템은 그것의 노드가 몇개 실패해도 작동을 지속한다.

노드 또는 site의 실패는 시스템에 의해서 발견되고 적절한 행동은 실패로부터 회복되는데 필요하다. 시스템은 반드시 그 사이트의 서비스를 사용하지 말아야한다. 추가로, 만약 실패한 사이트의 함수가 다른 사이트로 넘어가면, 시스템은 반드시 함수의 전달이 알맞게 일어났는지 확인해야한다. 마지막으로, 실패한 사이트가 회복되거나 수리되면, 그것을 시스템으로 부드럽게 다시 합병하는 메커니즘이 있어야한다.

## 19.2 Network Structure

오늘 날 사용하는 분산 시스템의 종류와 역할을 완벽히 이해하기 위해서, 우리는 그들을 연결하는 네트워크를 이해할 필요가 있다. 이 절은 기본적인 네트워킹 컨셉과 그들이 분산 시스템과 관련된 문제를 소개하는 네트워크 입문서로서 다루겠다. 장의 나머지는 분산 시스템을 특별히 다루겠다.

네트워크에는 두가지 타입이 있다 : **Local-area networks(LAB)**과 **Wide-area networks(WAN)**이다. 두개의 가장 큰 차이점은 그들이 지리적으로 분산된 방식이다. LAN은 작은 공간(단일 건물 또는 인접한 빌딩)에 분산된 호스트들로 구성되어있고, 반면에 WAN은 큰 공간(미국)에 부산된 시스템으로 구성되어 있다. 이런 차이가 통신 네트워크의 속도와 신뢰성에서의 주요한 변형을 내포하고, 그들은 분산 시스템 디자인에도 반영된다.

### 19.2.1 LAN

LAN은 메인프레임 컴퓨터 시스템의 대체로 1970년대 초기에 부상했다. 많은 기업체가, 각자의 앱을 가진 작은 컴퓨터들을 가지는 것 단일 큰 시스템을 가지는 것보다 경제적이었다. 각 작은 컴퓨터가 부속 디바이스의 전체 보완을 필요로했고, 몇가지 데이터 공유가 단일 기업체에서 공유되어야했다. 그것은 이런 작은 시스템을 네트워크로 연결하는 자연스러운 단계이다.

LANs 말했듯이, 작은 지리적 영역에 디자인되고 그들은 오프시 또는 가정 환경에서 쓰였다. 이런 시스템에서의 모든 사이트는 다른 것과 가까웠고, 그래서 통신 링크는 빠른 속도와 wan에 비해서 적은 에러를 가졌다.

일반적인 LAN은 다른 컴퓨터(워크스테이션, 서버, 랩탑, 태블릿, 스마트폰)를 포함하고, 다양한 공유 부속 디바이스(프린터, 저장소행렬), 하나 또는 이상의 **router**를 포함한다. 이더넷과 **WiFi**는 LAN을 건설하느데 사용되었다. *Wireless access points*가 LAN에 디바이스를 무선으로 연결하고 그들은 그들자체로 라우터가 되거나 안되었다.

이더넷 네트워크들은 일반적으로 컴퓨터와 부속기기가 이동이 불가능한 사업과 조직에서 사용되었다. 이런 네트워크들은 *coaxial, twisted pair, fiber optic*케이블을 시그널을 보내기 위해서 사용한다. 이더넷 네트워크는 중앙 컨트롤러가 없는데, 왜냐하면 그것은 다중 엑세스 버스이고 그래서 새로운 호스트들은 네트워크에 쉽게 추가될 수 있다. 이더넷 프로토콜은 IEEE 802.3 표준에 의해서 정의된다. twisted-pair 케이블링을 사용하는 일반적인 이더넷 속도는 10Mbps~10Gbps이고 다른 케이블링은 100Gbps이다.

와이파이는 이제 유비쿼터스이고 전통적인 이더넷 네트워크를 보충하거나 그 자체로 존재한다. 특히, 와이파이는 우리가 네트워크를 물리적 케이블 없이 건설하게 허용한다. 각 호스트는 네트워크에 참석하는데 사용하는 무선 전송기와 수신기를 가진다. 와이파이는 IEEE 802.11 표준으로 정의된다. 무선 네트워크는 가정과 사업에서 유망하다. 와이파이 속도는 11Mbps에서 400Mbps로 다양하다.

IEEE 802.3과 802.11 표준은 지속적으로 진화중이다. 다양한 표준과 속도에 관한 최근의 정보에서는 장의 마지막에 살펴보겠다.

### 19.2.2 WAN

WAN은 1960년 후반에 부상했고, 사이트 사이에서 하드웨어와 소프트웨어가 넓은 범위의 유저에 의해서 간편하고 경제적으로 공유되는 것을 허용하는 효율적인 소통을 제공하기 위한 학술적인 연구 프로젝트로서 발전했다. 첫번째로 디자인되고 개발된 WAN은 ARPANET이다. 1968년에 시작해서, ARPANET은 4가지 사이트 실험적인 네트워크에서 WWW인 수백만개의 컴퓨터 시스템을 구성하는 **Internet**으로 자랐다.

WAN의 사이트는 물리적으로 넓은 장소에 분산되어있다. 일반적인 링크들은 전화선, leased llines, optical cable, microwave link, radio waves, satellite channel이다. 이런 통신 링크들은 다른 라우터와 네트워크의 교통을 지시하고 다양한 사이트 사이에서 정보를 전송하는 라우터에 의해서 제어된다.

예를 들어서, 인터넷 WAN은 멀리 떨어진 호스트가 다른 것과 통신하게 한다. 호스트 컴퓨터들은 일반적으로 통신하는 것과 속도, CPU 종류, 운영체제 등이 다르다. 호스트들은 LAN위에 있고, 지역 네트워크를 통해 인터넷에 연결되어있다. 지역 네트워크들은 라우터와 함께 worldwide network에 연결되어 있다. 거주자들은 전화, 케이블 또는 거주자를 중앙 서비스와 연결하는 라우터가 설치된 특화된 인터넷 서비스 제공자와 연결되어있다. 물론, 인터넷 사이에는 WAN이 있다. 회사는 그것의 사적인 WAN을 증가된 보안, 성능, 신뢰성을 위해서 만들 수 있다.

WANs들은 일반적으로 LANs보다 느린데, 비록 주요한 도시를 연결하는 근간 WAN 연결은 광학 케이블을 통해서 빠른 속도의 전송속도를 가질 수 있다. 실제로, 많은 근간 제공자들은 40Gbps 또는 100Gbps의 광학 케이블을 가진다.(그것은 보통 로컬 **Internet Service Providers(ISPs)**로부터의 링크이다.) 그러나, WAN 링크들은 빠른 속도를 원하는 수요가 늘어나면서 빠른 기술로 발전하고 있다.

자주, WANs와 LANs는 연결되어있고, 그것은 어떤게 시작이고 어떤게 끝인지 말하기 어렵다. 핸드폰 데이터 네트워크를 고려하겠다. 핸드폰들은 음성과 데이터 통신에 사용된다. 주어진 영역에 있는 핸드폰은 수신기와 송신기를 가진 무선기지국에서 나오는 라디오파를 통해서 연결한다. 네트워크의 부분은 셀폰이 다른 것과 통신하지 않는다는 것을 제외하면 LAN과 비슷하다. (비록 두 사람이 데이터를 주고받거나 통화해도 같은 타워에 연결되어있다고 한다.) 오히려, 기지국이 다른 기지국과 타워 통신을 랜드 라인 또는 다른 통신 매체에 연결하고 그들의 목적지로 라우트하는 허브에 연결되어있다. 이 네트워크의 부분은 WAN과 비슷하다. 한번 적절한 타워가 패킷을 받으면, 그것은 송신기를 이용해서 정확한 수신인이 있는 곳으로 보낸다.

## 19.3 Communication Structure

이제 우리는 네트워킹의 물리적인 측면을 살펴보고, 우리는 내부적인 일을 보겠다.

### 19.3.1 Naming and Name Resolution

네트워크 통신에서 첫번째 이슈는 네트워크에서의 시스템 이름을 포함한다. site A의 프로세스는 사이트 B의 프로세스와 정보를 교환하고, 각각은 반드시 서로를 명시할 수 있어야 한다. 컴퓨터 시스템 내에서, 각 프로세스는 프로세스 식별자가 있고 메시지들은 프로세스 식별자로 지정된다. 네트워크 시스템이 메모리를 공유하지 않아서, 시스템의 호스트는 다른 호스트들의 프로세스에 대한 정보가 전혀 없다.

이 문제를 해결하기 위해서, 원격 시스템의 프로세스들은 <host name, identifier> 쌍으로 구별되고, **host name**은 네트워크 안의 유일한 이름이고 **identifier**는 호스트 안의 프로세스 식별자 또는 유일한 숫자이다. 호스트 이름은 일반적으로 알파벳+숫자 식별자여서 유저가 명시하기 쉽다. 예를 들어서, site A는 *program, student, faculty, cs*라는 이름을 가진 호스트를 가진다. 호스트 이름 *program*은 호스트 주소 `128.148.31.100`보다 훨씬 기억하기 쉽다.

이름들은 사람이 사용하기 편하지만, 컴퓨터는 속도와 단순성 때문에 숫자를 선호한다. 이 이유때문에, 호스트이름을 도착 시스템에서 네트워킹 하드웨어를 설명할 **host-id**로 **resolve**할 메커니즘이 필요하다. 이 메커니즘은 컴파일, 링킹, 로딩, 실행에서 나타나는(9장) name-to-address binding과 비슷하다. 호스트 이름의 경우에는, 두가지 가능성이 존재한다. 첫번쨰로, 모든 호스트는 네트워크에서 도달할 수 있는 이름과 숫자 주소를 포함한 데이터 파일을 가진다.(컴파일 시의 binding과 비슷하다.) 이 모델과의 문제는 네트워크로부터 호스트를 추가하고 삭제하는 것은 모든 호스트에서 데이터 파일을 업데이트할 필요가 있다는 것이다. 실제로, ARPRANET의 초기에는, 모든 시스템을 주기적으로 복사하는 고전적인 호스트 파일이 있었다. 네트워크가 성장하자, 이 메서드는 지지할 수 없는 메서드이다.

네트워크 상에서 시스템 사이에 정보를 배분하는 대안이 있다. 네트워크는 정보를 분산하고 되찾기 위해서 프로토콜을 사용했다. 이 구조는 excution time binding과 비슷하다. 인터넷은 호스트 이름 해결책으로 **domain-name system(DNS)**를 사용했다.

DNS는 호스트의 이름 구조 뿐만 아니라 name-to-address resolution을 명시했다. 인터넷의 호스트는 논리적으로 IP주소라고 알려진 multipart names로 보내졌다. IP 주소의 일부는 가장 상세한 것에서 일반적인것으로 필드를 분할하는 주기와 함께 진행했다. 예를 들어서, `eric.cs.yale.edu`는 탑 레벨 도메인 `edu`안의 예일 대의 컴퓨터 공학 부서의 호스트 eric이다.(다른 탑레벨 도메인은, com for commercial sites and org for organizations, 시스템에 연결된 각나라의 주소일 수 있다.) 일반적으로, 시스템은 호스트 이름 구성요소를 역순으로 검사해서 주소를 resolve한다. 각 컴포넌트는 **name server**를 가지고- 간단히 시스템의 프로세스- 이름을 수락하고 이름에 책임있는 네임 서버의 주소를 리턴한다. 마지막 단계로, 호스트를 위한 네임 서버가 연결되고, 호스트-id가 리턴된다. 예를 들어서 `eric.cs.yale.edu`와 소통하려는 시스템 A의 프로세스에 의해서 만들어진 요청은 다음의 과정을 밟는다.

1. 시스템 A의 시스템 라이브러리 또는 커널이 `edu` 도메인을 위해서 네임 서버를 요청하고, `yale.edu`의 네임 서버의 주소를 물어본다. `edu` 도메인 네임 서버는 반드시 알고 있는 주소여야하고, 그래서 그것은 쿼리될 수 있다.
2. `edu` 네임 서버가 `yale.edu` 네임서버가 거주하는 호스트의 주소를 리턴한다.
3. 시스템 A는 그러면 주소에서의 네임서버를 쿼리하고 `cs.yale.edu`를 물어본다.
4. 주소가 리턴된다. 이제, 마지막으로 `eric.cs.yale.edu`를 위한 주소 요청이 호스트를 위한 인터넷 주소 host-id를 리턴한다.(예를 들어서, `128.148.31.100`)

이 프로토콜은 비효율적이어 보이지만, 개인 호스트들은 이미 해결한 IP 주소를 캐시해서 프로세스의 속도를 증가시킨다.(물론, 이런 캐시의 컨텐츠는 네임 서버가 이동하거나 그것의 주소가 바뀌면 반드시 다시 채워야한다.) 실제로, 프로토콜은 그것이 여러번 최적화되고 많은 세이프가드가 추가될 정도로 너무 중요하다. 만약 초기 `edu` 네임서버가 충돌했다면 무슨일이 일어날지 고려해보아라. `edu`라는 이름을 가진 모든 호스트들은 resolve될수 없고, 그들은 닿을수 없어진다. 해결책은 2차 선을 두는 것인데, 백업 네임서버가 초기 서버의 컨텐츠를 복제해둔다.

dns가 소개되기 전에, 인터넷의 호스트는 네트워크에서 각 호스트의 이름과 주소를 포함한 파일의 카피를 가질 필요가 있었다. 이 파일에 모든 변화는 한가지 사이트(SRI-NIC)에 등록되었고, 주기적으로 모든 호스트들은 SRI-NIC로 부터 파일을 업데이트해서 새로운 시스템에 접근하고 주소가 바뀐 호스트들을 찾아야했다. DNS에서는, 각 이름 서버 사이트는 그 도메인에 대해서 호스트 정보를 업데이트할 책임만 있다. 예를 들어서, 예일 대학교에서의 호스트 변화들은 yale.edu 네임 서버에게 책임이 있고 어디에도 보고되지 않는다. DNS 룩업은 그들이 yale.edu에 직접 연결되기 떄문에 자동으로 업데이트된 정보를 되찾는다. 도메인들은 호스트 이름과 호스트아이디 변화에 책임을 분산하는 독자적인 서브 도메인을 가진다.

자바는 IP 이름을 IP 주소로 매핑하는 필수 API를 제공한다. `InetAddress`는 IP 이름 또는 주소를 대표하는 자바 클래스이다. `InetAddress` 클래스의 정적 메서드 `getByName()`은 IP 이름의 대표를 문자열 대표에 전달한다. 그리고 그것은 상응하는 `InetAddress`를 리턴한다. 프로그램은 그리고 `getHostAddress()`메서드를 실행하고, 내부적으로 DNS를 이용해서 원하는 호스트의 IP 주소를 룩업한다.

일반적으로, 운영체제는 그것의 프로세스로부터 <host name, identifier>를 목적지로한 메시지를 수락하고 적절한 호스트에게 메시지를 전달하는 책임이 있다. 목적지 호스트의 커널은 식별자로 이름지어진 프로세스에 메시지를 전송할 책임이 있다.(이것은 19.3.4에서 더 다루겠다.)

### 19.3.2 Communication Protocols

우리가 통신 네트워크를 디자인할 때, 우리는 반드시 잠재적으로 느리고 에러가 자주 나오는 환경에서 조직화된 비동기 명령어의 내부적 복잡성을 처리해야한다. 추가로, 네트워크의 시스템은 호스트 이름을 결정하고, 네트워크에 호스트를 위치시키고, 연결을 성사시키는 프로토콜의 집합을 수락해야한다. 우리는 다중 레이어로 문제를 분할함으로서 디자인 문제를 단순화시켰다. 시스템의 각 레이어는 다른 시스템에서의 같은 레이어와 통신한다. 일반적으로, 각 레이어는 그것의 고유 프로토콜을 가지고, 통신은 특정 프로토콜을 이용해서 피어 레이어 사이에서 자리한다. 프로토콜들은 하드웨어 또는 소프트웨어에 구현된다. 예를 들어서, 두 컴퓨터 사이에서의 논리적 통신을 가진다.

국제 표준 조직은 Open System Interconnection(OSI) 모델을 네트워킹의 다양한 계층을 표현하기 위해서 만들었다. 이런 레이어들이 실제로는 구현되지는 않지만, 그들은 어떻게 네트워킹이 논리적으로 작동하는지 이해하는데에 유용하고, 우리는 그들을 소개하겠다.

- Layer 1 : Physical layer. 물리 계층은 비트스트림의 물리적 통신의 기계/전자적인 상세를 핸들링한다. 물리 계층에서, 통신 시스템은 반드시 0과 1에서만 허용해야하고, 그래서 데이터가 전기적인 신호의 스트림으로 보내지면, 수락자는 데이터를 바이너리 데이터로 적절히 해석할 수 있다. 이 레이어는 네트워킹 디바이스의 하드웨어로 구현된다. 이것은 비트를 전송하는 역할을 한다.
- Layer 2 : Data-link layer. 데이터 링크 레이어는 물리 계층에서 일어난 에러 감지와 회복을 포함한 *frames* 또는 고정된 길이의 패킷을 다룬다. 그것은 물리적 주소사이에서 프레임을 보낸다.
- Layer 3 : Network layer. 네트워크 레이어는 메시지를 패킷으로 쪼개는 역할을 하고, 논리적 주소와 떠나는 패킷의 주소 통신를 다루고, 들어오는 패킷의 주소를 디코딩하고 라우팅 정보를 변하는 로드 레벨에 따라서 적절히 유지하는 네트워크에서 라우팅 패킷을 포함한다. 라우터는 이 계층에서 일한다.
- Layer 4 : Transport layer. 전송 계층은 노드 사이의 메시지의 전달, 패킷 순서를 유지, 혼잡을 피하기 위해서 플로우를 통제하는 역할을 한다.
- Layer 5 : Session layer. 세션 계층은 세션 또는 프로세스-프로세스 통신 프로토콜을 구현하는 역할을 한다.
- Layer 6 : Presentation layer. 표현 계층은 네트워크의 다양한 사이트 사이에서의 포맷 차이를 해결하는 역할을 한다. 하프 듀플렉스와 풀 듀플렉스 모드와 캐릭터 컨버전을 포함한다.
- Layer 7 : Application layer. 앱 계층은 유저와 직접 소통하는 역할을 한다. 이 레이어는 파일 전송, 원격 로그인 프로토콜, 전자 메일, 분산 데이터를 위한 구조를 처리한다.

**OSI protocol stack**은 프로토콜의 집합이고 데이터의 물리적 흐름을 나타낸다. 말했듯이, 논리적으로 프로토콜 스택의 각 레이어는 다른 시스템의 같은 계층과 통신한다. 그러나 물리적으로, 메시지는 앱 계층에서 시작하고 낮은 레벨에 전달된다. 각 레이어는 메시지를 수정하고 받는 쪽에서 같은 계층을 위한 메시지 헤더 데이터를 포함한다. 궁극적으로, 메시지는 데이터 네트워크 계층에 도달하고 하나 또는 이상의 패킷으로 전송된다. 데이터 링크 계층의 타겟 시스템은 이런 데이터를 받고 메시지는 프로토콜 스택을 통해서 위로 이동한다. 그것은 분석되고, 수정되고, 쪼개진다. 그것은 마침내 앱 계층으로 도달해서 프로세스에 수락되서 사용된다.

OSI 모델은 네트워크 프로토콜에서 생긴 최근의 연구를 정규화했지만 1970년대 후반에 개발되었고 현재는 널리 쓰이지 않는다. 아마도 대부분의 널리 채택된 플토콜 스택은 TCP/IP 모델(*Internet mode*이라고도 불림)인데, 가상적으로 모든 인터넷 사이트에 채택되었다. TCP/IP 프로토콜 스택은 OSI 모델보다 적은 계층을 가진다. 이론적으로, 그것이 각 레이어의 몇가지 함수를 합치기 때문에, 그것은 구현하기는 어렵지만 OSI 네트워킹에는 더욱 효율적이다.

TCP/IP 앱 계층은 HTTP, FTP, SSH, DNS, SMTP를 포함한 인터넷에서 널리 쓰이는 몇가지 프로토콜을 식별한다. 전송 계층은 신뢰할 수 없고, 연결이 없는 **user datagram protocol(UDP)**와 신뢰할 수 있고, 연결에 기반한 **transmission control protocol(TCP)**로 구별한다. **Internte protocol(IP)**는 인터넷을 통해서 IP **datagrams** 또는 패킷을 라우팅하는 역할을 한다. TCP/IP 모델은 링크 또는 물리 레이어를 정식으로 구별하지 않고, TCP/IP 트래픽이 어느 물리 네트워크로든지 달려가게 허용한다. 19.3.3절에서, 우리는 이더넷 네트워크를 건너서 작동하는 TCP/IP 모델을 고려하겠다.

보안은 반드시 어느 현대 통신 프로토콜에서 디자인되고 구현되어야한다. 강한 인증과 암호화는 보안 통신을 위해서 필요하다. 강한 인증은 보낸이와 받는이의 통신을 누가 어떻게 그들이 가정한대로 하는지 확신한다. 암호화는 감청으로부터 통신의 컨텐츠를 보호한다. 약한 인증과 정확한 텍스트 통신이 여전히 일반적이지만, 여러가지 이유가 있다. 대부분의 일반적인 프로토콜이 디자인되면, 보안은 성능, 단순성 효율성보다 덜중요하게 여겨진다. 이런 유산은 여전히 남아있고, 존재하는 인프라스트럭쳐에 보안을 더하는 것은 어렵고 복잡하다고 증명되었다.

강한 인증은 멀티스텝 handshake 프로토콜 또는 인증 기기를 필요로하고, 프로토콜에 복잡성을 추가한다. 보안이 필요해짐에 따라서, 현대 CPU들은 효율적으로 보안을 수행하고, 자주 암호학 가속 명령어를 포함해서 그래서 시스템 성능은 깍이지 않는다. 원거리 통신은 엔드포인트를 인증하고 가상 개인 네트워크의 패킷의 스트림을 암호화함으로서 보안을 만든다. LAN 통신은 대부분의 사이트에서 암호화되지 않은채 남아있지만, NFS 버전 4와 같은 프로토콜은 강한 native 인증과 암호화를 포함한다. 이들은 LAN 보안마저도 향상시킨다.

### 19.3.3 TCP/IP 예제.

다음으로, 우리는 인터넷에서 TCP/IP 프로토콜 스택에 따라서 이름 해석을 지시하고 그것의 명령어를 평가하겠다. 우리는 다른 이더넷 네트워크사이에서 패킷을 전송하는데 필요한 프로세싱을 고려하겠다. 우리는 우리의 설명을 IPV4 프로토콜에 기반해서하겠다.

TCP/IP 네트워크에서, 모든 호스트는 이름과 관련된 IP 주소를 가진다. 두 스트링은 반드시 유일해야한다. 그래서 이름 공간이 관리되고, 그들은 분리된다. 앞서 설명했듯이, 이름은 계층적이고, 호스트이름을 설명하고, 호스트가 연관된 조직을 말해준다. 호스트 아이디는 네트워크 번호와 호스트 번호로 분리된다. 스플릿의 범위는 네트워크의 사이즈에 따라서 다양하다. 한번 인터넷 관리자가 네트워크 번호를 할당하면, 그 숫자의 사이트는 호스트 아이디를 할당하기위해서 해제된다.

보내는 시스템은 그것의 라우팅 테이블을 그것의 길로 프레임을 보내기 위해서 체크한다. 이 라우팅 테이블은 시스템 관리자에 의해서 수동으로 설정되거나 **Border Gateway Protocol(BGP)**같은 라우팅 프로토콜에 의해서 위치된다. 라우터는 호스트 id의 네트워크 파트를 패킷을 그것의 소스 네트워크에서 도착지 네트워크로 전송하기 위해서 사용한다. 목적지 시스템은 그러면 패킷을 받는다. 패킷은 완벽한 메시지가 될 수 있거나, 그것은 목적 프로세스로의 전송을 위해서 메시지가 뭉쳐지고 TCP/UDP(transport) 게층으로 전달되기전에 메시지의 일부일 수도 있다.

네트워크에서, 어떻게 패킷이 보낸이(호스트 또는 라우터)에서 받는이로 갈까? 모든 이더넷 디바이스는 유일한 바이트 넘버를 가지고 **medium access control(MAC) address**라고 불리고, 주소를 위해서 할당된다. LAN의 두 디바이스는 이 이름으로 각자와 통신한다. 만약 시스템이 다른 시스템에 데이터를 보낼려면, 네트워킹 소프트웨어는 목적 시스템의 IP 주소를 포함한 **address resolution protocol(ARP)** 패킷을 생성한다.

브로드캐스트는 모든 호스트가 받고 프로세스해야할 패킷을 시그널하는 특별한 네트워크 주소를 사용한다. 브로드캐스트는 다른 네트워크 사이에서 라우터에 의해서 재전송되지 않고, 그래서 오직 로컬 네트워크 시스템이 받는다. IP 주소가 ARP 요청의 IP주소와 매치하는 시스템은 반응하고 그것의 MAC 주소를 쿼리를 시작한 시스템에 돌려 보낸다. 효율성을 위해서, 호스트는 IP-MAC 주소 페어를 내부 테이블에 캐시한다. 캐시 엔트리가 오래되면, 그래서 만약 시스템의 접근이 주어진 시간에 필요하지 않으면 엔트리가 캐시에서 마침내 제거된다. 이 방법으로, 네트워크에서 제거된 호스트들은 마침내 잊혀진다. 추가된 성능으로, 자주 사용되는 호스트를 위한 ARP 엔트리는 ARP 엔트리에 고정될 수 있다.

한번 이더넷 디바이스가 그것의 호스트id와 주소를 선언하면, 통신은 시작한다. 프로세스는 통신할 호스트의 이름을 명시할 수 있다. 네트워킹 소프트웨어는 DNS 룩업 또는 번역이 수동으로 저장된 로컬 호스트 파일의 엔트리을 사용해서 이름을 가져가고 타켓의 IP 주소를 결정한다. 메시지는 앱 계층에서 전달되고 소프트웨어 계층을 통해서 하드웨어 계층으로 간다. 하드웨어 계층에서, 패킷은 그것의 시작에 이더넷 주소를 가진다. 트레일러는 패킷의 끝을 가르키고 패킷 데미지의 발견을 위한 **checksum**을 포함한다. 패킷은 이더넷 디바이스에 의해서 네트워크에 위치한다. 패킷의 데이터 섹션은 원본 메시지의 데이터의 일부 또는 전체를 포함하지만, 그것은 메일을 구성하는 높은 레벨의 헤더의 일부또한 포함한다. 다른 말로는, 원본 메시지의 모든 파트는 소스에서 목적지로 보내지고, 802.3 계층(data-link layer)위의 헤더는 이더넷 패킷안의 데이터로 포함된다.

만약 목적지가 소스와 같은 로컬 네트워크에 있으면, 시스템은 그것의 ARP 캐시를 살펴보고, 호스트의 이더넷 주소를 찾고, 와이어에 패킷을 담는다. 목적지 이더넷 디바이스는 패킷의 그것의 주소를 보고 패킷을 읽고, 프로토콜 스택위로 전달한다.

만약 목적지 시스템이 소스와 다른 네트워크에 위치하면, 소스 시스템은 그것의 네트워크에서 적절한 라우터를 찾고 그곳으로 패킷을 보낸다. 라우터는 그러면 WAN을 따라서 패킷을 그것이 목적지 네트워크에 도달할떄까지 보낸다. 목적지 네트워크와 연결된 라우터는 그것의 ARP 캐시를 체크하고, 목적지의 이더넷 번호를 찾고, 패킷을 호스트에게 보낸다. 이런 전송을 통해서, 데이터 링크 레이어 헤더는 다음 라우터의 사용된 체인안의 이더넷 주소에 따라서 변할 수 있다. 그러나 패킷의 다른 헤더들은 패킷이 도달할떄까지 같게 유지되고 프로토콜 스택에 의해서 프로세스되고 마침내 커널에 의해서 받는 프로세스에 전달된다.

### 19.3.4 Transport Protocols UDP and TCP

한번 특정 IP 주소의 호스트가 패킷을 받으면, 그것은 반드시 그것을 정확한 대기 프로세스에 전달해야한다. 전송 프로토콜 TCP와 UDP는 **port number**의 사용을 통해서 받는(보내는) 프로세스를 식별한다. 그러므로 단일 IP 주소를 가진 호스트는 작동하고 각 프로세스가 다른 포트넘버를 명시하는 동안 패킷을 기다리는 다중 서버 프로세스를 가진다.  기본으로, 많은 서비스가 *well-known* 포트 넘버를 사용한다. 예를 들어서, FTP(21), SSH(22), SMTP(25), HTTP(80)을 포함한다. 예를 들어서, 만약 니가 브라우저를 통해서 "http" 웹사이트에 접속하기를 원하면, 너의 브라우저는 자동으로 TCP 전송 헤더의 포트 숫자를 80으로 사용함으로서 서버의 포트 80에 접속하려고 시도할 것이다. 잘 알려진 포트의 확장된 리스트에서, 너의 리눅스 또는 유닉스에 로그인하고 파일 `/etc/services`를 확인해라.

전송 계층은 네트워크 패킷을 실행하는 프로세스에 연결하는 것보다 많은 일을 한다. 그것은 또한, 원한다면 네트워크 패킷 스트림에 신뢰성을 추가할 수 있다. 설명하기 위해서, 우리는 UDP와 TCP 전송 프로토콜의 행동을 강조하겠다.

#### 19.3.4.1 User Datagram Protocol

전송 프로토콜 UDP는 그것이 포트넘버의 추가와 함께 IP의 말라빠진 확장이기 때문에 *unreliable*하다. 실제로 UDP 헤더는 단순하고 오직 4가지 필드를 포함한다. 소스 포트 넘버, 목적지 포트 넘버, 길이, 체크섬이다. 패킷은 UDP를 이용해서 목적지에 빠르게 보내질 수 있다. 그러나, 네트워크 스택의 낮은 계층에서의 배달을 보장할 수 없기 때문에, 패킷을 잃을 수도 있다. 패킷들은 또한 수신자에게 순서없이 갈 수 있다. 그것은 에러를 찾고 수정하는것을 앱에게 맞긴다.

UDP 패킷이 데이터를 손실하는 시나리오를 보겠다. 이 프로토콜은 *connectionless* 프로토콜이라고 불리는데 왜냐하면 상태를 설정하는 전송의 시작에 어떠한 연결 셋업이 없다. 클라이언트는 오직 데이터를 보내기 시작한다. 비슷하게, 연결 teardown도 없다.

클라이언트가 서버에 몇가지 정보를 요청하는 것을 시작한다. 서버는 4가지 데이터그램 또는 패킷을 클라이언트에게 보낸다. 불행히도, 패킷의 하나는 라우터의 오작동으로 손실되었다. 클라이언트는 3가지 패킷으로 만들거나 잃어버린 패킷을 요청하는 앱에 구현된 로직을 사용할 것이다. 그러므로, 우리는 만약 네트워크에 의해서 조절되는 신뢰성을 보장하는 것을 원한다면 다른 전송 프로토콜을 사용해야한다.

#### 19.3.4.2 Transmission Control Protocol

TCP는 *reliable*하고 *connection oriented*한 전송 프로토콜이다. 다른 호스트에서 받고 보내는 프로세스를 구별하는 포트넘버를 명시해서, TCP는 한 호스트의 보내는 프로세스가 네트워크를 통해서 다른 호스트의 받는 프로세스에 순차적으로, 방해받지 않는 *byte stream*을 보내는 것을 허용하는 추상화를 제공한다. 그것은 다음의 메커니즘으로 이를 해결한다.

- 호스트가 패킷을 보내면, 받는이는 반드시 **acknowledgment packet**을 보낸이가 패킷이 받아졌다고 알리기 위해서 보내야한다. 만약 ACK를 타이머가 만료되기전에 받지 못하면, 보낸이는 패킷을 다시 보낸다.
- TCP는 모든 패킷의 TCP 헤더에 **sequence numbers**를 제공한다. 이런 숫자들은 받는이가 (1) 요청한 프로세스에 준비된 데이터를 보내기전에 패킷을 순서대로 두고 (2) 바이트 스트림으로 부터 잃은 패킷에 대해서 지각하는 것을 허용한다.
- TCP 연결은 보낸이와 받는이(*three-way handshake*라고 불림) 사이의 컨트롤 패킷의 연속으로 시작되고 연결을 끊는 책임을 가진 컨트롤 패킷과 함께 우아하게 닫힌다.

TCP가 정보를 교환하는 방법을 보겠다.(연결 셋업과 끊기는 생략한다.) 연결이 생기면, 클라이언트는 요청 패킷을 서버에 시퀀스 넘버 904로 보낸다. UDP 예제의 서버와 달리, 서버는 반드시 ACK를 클라이언트에게 보낸다. 다음으로, 서버는 그것의 ACK 패킷을 클라이언트에게 보낸다. 다음으로, 서버는 다른 시퀀스 넘버로 시작하는 데이터 패킷의 스트림을 보내기 시작한다. 클라이언트는 받은 데이터 패킷에 대한 ACK 패킷을 보낸다. 불행히도, 시퀀스 127의 데이터 패킷을 잃었고, 클라이언트로부터 ACK 패킷이 돌아오지 않는다. 보낸이는 ACK 패킷을 기다리는 시간이 만료되고, 그래서 데이터 패킷 127을 다시보낸다. 시간이 흘러서, 서버는 데이터 패킷 128을 보낸지만, ACK를 잃는다. 서버가 ACK를 받지 못했기에 패킷 128은 다시 보내진다. 클라이언트는 중복된 패킷을 받는다. 클라이언트는 시퀀스 넘버를 통해서 받은 패킷이 이미 받은 것을 알고 버린다. 그러나, 그것은 서버에 ACK를 다시 보내서 서버가 진행하게 한다.

실제 TCP 상세에서, ACK는 각각에 필요하지 않는다. 대신에, 수신자는 패킷의 시리즈를 ACK하기 위해서 *cumulative ACK*를 보낸다. 서버는 또한 ACK를 기다리기전에 수많은 데이터 패킷을 보내고, 네트워크 산출량의 강점을 얻는다.

TCP는 또한 *flow control*과 *congestion control*을 이용해서 패킷의 플로우를 제제한다. **Flow control**은 수신인의 용량을 초과하지 않도록 보낸이를 예방한다. 예를 들어서, 수신인이 느린 연결을 가지거나 느린 하드웨어를 가졌다. 플로우 컨트롤은 보낸이가 느리게하거나 빠르게하라고 경고하는 리시버의 ACK 패킷으로 리턴된다. **Congestion control**은 보낸이와 받는이의 네트워크(일반적으로 라우터)의 상태를 근사화하게한다.  만약 라우터가 패킷에 의해서 꽉차면, 그것은 그들을 떨어뜨리는 경향이 있다. 패킷을 떨어뜨리면 ACK 타임아웃이 생기고, 더 많은 패킷이 네트워크에 포화된다. 이런 컨디션을 예방하기 위해서, 센더는 얼마나 많은 패킷이 인지되지 않았는지 아는 것으로서 드랍된 패킷으로 연결을 모니터링한다. 만약 너무 많은 드랍된 패킷이 있으면, 보낸이는 그들을 보내는 속도를 늦춘다. 이것은 TCP 연결이 같은 시간에 생기는 다른 연결과 공평하게 보장하는 것을 돕는다.

TCP같은 reliable 전송 프로토콜을 실행함으로서, 분산 시스템은 패킷의 손실이나 잘못된 순서를 교정할 로직이 필요하지 않다. 그러나, TCP는 UDP보다 느리다.

## 19.4 Network and Distributed Operating Systems

이 절에서, 우리는 두가지 종류의 네트워크 기반 운영체제를 설명하겠다.: 네트워크 운영체제와 분산 운영체제이다. 네트워크 운영체제는 구현하기는 간편하지만 많은 기능을 제공하는 분산 운영체제보다 유저가 접근하고 사용하기 더 어렵다.

### 19.4.1 네트워크 운영체제

**network operating system**은 유저가 적절한 원격 머신에 로그인하거나 그들의 머신으로 원격 머신에 있는 데이터를 전송함으로서 원격 리소스에 접근할 수 있는 환경을 제공한다. 최근에, 모든 범용 운영체제, 심지어는 안드로이드와 iOS같은 임베디드 운영체제도 네트워크 운영체제이다. 

#### 19.4.1.1 Remote Logini

네트워크 운영체제의 중요한 기능은 유저가 원격에서 로그인하게 허락하는 것이다. 인터넷은 이 목적을 위해서 `ssh`를 제공한다. 설명하자면, 웨스트민스터 대학의 유저가 예일 대학교에 위치한 컴퓨터, `kristen.cs.yale.edu`에서 연산하기를 바란다. 이걸 하기 위해서, 유저는 반드시 머신에 적절한 계정을 가지고 있어야한다. 원격에서 로그인하기 위해서, 유저는 다음 커맨드를 발행한다.

`ssh kristen.cs.yale.edu`

이 커맨드는 웨스트민스터 대학의 로컬 컴퓨터와 `kristen.cs.yale.edu` 컴퓨터사이를 암호화된 소켓 연결의 형식으로 얻는다. 이 연결이 성립된 이후에, 네트워킹 소프트웨어는 유저가 입력한 모든 문자가 `kristen.cs.yale.edu`의 프로세스로 보내지고 프로세스로부터의 모든 아웃풋이 유저에게 다시 보내지는 transparent, bidirectional 링크를 생성한다. 한번 정확한 정보를 얻으면, 프로세스는 원격 머신을 로컬 머신처럼 연산가능한 유저에게 프록시처럼 행동한다.

#### 19.4.1.2 Remote File Transfer

네트워크 운영체제의 다른 주요한 함수는 한 머신에서 다른 머신으로 **remote file transfer**하는 메커니즘을 제공하는 것이다. 이런 환경에서, 각 컴퓨터는 그것의 로컬 파일 시스템을 유지한다. 만약 사이트(Kurt at albion.edu)에서의 유저가 다른 컴퓨터(colby.edu)의 베카에 의해서 소유된 파일에 접근을 원하면, 파일은 반드시 Colby에 있는 컴퓨터에서 Albion에 있는 컴퓨터로 명시적으로 카피되어야한다. 이 통신은 다른 유저가 파일을 전송하기를 원하면 이런 커맨드의 집합을 발행해야하므로 단방향이고 개인적이다.

인터넷은 File transfer protocol(FTP)와 더욱 개인적인 secure file transfer protocol(SFTP)같은 전송을 위한 메커니즘을 제공한다. `wesleyan.edu`에 있는 카를라라는 유저가 `kzoo.edu`에 있는 오웬에 의해서 소유된 파일을 카피하기를 원한다고 가정하겠다. 유저는 반드시 `sftp owen@kzoo.edu`라는 프로그램을 실행함으로서 `sftp` 프로그램을 깨워야한다. 프로그램은 그리고 유저에게 로그인 이름과 패스워드를 묻는다. 한번 정확한 정보를 받으면, 유저는 파일을 업로드하고 다운로드하고, 파일 시스템 구조를 탐색하기 위해서 다음과 같은 커맨드를 사용할 수 있다.

- get - 원격 머신에서 로컬 머신으로 파일을 전송한다.
- put - 로컬 머신에서 원격 머신으로 파일을 전송한다.
- ls or dir - 리모트 머신의 현재 디렉토리의 파일을 리스트한다.
- cd - 리모트 머신의 현재 디렉토리를 변경한다.

#### 19.4.1.3 Cloud Storage

기본적인 클라우드 베이스 저장소 앱은 유저가 FTP를 이용해서 파일을 전송하게 허용한다. 유저는 클라우드 서버에 파일을 업로드하고, 로컬 컴퓨터에 파일을 다운로드하고 웹링크 또는 그래픽 인터페이스를 통한 다른 공유 메커니즘을 통해서 클라우드 시스템으로 파일을 공유한다. 일반적인 예시는 드롭박스와 구글 드라이브이다.

SSH, FTP와 클라우드 기반 저장소 앱에 관한 중요한 포인트는 그들은 유저가 패러다임을 바꾸도록 한다는 것이다. 예를 들어서, FTP는 기본 운영체제 시스템 커맨드와 확실히 다른 커맨드셋을 알도록 한다. SSH의 경우에는, 유저는 반드시 원격 시스템의 적절한 커맨드를 알아야한다. 예를 들어서, 윈도우의 유저가 유닉스 머신에 접근하면, SSH 세션동안에는 반드시 유닉스 커맨드를 사용해야한다.(네트워킹에서, **session**은 통신의 완벽한 라운드이고, 인증에 고르인하는 것부터 통신을 종료하는 로그오프까지를 의미한다.) 클라우드 기반 저장소 앱에서, 유저는 클라우드 서비스(웹 브라우저를 통해서)에 로그인하고 앱을 탐색하고 업로드, 다운로드, 공유를 위해서 그래픽 커맨드를 사용한다. 명백히, 유저들은 다른 커맨드의 집합을 필요롸지 않는 것을 더욱 편하다고 생각할 것이다. 분산 운영체제는 이 문제를 해결하기 위해서 디자인되었다.

### 19.4.2 분산 운영체제

분산 운영체제에서, 유저들은 그들이 로컬 리소스에 접근하는 것과 같은 방식으로 원격 리소스에 접근한다. 한 사이트에서 다른 사이트로의 프로세스와 데이터 이전은 분산 운영체제의 컨트롤 아래에 있다. 시스템의 목적에 따라서, 그것은 데이터 전송, 연산 전송, 프로세스 전송을 구현한다.

#### 19.4.2.1 Data Migrration

사이트 A의 유저가 사이트 B의 데이터에 접근하기를 원한다고 가정하겠다. 시스템은 두가지 기본적인 메서드 중 한가지로 전송할 수 있다. **data migration**을 통한 한가지 접근은 사이트 A에 전체 파일을 전송하는 것이다. 그 포인트로부터, 파일에 모든 접근은 로컬이다. 유저가 파일에 더이상 접근할 필요가 없으면, 파일의 카피가 사이트 B에 다시 보내진다. 오직 일부의 적당한 변화가 큰 파일에 만들어져도, 모든 데이터는 전송되어야한다. 이 메커니즘은 자동화된 FTP 시스템으로 생각하면 된다. 이 접근은 앤드류 파일 시스템(15장)에서 사용되었지만, 비효율적이었다.

사이트 A에 오직 현재의 태스크에 실제로 필요한 파일의 일부만 전송하는 다른 접근이다. 만약 다른 부분이 후에 필요하면, 다른 전송이 생긴다. 유저가 더 이상 필요로 하지 않으면, 수정된 일부분만이 사이트 B로 돌아간다.(디맨드 페이징과 비슷하다.) 대부분의 현대 분산 시스템은 이 방법을 사용한다.

어떤 메서드가 사용되든지, 데이터 전송은 데이터의 전송이 포함된다. 시스템은 만약 두사이트가 직접적으로 호환되지 않으면 반드시 다양한 데이터 번역을 수행해야한다.(예를 들어서, 만약 다른 캐릭터 코드 대표를 사용하거나 다른 숫자 또는 다른 비트의 순서의 정수를 사용하는 것이다.)

#### 19.4.2.2 Computaiton Migration

몇몇 상황에서, 우리는 시스템을 통해서 데이터보다는 연산을 전송하기를 원할수 있다. 이 프로세스는 **computation migration**이라고 불린다. 예를 들어서, 파일들의 요약을 얻기 위해서, 다른 사이트에 거주하는 큰 파일들에 접근할 필요가 있는 일을 고려해보자. 파일이 거주하는 사이트에서 접근하고 원하는 값을 연산을 시작한 사이트에서 리턴하는 것이 더욱 효율적이다. 일반적으로, 만약 데이터를 전송할 시간이 리모트 커맨드를 실행할 시간보다 길면, 리모트 커맨드가 사용되어야한다.

이런 연산을 다른 방식으로 실행된다. 프로세스 P가 사이트 A에 있는 파일에 접근하기를 원한다고 가정하겠다. 사이트 A에서 파일의 접근이 실행되고 RPC에 의해서 시작된다. RPC는 리모트 시스템에 있는 루틴을 실행할 네트워크 프로토콜을 사용한다. 프로세스 P는 사이트 A에서 미리 정의된 프로시저를 실행한다. 프로시저는 적절히 실행하고 P에 결과를 리턴한다.

대안으로, 프로세스 P는 사이트 A에 메시지를 보낸다. 사이트 A의 운영체제는 지정된 태스크를 실행하는 프로세스 Q를 새롭게 생성한다. 프로세스 Q가 그것의 실행을 마치면, 그것은 메시지 시스템을 통해서 P에 결과를 보낸다. 이 구조에서, 프로세스 P는 프로세스 Q와 동시에 실행한다. 실제로, 몇가지 사이트에서 동시에 작동하는 몇가지 프로세스가 있을 수 있다.

다양한 사이트에 거주하는 몇가지 파일에 접근하기 위해서 메서드가 사용될 수 있다. 한가지 RPC는 다른 RPC의 실행또는 다른 사이트로의 메시지의 전송에 결과할 수 있다. 비슷하게, 프로세스 Q는 그것의 실해웅에, 다른 사이트에 메시지를 보내고, 다른 프로세스를 생성한다. 이 프로세스는 Q에 메시지를 돌려보내거나 사이클을 반복한다.

#### 19.4.2.3 Process Migration

연산 이전의 논리적 확장은 **process migration**이다. 프로세스가 실행을 위해서 제출되면, 그것은 시작한 사이트에서 항상 실행되지 않는다. 전체 프로세스 또는 일부분이 다른 사이트에서 실행될 수 있다. 이런 구조는 다음의 이유로 사용된다.

- Load balancing 프로세스들은 사이트에서 부담을 분산할 수 있다.
- Computation speedup 만약 단일 프로세스가 다른 사이트 또는 노드에서 동시에 작동하는 서브 프로세스로 쪼개지면, 전테 프로세스 턴어라운드 시간이 줄어든다.
- Hardware preference 프로세스는 특정 프로세서에 적합한 실행을 요구하는 특정을 원할 수 있다.(매트릭스 인버전은 GPU에서)
- Software preference 프로세스는 특정 사이트에서 가용한 소프트웨어를 필요로하고, 소프트웨어는 이동될 수 없거나 프로세스를 이동하는게 싸다
- Data access 연산 이전에서 처럼, 만약 연산에 필요한 데이터가 크면, 그것은 원격에서 프로세스를 가지는 것이 데이터를 전송하는 것보다 효율적이다.

우리는 컴퓨터 네트워크에서 프로세스를 이동하기 위해서 두가지 상호보완적인 테크닉을 사용한다. 첫번쨰는, 시스템은 클라이언트로부터 프로세스가 이전되었다는 사실을 숨긴다. 클라이언트는 그러면 이전을 위해서 그녀의 프로그램을 코딩할 필요가 없다. 이 메서드는 보통 같은 시스템 사이에서 로드 밸런싱과 computation speedup을 실현함으로서 구현되고, 그들은 프로그램을 원격으로 실행하기 위해서 유저 인풋을 필요로 하지 않는다.

다른 접근은 유저가 어떻게 프로세스가 이전되는지 명시하는 것을 허용한다.(또는 필요) 이 메서드는 프로세스가 소프트웨어 또는 하드웨어 선호를 필요로할 때 사용된다.

너는 WWW가 분산 컴퓨팅 환경의 측면을 가진 것을 알 것이다. 확실히, 그것은 데이터 전송을 제공한다. 그것은 또한 computation migration도 제공한다. 예를 들어서, 웹 클라이언트는 쉡서버에서 데이터 베이스 명령어를 실행한다. 마지막으로, 자바, 자바 스크립트에서, 그것은 프로세스 이전의 형태를 제공한다. 자바 애플릿과 자바 스크립트 스크립츠는 그들이 실행되는 클라이언트로 보내진다. 네트워크 운영체제는 대부분의 이런 기능을 제공하지만, 분산 운영체제는 그들을 seamless하고 쉽게 접근하게 만든다. 강력하고 사용하기 쉬운 점이 WWW의 큰 성장의 이유이다.


## 19.5 Design Issues in Distributed Systems

분산 시스템의 디자이너들은 반드시 다양한 디자인 챌린지를 염두해야한다. 시스템은 그것이 실패를 견디도록 견고해야한다. 시스템은 파일 위치와 유저 이동성에대해서 유저에게 투명해야한다. 마지막으로, 시스템은 반드시 추가적인 연산 파워, 더 많은 공간, 더 많은 유저로 확장되게끔 허용되어야한다. 우리는 간단하게 이런 이슈들을 보겠다. 다음 절에서는, 우리는 우리가 말한 특정 분산시스템의 디자인을 설명하겠다. 

### 19.5.1 Robustness

분산 시스템은 다양한 타입의 하드웨어 실패로 고통받는다. 링크, 호스트, 사이트의 실패와 메시지의 손실이 가장 일반적이다. 시스템이 견고하다는 것을 확신하려면, 우리는 이런 실패를 탐지해야하고, 연산이 지속되게끔 시스템을 재설정하고, 실패가 수리되면 회복해야한다.

시스템은 그것이 실패의 레벨을 참아내고 함수를 일반적으로 실행함으로서 **fault tolerant**할 수 있다. fault tolerance의 정도는 분산 시스템의 디자인과 특정 실패에 달려있다. 명백히, 더 많은 fault tolerance가 낫다.

우리는 *fault tolerance*를 다양한 범위에서 사용한다. 통신 실패, 특정 머신 실패, 저장 디바이스 크래시, 저장 미디어의 부패는 모두 몇가지 확장으로 tolerated할 수 있다. **fault tolerant system**은 반드시 함수를 지속하고, 아마 이런 실패를 겪으면 디그레이드된 형태가 된다. 디그레이션은 성능, 기능에 영향을 줄 수 있다. 그것은 일부여야만하고, 실패를 발생했다. 한가지 컴포넌트가 실패해서 정지를 생산한 시스템은 fault tolerant가 아니다.

불행히도, 폴트 톨레런스는 구현하기 비싸고 힘들다. 네트워크 계층에서, 다양한 추가적인 통신 경로와 네트워크 디바이스(스위치, 라우터)가 통신 실패를 피하기 위해서 존재한다. 저장소 실패는 운영체제, 앱, 데이터의 손실을 초래한다. 저장소 유닛은 자동으로 이런 실패를 극복하기 위해서 추가적인 하드웨어 컴포넌트를 포함한다. 추가적으로 레이드 시스템은 하나 또는 그 이상의 저장소 디바이스 실패 상황에서도 데이터에 연속적인 접근을 보장한다.

#### 19.5.1.1 실패 탐지

공유 메모리가 없는 환경에서, 우리는 링크 실패, 사이트 실패, 호스트 실패, 메시지 손실를 구별할 수 없다. 우리는 보통 이 중에서 한가지가 생겼다고 탐지한다. 한번 실패가 탐지되면, 적절한 액션이 취해진다. 어떤 액션이 적절한지는 특정 앱에 따라 달려있다.

링크와 사이트 실패를 탐지하려면, 우리는 **heartbeat** 프로시저를 사용한다. 사이트 A와 B가 그들 사이에 물리적 직접 연결이 있다. 고정된 간격에서, 그 사이트들은 서로에게 `I-am-up` 메시지를 보낸다. 만약 사이트 A가 이 메시지를 미리 정한 주기 내에 받지 못하면, 그것은 사이트 B가 실패했다고 가정하고, A와 B사이의 링크가 실패하거나 B로부터의 메시지가 손실되었다고 한다. 이 시점에, 사이트A는 두가지 선택이 있다. 그것은 B로부터 `I-am-up` 메시지를 다른 시간 기간동안 기다리거나, B에게 `Are-you-up?`메시지를 보낸다.

만약 시간이 흐르고 사이트 A가 `I-am-up` 메시지를 받지 못하거나 `Are-you-up?`에 대한 답장을 받지 못했다. 다시, 사이트 A가 내리는 결론은 실패가 일어났다는 것디아.

사이트 A는 링크 실패와 사이트 실패를 다른 루트로 `Are-you-up?` 메시지를 보냄으로서 구별할 수 있다. 만약 이 메시지를 B가 받으면, 그것은 즉시 답장할 것이다. 이 긍정적 답장은 A에게 B가 준비되어 있고 그들 사이의 링크가 실패했다는 것이다. 우리가 메시지가 A에서 B까지 얼마나 걸릴지 알수 없기 때문에, 우리는 time-out 구조를 사용해야한다. A가 `Are-you-up?`을 보낸시간에, 그것은 B로부터 답변을 기다리길 원하는 시간 간격을 정한다. 만약 A가 답장 메시지를 시간 간격안에 받으면, 그것은 B가 준비되었다고 할 수 있다. 그렇지 않으면, A는 다음 상황을 가정한다.
- Site B is down
- Direct link from A to B is down
- Alternative path from A to B is down
- The message has been lost.(Although the use of reliable TCP)

사이트 A는 이런 것중 무엇이 일어났는지는 모른다.

#### 19.5.1.2 Reconfiguration

사이트 A가 이전에 말한 메커니즘으로 실패가 일어났다고 발견되었다고 가정하자. 그것은 반드시 시스템이 그것의 명령의 일반적인 모드를 재설정하고 진행하게 허용하는 프로시저를 시작해야한다.

- 만약 A에서 B의 직접 링크가 실패하면, 이 정보는 시스템의 모든 사이트에 방송되어서, 다양한 라우트 테이블이 이에 맞게 업데이트된다.
- 만약 시스템이 사이트가 실패했다고 믿으면(왜냐하면 사이트가 더 이상 닿지 않는다.), 그떄 시스템의 모든 사이트에 알려지고, 더이상 실패한 사이트의 서비스를 사용하려고 시도하지 않는다. 몇몇 활동을 위한 중신 중재자로 역할하는 사이트의 실패는 새로운 중재자를 필요로한다. 만약 사이트가 실패하지 않으면, 그때 우리는 두가지 서버가 중재자로서 취급하는 원치 않는 상황을 가진다. 네트워크가 파티션되면, 두 중재자는 충돌하는 액션을 시작한다. 예를 들어서, 만약 중재자가 상호배제를 구현하는 역할이면, 우리는 두 프로세스가 그들의 임계영역을 실행하는 상황을 보게된다.

#### 19.5.1.3 Recovery from failure

실패한 링크 또는 사이트가 고쳐지면, 그것은 반드시 시스템에 우아하고 부드럽게 통합되어야한다.

- A와 B사이의 링크가 실패했다고 가정하자. 그것이 고쳐지면, A와 B에게 알려져야한다. 우리는 19.5.1.1에서 설명한 하트비트 절차를 반복해서 이 정보를 알린다.
- 사이트 B가 실패했다고 가정하자. 그것이 고쳐지면, 그것은 반드시 다른 사이트에게 그것이 준비되었다고 알려야한다. 사이트 B는 그것의 로컬 테이블을 업데이트하기 위해서 다른 사이트로부터 정보를 얻어야한다. 예를 들어서, 그것은 라우팅 테이블 정보, 다운된 사이트의 리스트, 배달되지 않은 메시지, 실행되지 않은 트랙잭션의 트랜잭션 로그를 필요로한다. 만약 사이트가실패하지 안았고 도달만 안되어도, 그것은 이 정보를 필요로한다.

### 19.5.2 Transparency

분산 시스템에서 다중 프로세스와 저장 디바이스를 유저에게 **transparent**하게 만드는 것은 많은 디자이너에게 주요한 챌린지이다. 이상적으로, 분산 시스템은 반드시 그것의 유저를 평범하고 중심화된 시스템으로 보아야한다. transparent 분산 시스템의 유저 인터페이스는 로컬과 리모트 리소스간에 구별되지 않아야한다. 즉, 유저는 반드시 리소스가 로컬인 것처럼 리모트 리소스에 접근할 수 있어야하고 분산 시스템은 반드시 리소스를 위치하고 적절한 인터섹션에 배열하는 책임을 가져야한다.

transparency의 다른 측면은 user mobility이다. 그것은 유저가 그들이 특정 머신을 사용하는 것보다 시스템의 어떤 기기에도 로그인하게 허용하기 편한 것이다. 투명한 분산 시스템은 유저 모빌리티를 유저의 환경을 그가 로그인 한 곳으로 가져다 줌으로서 가능하게한다. LDAP같은 프로토콜은 로컬, 리모트, 모바일유저에게 인증 시스템을 제공한다. 한번 인증이 완료되면, 데스크탑 가상화 같은 기능은 유저가 그들의 데스크탑 세션을 원격 퍼실리티에서 보게 허용한다.

### 19.5.3 Scalability

여전히 다른 이슈는 **scalability**이다. 증가된 서비스 로드에 적응하는 시스템의 능력이다. 시스템은 제한된 리소스를 가지고 증가된 로드에 의해서 완벽히 포화된다. 예를 들어서, 파일 시스템에서, 포화는서버의 CPU가 높은 실행율에서 실행되거나 디스크의 I/O 요청이 I/O 서브시스템을 압도할 때 생긴다. Scalability는 상대적인 특징이고 그러나 그것은 정확히 측정된다. scalable 시스템은 그렇지 않은 것보다 증가하는 로드에 우아하게 대응한다. 첫번째, 그것의 성능은 더욱 온화하게 감소한다. 두번째, 그것의 리소스는 포화된 상태에 늦게 도착한다. 아무리 완벽한 디자인도 무한히 자라는 로드를 감다앟지 못한다. 새로운 리소스를 더하는 것은 문제를 해결하지만, 그러나 그것은 다른 리소스에 간접적인 로드를 추가하는 것을 생성한다. 더 최악으로, 시스템을 확장하는 것은 이런 문제 없이 자라날 가능성을 가진다. 분산 시스템에서, 스케일업 할 능력은 특별히 중요한데, 새로운 머신을 추가해서 네트워크를 확장하거나 두 네트워크를 연결하는 것이 일반적이기 때문이다. 짧게 말해서, 증가하는 디자인은 높은 서비스 로드를 감당하고, 유저 커뮤니티의 증가를 수용하고, 추가된 리소스의 간단한 통합을 허용해야한다.

증가는 fault tolerance에도 연관이 있다. 높게 로드된 컴포넌트는 마비되거나 faulty 컴포넌트처럼 행동한다. 추가로, 폴티 컴포넌트로부터 컴포넌트의 백업으로 로드를 바꾸는 것은 후자를 포화시킨다. 일반적으로, 스패어 리소스를 가지는 것은 신뢰성을 보장하는 것에 주요하다. 그러므로, 분산 시스템에서의 다중 리소스는 내부적인 장점을 대표하고, 시스템이 faulty tolerance와 scalabilty에 큰 가능성을 준다. 그러나, 부적절한 디자인은 이 가능성을 애매하게한다. 폴트 톨레랑스와 확장성 고려는 데이터와 컨트롤의 분산을 정의하는 디자인을 콜한다.

확장성은 또한 효율적인 저장소 구조와 관련되어 있다. 예를 들어서, 많은 클라우드 저장소는 사용하는 저장소의 양을 줄이기 위해서 **compression** 또는 **deduplication** 사용을 제공한다. *Compression*은 파일의 크기를 줄인다. 예를 들어서, `zip` 아카이브 파일은 `zip`커맨드를 이용해서 파일을 생성한다. 결과는 압축된 것이 더 적은 용량이다. 원래 상태로 돌리려면, 유저는 unzip 커맨드를 사용하면 된다. *Deduplication*은 데이터 저장 필요를 추가적인 데이터를 지움으로서 낮춘다. 이 기술과 함꼐, 데이터의 한가지 인스턴스만이 전체 시스템에 저장된다. 압축과 중복방지는 파일 레벨 또는 블럭레벨에서 사용되고, 그들은 함께 사용된다. 이런 기술들은 자동으로 분산 시스템에 유저가 특정 커맨드를 명시적으로 발행하지 않고 정보를 압축하게 지어지고, 그러므로 저장소 공간을 아끼고 유저 복잡도를 추가하지 않고 네트워크 통신 비용을 절약한다.

